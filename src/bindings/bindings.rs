/* automatically generated by rust-bindgen 0.71.1 */

pub const DNNL_RUNTIME_NONE: u32 = 0;
pub const DNNL_RUNTIME_SEQ: u32 = 1;
pub const DNNL_RUNTIME_OMP: u32 = 2;
pub const DNNL_RUNTIME_TBB: u32 = 4;
pub const DNNL_RUNTIME_THREADPOOL: u32 = 8;
pub const DNNL_RUNTIME_OCL: u32 = 256;
pub const DNNL_RUNTIME_SYCL: u32 = 512;
pub const DNNL_RUNTIME_DPCPP: u32 = 512;
pub const DNNL_VENDOR_NONE: u32 = 0;
pub const DNNL_VENDOR_INTEL: u32 = 1;
pub const DNNL_VENDOR_NVIDIA: u32 = 2;
pub const DNNL_VENDOR_AMD: u32 = 4;
pub const DNNL_VENDOR_GENERIC: u32 = 8;
pub const DNNL_CPU_THREADING_RUNTIME: u32 = 4;
pub const DNNL_CPU_RUNTIME: u32 = 512;
pub const DNNL_GPU_RUNTIME: u32 = 512;
pub const DNNL_GPU_VENDOR: u32 = 1;
pub const BUILD_TRAINING: u32 = 1;
pub const BUILD_INFERENCE: u32 = 0;
pub const BUILD_PRIMITIVE_ALL: u32 = 1;
pub const BUILD_BATCH_NORMALIZATION: u32 = 0;
pub const BUILD_BINARY: u32 = 0;
pub const BUILD_CONCAT: u32 = 0;
pub const BUILD_CONVOLUTION: u32 = 0;
pub const BUILD_DECONVOLUTION: u32 = 0;
pub const BUILD_ELTWISE: u32 = 0;
pub const BUILD_GROUP_NORMALIZATION: u32 = 0;
pub const BUILD_INNER_PRODUCT: u32 = 0;
pub const BUILD_LAYER_NORMALIZATION: u32 = 0;
pub const BUILD_LRN: u32 = 0;
pub const BUILD_MATMUL: u32 = 0;
pub const BUILD_POOLING: u32 = 0;
pub const BUILD_PRELU: u32 = 0;
pub const BUILD_REDUCTION: u32 = 0;
pub const BUILD_REORDER: u32 = 0;
pub const BUILD_RESAMPLING: u32 = 0;
pub const BUILD_RNN: u32 = 0;
pub const BUILD_SDPA: u32 = 0;
pub const BUILD_SHUFFLE: u32 = 0;
pub const BUILD_SOFTMAX: u32 = 0;
pub const BUILD_SUM: u32 = 0;
pub const BUILD_PRIMITIVE_CPU_ISA_ALL: u32 = 1;
pub const BUILD_SSE41: u32 = 0;
pub const BUILD_AVX2: u32 = 0;
pub const BUILD_AVX512: u32 = 0;
pub const BUILD_AMX: u32 = 0;
pub const BUILD_PRIMITIVE_GPU_ISA_ALL: u32 = 1;
pub const BUILD_GEN9: u32 = 0;
pub const BUILD_GEN11: u32 = 0;
pub const BUILD_XELP: u32 = 0;
pub const BUILD_XEHP: u32 = 0;
pub const BUILD_XEHPG: u32 = 0;
pub const BUILD_XEHPC: u32 = 0;
pub const BUILD_XE2: u32 = 0;
pub const BUILD_XE3: u32 = 0;
pub const BUILD_GEMM_KERNELS_ALL: u32 = 1;
pub const BUILD_GEMM_KERNELS_NONE: u32 = 0;
pub const BUILD_GEMM_SSE41: u32 = 0;
pub const BUILD_GEMM_AVX2: u32 = 0;
pub const BUILD_GEMM_AVX512: u32 = 0;
pub const DNNL_MAX_NDIMS: u32 = 12;
pub const DNNL_VERSION_MAJOR: u32 = 3;
pub const DNNL_VERSION_MINOR: u32 = 8;
pub const DNNL_VERSION_PATCH: u32 = 1;
pub const DNNL_ARG_UNDEF: u32 = 0;
pub const DNNL_ARG_SRC_0: u32 = 1;
pub const DNNL_ARG_SRC: u32 = 1;
pub const DNNL_ARG_SRC_LAYER: u32 = 1;
pub const DNNL_ARG_FROM: u32 = 1;
pub const DNNL_ARG_SRC_1: u32 = 2;
pub const DNNL_ARG_SRC_ITER: u32 = 2;
pub const DNNL_ARG_SRC_2: u32 = 3;
pub const DNNL_ARG_SRC_ITER_C: u32 = 3;
pub const DNNL_ARG_SRC_3: u32 = 4;
pub const DNNL_ARG_AUGRU_ATTENTION: u32 = 4;
pub const DNNL_ARG_DST_0: u32 = 17;
pub const DNNL_ARG_DST: u32 = 17;
pub const DNNL_ARG_TO: u32 = 17;
pub const DNNL_ARG_DST_LAYER: u32 = 17;
pub const DNNL_ARG_DST_1: u32 = 18;
pub const DNNL_ARG_DST_ITER: u32 = 18;
pub const DNNL_ARG_DST_2: u32 = 19;
pub const DNNL_ARG_DST_ITER_C: u32 = 19;
pub const DNNL_ARG_WEIGHTS_0: u32 = 33;
pub const DNNL_ARG_WEIGHTS: u32 = 33;
pub const DNNL_ARG_WEIGHTS_LAYER: u32 = 33;
pub const DNNL_ARG_WEIGHTS_1: u32 = 34;
pub const DNNL_ARG_WEIGHTS_ITER: u32 = 34;
pub const DNNL_ARG_WEIGHTS_2: u32 = 35;
pub const DNNL_ARG_WEIGHTS_PEEPHOLE: u32 = 35;
pub const DNNL_ARG_WEIGHTS_3: u32 = 36;
pub const DNNL_ARG_WEIGHTS_PROJECTION: u32 = 36;
pub const DNNL_ARG_BIAS: u32 = 41;
pub const DNNL_ARG_REDUCE: u32 = 42;
pub const DNNL_ARG_MEAN: u32 = 49;
pub const DNNL_ARG_VARIANCE: u32 = 50;
pub const DNNL_ARG_SCALE: u32 = 51;
pub const DNNL_ARG_SHIFT: u32 = 52;
pub const DNNL_ARG_WORKSPACE: u32 = 64;
pub const DNNL_ARG_SCRATCHPAD: u32 = 80;
pub const DNNL_ARG_DIFF_SRC_0: u32 = 129;
pub const DNNL_ARG_DIFF_SRC: u32 = 129;
pub const DNNL_ARG_DIFF_SRC_LAYER: u32 = 129;
pub const DNNL_ARG_DIFF_SRC_1: u32 = 130;
pub const DNNL_ARG_DIFF_SRC_ITER: u32 = 130;
pub const DNNL_ARG_DIFF_SRC_2: u32 = 131;
pub const DNNL_ARG_DIFF_SRC_ITER_C: u32 = 131;
pub const DNNL_ARG_DIFF_SRC_3: u32 = 132;
pub const DNNL_ARG_DIFF_AUGRU_ATTENTION: u32 = 132;
pub const DNNL_ARG_DIFF_DST_0: u32 = 145;
pub const DNNL_ARG_DIFF_DST: u32 = 145;
pub const DNNL_ARG_DIFF_DST_LAYER: u32 = 145;
pub const DNNL_ARG_DIFF_DST_1: u32 = 146;
pub const DNNL_ARG_DIFF_DST_ITER: u32 = 146;
pub const DNNL_ARG_DIFF_DST_2: u32 = 147;
pub const DNNL_ARG_DIFF_DST_ITER_C: u32 = 147;
pub const DNNL_ARG_DIFF_WEIGHTS_0: u32 = 161;
pub const DNNL_ARG_DIFF_WEIGHTS: u32 = 161;
pub const DNNL_ARG_DIFF_WEIGHTS_LAYER: u32 = 161;
pub const DNNL_ARG_DIFF_WEIGHTS_1: u32 = 162;
pub const DNNL_ARG_DIFF_WEIGHTS_ITER: u32 = 162;
pub const DNNL_ARG_DIFF_WEIGHTS_2: u32 = 163;
pub const DNNL_ARG_DIFF_WEIGHTS_PEEPHOLE: u32 = 163;
pub const DNNL_ARG_DIFF_WEIGHTS_3: u32 = 164;
pub const DNNL_ARG_DIFF_WEIGHTS_PROJECTION: u32 = 164;
pub const DNNL_ARG_DIFF_BIAS: u32 = 169;
pub const DNNL_ARG_DIFF_SCALE: u32 = 255;
pub const DNNL_ARG_DIFF_SHIFT: u32 = 256;
pub const DNNL_ARG_ATTR_ROUNDING_SEED: u32 = 508;
pub const DNNL_ARG_ATTR_DROPOUT_MASK: u32 = 509;
pub const DNNL_ARG_ATTR_DROPOUT_PROBABILITY: u32 = 510;
pub const DNNL_ARG_ATTR_DROPOUT_SEED: u32 = 511;
pub const DNNL_ARG_ATTR_OUTPUT_SCALES: u32 = 513;
pub const DNNL_ARG_MULTIPLE_SRC: u32 = 1024;
pub const DNNL_ARG_MULTIPLE_DST: u32 = 2048;
pub const DNNL_ARG_ATTR_SCALES: u32 = 4096;
pub const DNNL_ARG_ATTR_ZERO_POINTS: u32 = 8192;
pub const DNNL_ARG_ATTR_POST_OP_DW: u32 = 16384;
pub const DNNL_ARG_ATTR_MULTIPLE_POST_OP_BASE: u32 = 32768;
pub const DNNL_JIT_PROFILE_NONE: u32 = 0;
pub const DNNL_JIT_PROFILE_VTUNE: u32 = 1;
pub const DNNL_JIT_PROFILE_LINUX_PERFMAP: u32 = 2;
pub const DNNL_JIT_PROFILE_LINUX_JITDUMP: u32 = 4;
pub const DNNL_JIT_PROFILE_LINUX_JITDUMP_USE_TSC: u32 = 8;
pub const DNNL_JIT_PROFILE_LINUX_PERF: u32 = 6;
pub const DNNL_GRAPH_UNKNOWN_NDIMS: i32 = -1;
pub mod dnnl_status_t {
    #[doc = " Status values returned by the library functions."]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " The operation was successful"]
    pub const dnnl_success: Type = 0;
    #[doc = " The operation failed due to an out-of-memory condition"]
    pub const dnnl_out_of_memory: Type = 1;
    #[doc = " The operation failed because of incorrect function arguments"]
    pub const dnnl_invalid_arguments: Type = 2;
    #[doc = " The operation failed because requested functionality is not implemented"]
    pub const dnnl_unimplemented: Type = 3;
    #[doc = " The last available implementation is reached"]
    pub const dnnl_last_impl_reached: Type = 4;
    #[doc = " Primitive or engine failed on execution"]
    pub const dnnl_runtime_error: Type = 5;
    #[doc = " Queried element is not required for given primitive"]
    pub const dnnl_not_required: Type = 6;
    #[doc = " The graph is not legitimate"]
    pub const dnnl_invalid_graph: Type = 7;
    #[doc = " The operation is not legitimate according to op schema"]
    pub const dnnl_invalid_graph_op: Type = 8;
    #[doc = " The shape cannot be inferred or compiled"]
    pub const dnnl_invalid_shape: Type = 9;
    #[doc = " The data type cannot be inferred or compiled"]
    pub const dnnl_invalid_data_type: Type = 10;
}
pub mod dnnl_data_type_t {
    #[doc = " Data type specification"]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " Undefined data type, used for empty memory descriptors."]
    pub const dnnl_data_type_undef: Type = 0;
    #[doc = " 16-bit/half-precision floating point."]
    pub const dnnl_f16: Type = 1;
    #[doc = " non-standard 16-bit (bfloat16 w/ 7 bit mantissa) floating point."]
    pub const dnnl_bf16: Type = 2;
    #[doc = " 32-bit/single-precision floating point."]
    pub const dnnl_f32: Type = 3;
    #[doc = " 32-bit signed integer."]
    pub const dnnl_s32: Type = 4;
    #[doc = " 8-bit signed integer."]
    pub const dnnl_s8: Type = 5;
    #[doc = " 8-bit unsigned integer."]
    pub const dnnl_u8: Type = 6;
    #[doc = " 64-bit/double-precision floating point."]
    pub const dnnl_f64: Type = 7;
    #[doc = " Boolean data type. Size is C++ implementation defined."]
    pub const dnnl_boolean: Type = 8;
    #[doc = " [OFP8 standard 8-bit floating-point](https://www.opencompute.org/documents/ocp-8-bit-floating-point-specification-ofp8-revision-1-0-2023-06-20-pdf)\n with a 5-bit exponent and a 2-bit mantissa."]
    pub const dnnl_f8_e5m2: Type = 9;
    #[doc = " [OFP8 standard 8-bit floating-point](https://www.opencompute.org/documents/ocp-8-bit-floating-point-specification-ofp8-revision-1-0-2023-06-20-pdf)\n with a 4-bit exponent and a 3-bit mantissa."]
    pub const dnnl_f8_e4m3: Type = 10;
    #[doc = " 4-bit signed integer."]
    pub const dnnl_s4: Type = 11;
    #[doc = " 4-bit unsigned integer."]
    pub const dnnl_u4: Type = 12;
    #[doc = " [MX-compliant 8-bit compliant scale data type](https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf) with 8-bit exponent."]
    pub const dnnl_e8m0: Type = 13;
    #[doc = " [MX-compliant 4-bit float data type](https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf) with 2-bit exponent and 1 bit mantissa."]
    pub const dnnl_f4_e2m1: Type = 14;
    #[doc = " 4-bit float data type with 3-bit exponent and 0 bit mantissa."]
    pub const dnnl_f4_e3m0: Type = 15;
    #[doc = " Parameter to allow internal only data_types without undefined behavior.\n This parameter is chosen to be valid for so long as sizeof(int) >= 2."]
    pub const dnnl_data_type_max: Type = 32767;
}
#[doc = " A type to describe tensor dimension."]
pub type dnnl_dim_t = i64;
#[doc = " A type to describe tensor dimensions."]
pub type dnnl_dims_t = [dnnl_dim_t; 12usize];
pub mod dnnl_fpmath_mode_t {
    #[doc = " Floating-point math mode"]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " Default behavior, no downconversions allowed"]
    pub const dnnl_fpmath_mode_strict: Type = 0;
    #[doc = " Implicit f32->bf16 conversions allowed"]
    pub const dnnl_fpmath_mode_bf16: Type = 1;
    #[doc = " Implicit f32->f16 conversions allowed"]
    pub const dnnl_fpmath_mode_f16: Type = 2;
    #[doc = " Implicit f32->f16, f32->tf32 or f32->bf16 conversions allowed"]
    pub const dnnl_fpmath_mode_any: Type = 3;
    #[doc = " Implicit f32->tf32 conversions allowed"]
    pub const dnnl_fpmath_mode_tf32: Type = 4;
}
pub mod dnnl_accumulation_mode_t {
    #[doc = " Accumulation mode"]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " Default behavior, f32/f64 for floating point computation, s32\n for integer"]
    pub const dnnl_accumulation_mode_strict: Type = 0;
    #[doc = " Same as strict but allows some partial accumulators to be\n rounded to src/dst datatype in memory."]
    pub const dnnl_accumulation_mode_relaxed: Type = 1;
    #[doc = " uses fastest implementation, could use src/dst datatype or\n wider datatype for accumulators"]
    pub const dnnl_accumulation_mode_any: Type = 2;
    #[doc = " use s32 accumulators during computation"]
    pub const dnnl_accumulation_mode_s32: Type = 3;
    #[doc = " use f32 accumulators during computation"]
    pub const dnnl_accumulation_mode_f32: Type = 4;
    #[doc = " use f16 accumulators during computation"]
    pub const dnnl_accumulation_mode_f16: Type = 5;
}
pub mod dnnl_engine_kind_t {
    #[doc = " @brief Kinds of engines."]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " An unspecified engine."]
    pub const dnnl_any_engine: Type = 0;
    #[doc = " CPU engine."]
    pub const dnnl_cpu: Type = 1;
    #[doc = " GPU engine."]
    pub const dnnl_gpu: Type = 2;
}
#[doc = " @struct dnnl_engine\n @brief An opaque structure to describe an engine."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_engine {
    _unused: [u8; 0],
}
#[doc = " @brief An engine handle."]
pub type dnnl_engine_t = *mut dnnl_engine;
pub mod dnnl_stream_flags_t {
    #[doc = " @brief Stream flags."]
    pub type Type = ::std::os::raw::c_uint;
    pub const dnnl_stream_in_order: Type = 1;
    #[doc = " Out-of-order execution."]
    pub const dnnl_stream_out_of_order: Type = 2;
    #[doc = " Default stream configuration."]
    pub const dnnl_stream_default_flags: Type = 1;
}
#[doc = " @struct dnnl_stream\n An opaque structure to describe an execution stream."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_stream {
    _unused: [u8; 0],
}
#[doc = " An execution stream handle."]
pub type dnnl_stream_t = *mut dnnl_stream;
#[doc = " A constant execution stream handle."]
pub type const_dnnl_stream_t = *const dnnl_stream;
#[doc = " Structure containing version information as per [Semantic\n Versioning](https://semver.org)"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_version_t {
    #[doc = "< Major version"]
    pub major: ::std::os::raw::c_int,
    #[doc = "< Minor version"]
    pub minor: ::std::os::raw::c_int,
    #[doc = "< Patch version"]
    pub patch: ::std::os::raw::c_int,
    #[doc = "< Git hash of the sources (may be absent)"]
    pub hash: *const ::std::os::raw::c_char,
    #[doc = "< CPU runtime"]
    pub cpu_runtime: ::std::os::raw::c_uint,
    #[doc = "< GPU runtime"]
    pub gpu_runtime: ::std::os::raw::c_uint,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of dnnl_version_t"][::std::mem::size_of::<dnnl_version_t>() - 32usize];
    ["Alignment of dnnl_version_t"][::std::mem::align_of::<dnnl_version_t>() - 8usize];
    ["Offset of field: dnnl_version_t::major"]
        [::std::mem::offset_of!(dnnl_version_t, major) - 0usize];
    ["Offset of field: dnnl_version_t::minor"]
        [::std::mem::offset_of!(dnnl_version_t, minor) - 4usize];
    ["Offset of field: dnnl_version_t::patch"]
        [::std::mem::offset_of!(dnnl_version_t, patch) - 8usize];
    ["Offset of field: dnnl_version_t::hash"]
        [::std::mem::offset_of!(dnnl_version_t, hash) - 16usize];
    ["Offset of field: dnnl_version_t::cpu_runtime"]
        [::std::mem::offset_of!(dnnl_version_t, cpu_runtime) - 24usize];
    ["Offset of field: dnnl_version_t::gpu_runtime"]
        [::std::mem::offset_of!(dnnl_version_t, gpu_runtime) - 28usize];
};
unsafe extern "C" {
    #[doc = " Returns the number of engines of a particular kind.\n\n @param kind Kind of engines to count.\n @returns Count of the engines."]
    pub fn dnnl_engine_get_count(kind: dnnl_engine_kind_t::Type) -> usize;
}
unsafe extern "C" {
    #[doc = " Creates an engine.\n\n @param engine Output engine.\n @param kind Engine kind.\n @param index Engine index that should be between 0 and the count of\n     engines of the requested kind.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_engine_create(
        engine: *mut dnnl_engine_t,
        kind: dnnl_engine_kind_t::Type,
        index: usize,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the kind of an engine.\n\n @param engine Engine to query.\n @param kind Output engine kind.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_engine_get_kind(
        engine: dnnl_engine_t,
        kind: *mut dnnl_engine_kind_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Destroys an engine.\n\n @param engine Engine to destroy.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_engine_destroy(engine: dnnl_engine_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates an execution stream.\n\n @param stream Output execution stream.\n @param engine Engine to create the execution stream on.\n @param flags Stream behavior flags (@sa dnnl_stream_flags_t).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_stream_create(
        stream: *mut dnnl_stream_t,
        engine: dnnl_engine_t,
        flags: ::std::os::raw::c_uint,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the engine of a stream object.\n\n @param stream Stream object.\n @param engine Output engine on which the stream is created.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_stream_get_engine(
        stream: const_dnnl_stream_t,
        engine: *mut dnnl_engine_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Waits for all primitives in the execution stream to finish computations.\n\n @param stream Execution stream.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_stream_wait(stream: dnnl_stream_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Destroys an execution stream.\n\n @param stream Execution stream to destroy.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_stream_destroy(stream: dnnl_stream_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the floating-point math mode that will be used by default\n for all subsequently created primitives.\n\n @param mode Output FP math mode.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_get_default_fpmath_mode(mode: *mut dnnl_fpmath_mode_t::Type)
        -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets the floating-point math mode that will be used by default\n for all subsequently created primitives.\n\n @param mode FP math mode. The possible values are:\n     #dnnl_fpmath_mode_strict,\n     #dnnl_fpmath_mode_bf16,\n     #dnnl_fpmath_mode_f16,\n     #dnnl_fpmath_mode_tf32,\n     #dnnl_fpmath_mode_any.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_set_default_fpmath_mode(mode: dnnl_fpmath_mode_t::Type) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Configures verbose output to stdout.\n\n @note\n     Enabling verbose output affects performance.\n     This setting overrides the ONEDNN_VERBOSE environment variable.\n\n @param level Verbosity level:\n  - 0: no verbose output (default),\n  - 1: primitive and graph information at execution,\n  - 2: primitive and graph information at creation/compilation and execution.\n @returns #dnnl_invalid_arguments/#dnnl::status::invalid_arguments if the\n     @p level value is invalid, and #dnnl_success/#dnnl::status::success on\n     success."]
    pub fn dnnl_set_verbose(level: ::std::os::raw::c_int) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns library version information.\n @returns Pointer to a constant structure containing\n  - major: major version number,\n  - minor: minor version number,\n  - patch: patch release number,\n  - hash: git commit hash."]
    pub fn dnnl_version() -> *const dnnl_version_t;
}
pub mod dnnl_format_kind_t {
    #[doc = " Memory format kind"]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " Undefined memory format kind, used for empty memory descriptors."]
    pub const dnnl_format_kind_undef: Type = 0;
    #[doc = " A special format kind that indicates that the actual format will be\n selected by a primitive automatically."]
    pub const dnnl_format_kind_any: Type = 1;
    #[doc = " A tensor in a generic format described by the stride and blocking\n values in each dimension."]
    pub const dnnl_blocked: Type = 2;
    #[doc = " A special format kind that indicates that tensor format is opaque."]
    pub const dnnl_format_kind_opaque: Type = 3;
    #[doc = " Parameter to allow internal only format kinds without undefined\n behavior. This parameter is chosen to be valid for so long as\n sizeof(int) >= 2."]
    pub const dnnl_format_kind_max: Type = 32767;
}
pub mod dnnl_format_tag_t {
    #[doc = " Memory format tag specification.\n\n oneDNN formats describe physical data layout. The physical layout\n is described as a sequence of the dimensions as they are laid out in the\n memory (from the outer-most to the inner-most). Note that this order\n doesn't affect the logical order of the dimensions that is kept in the\n `dims` field of the dnnl_memory_desc_t structure. The logical order of the\n dimensions is specified by the primitive that uses the tensor.\n\n For example, CNN 5D tensor always has its logical dimensions in the order\n `(batch, channels, depth, height, width)`, while the physical layout might be\n `NCDHW` (corresponds to #dnnl_ncdhw format tag) or\n `NDHWC` (corresponds to #dnnl_ndhwc format tag).\n\n ~~~cpp\n int batch = 2, channels = 16, depth = 13, height = 13, width = 13;\n\n int ndims = 5; // 5D tensor\n dnnl_dims_t dims = {batch, channels, depth, height, width};\n dnnl_memory_desc_t data_in_ncdhw;\n dnnl_memory_desc_create_with_tag(\n      &data_in_ncdhw, 5, dims, dnnl_f32, dnnl_ncdhw);\n\n // note that in both cases dims passed are the same\n dnnl_memory_desc_t data_in_ndhwc;\n dnnl_memory_desc_create_with_tag(\n      &data_in_ndhwc, 5, dims, dnnl_f32, dnnl_ndhwc);\n\n dnnl_memory_desc_destroy(data_in_ncdhw);\n dnnl_memory_desc_destroy(data_in_ndhwc);\n ~~~\n\n Memory format tags can be further divided into two categories:\n  - Domain-agnostic names, i.e. names the do not depend on the tensor usage\n    in the specific primitive. These names use letters from `a` to `l` to\n    denote logical dimension from 1 to 12, and form the order in which the\n    dimensions are laid in memory. For instance, #dnnl_ab is used to denote\n    2D tensor where the second logical dimension (aka `b`) is the innermost,\n    i.e. has stride = 1, and the first logical dimension (`a`) laid out in\n    memory with stride equal to the size of second dimension. On the other\n    hand, #dnnl_ba is just transposed version of the same tensor: the\n    first dimension (`a`) becomes the innermost one.\n  - Domain-specific names, i.e. names that make sense only in the context of\n    a certain domain, such as CNN. This names are just aliases to the\n    corresponding domain-agnostic tags and used mostly for the convenience.\n    For example, #dnnl_nc is used to denote 2D CNN activations tensor\n    memory format, where channels are the innermost dimension and batch is an\n    outermost one. Moreover, #dnnl_nc is just an alias to #dnnl_ab,\n    since for oneDNN CNN primitives the logical dimensions of\n    activations tensors come in order: batch, channels, spatial.\n    In other words, batch corresponds to the first logical dimension (`a`),\n    channels correspond to the second one (`b`).\n\n The following domain-specific notation applies to memory format tags:\n  - @c 'n' denotes the mini-batch dimension\n  - @c 'c' denotes a channels dimension\n  - When there are multiple channel dimensions (for example, in convolution\n    weights tensor), @c 'i' and @c 'o' denote dimensions of input and output\n    channels\n  - @c 'd', @c 'h', and @c 'w' denote spatial depth, height, and width\n    respectively\n\n Upper-case letters indicate that the data is laid out in blocks for a\n particular dimension. In such cases, the format name contains both upper-\n and lower-case letters for that dimension with a lower-case letter preceded\n by the block size. For example: #dnnl_nChw8c describes a format where the\n outermost dimension is mini-batch, followed by the channel block number,\n followed by the spatial height and width, and finally followed by 8-element\n channel blocks.\n\n @sa @ref dev_guide_understanding_memory_formats"]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " Undefined memory format tag"]
    pub const dnnl_format_tag_undef: Type = 0;
    #[doc = " Undefined memory format tag.\n The primitive selects a format automatically."]
    pub const dnnl_format_tag_any: Type = 1;
    #[doc = "< plain 1D tensor"]
    pub const dnnl_a: Type = 2;
    #[doc = "< plain 2D tensor"]
    pub const dnnl_ab: Type = 3;
    #[doc = "< plain 3D tensor"]
    pub const dnnl_abc: Type = 4;
    #[doc = "< plain 4D tensor"]
    pub const dnnl_abcd: Type = 5;
    #[doc = "< plain 5D tensor"]
    pub const dnnl_abcde: Type = 6;
    #[doc = "< plain 6D tensor"]
    pub const dnnl_abcdef: Type = 7;
    #[doc = "< plain 7D tensor"]
    pub const dnnl_abcdefg: Type = 8;
    #[doc = "< plain 8D tensor"]
    pub const dnnl_abcdefgh: Type = 9;
    #[doc = "< plain 9D tensor"]
    pub const dnnl_abcdefghi: Type = 10;
    #[doc = "< plain 10D tensor"]
    pub const dnnl_abcdefghij: Type = 11;
    #[doc = "< plain 11D tensor"]
    pub const dnnl_abcdefghijk: Type = 12;
    #[doc = "< plain 12D tensor"]
    pub const dnnl_abcdefghijkl: Type = 13;
    #[doc = "< permuted 2D tensor"]
    pub const dnnl_ba: Type = 14;
    #[doc = "< permuted 3D tensor"]
    pub const dnnl_acb: Type = 15;
    #[doc = "< permuted 3D tensor"]
    pub const dnnl_bac: Type = 16;
    #[doc = "< permuted 3D tensor"]
    pub const dnnl_bca: Type = 17;
    #[doc = "< permuted 3D tensor"]
    pub const dnnl_cab: Type = 18;
    #[doc = "< permuted 3D tensor"]
    pub const dnnl_cba: Type = 19;
    #[doc = "< permuted 4D tensor"]
    pub const dnnl_abdc: Type = 20;
    #[doc = "< permuted 4D tensor"]
    pub const dnnl_acbd: Type = 21;
    #[doc = "< permuted 4D tensor"]
    pub const dnnl_acdb: Type = 22;
    #[doc = "< permuted 4D tensor"]
    pub const dnnl_adbc: Type = 23;
    #[doc = "< permuted 4D tensor"]
    pub const dnnl_adcb: Type = 24;
    #[doc = "< permuted 4D tensor"]
    pub const dnnl_bacd: Type = 25;
    #[doc = "< permuted 4D tensor"]
    pub const dnnl_bcda: Type = 26;
    #[doc = "< permuted 4D tensor"]
    pub const dnnl_cdab: Type = 27;
    #[doc = "< permuted 4D tensor"]
    pub const dnnl_cdba: Type = 28;
    #[doc = "< permuted 4D tensor"]
    pub const dnnl_dcab: Type = 29;
    #[doc = "< permuted 5D tensor"]
    pub const dnnl_abced: Type = 30;
    #[doc = "< permuted 5D tensor"]
    pub const dnnl_abdec: Type = 31;
    #[doc = "< permuted 5D tensor"]
    pub const dnnl_acbde: Type = 32;
    #[doc = "< permuted 5D tensor"]
    pub const dnnl_acdeb: Type = 33;
    #[doc = "< permuted 5D tensor"]
    pub const dnnl_adecb: Type = 34;
    #[doc = "< permuted 5D tensor"]
    pub const dnnl_bacde: Type = 35;
    #[doc = "< permuted 5D tensor"]
    pub const dnnl_bcdea: Type = 36;
    #[doc = "< permuted 5D tensor"]
    pub const dnnl_cdeab: Type = 37;
    #[doc = "< permuted 5D tensor"]
    pub const dnnl_cdeba: Type = 38;
    #[doc = "< permuted 5D tensor"]
    pub const dnnl_decab: Type = 39;
    #[doc = "< permuted 6D tensor"]
    pub const dnnl_abcdfe: Type = 40;
    #[doc = "< permuted 6D tensor"]
    pub const dnnl_abdefc: Type = 41;
    #[doc = "< permuted 6D tensor"]
    pub const dnnl_abdfce: Type = 42;
    #[doc = "< permuted 6D tensor"]
    pub const dnnl_acbdef: Type = 43;
    #[doc = "< permuted 6D tensor"]
    pub const dnnl_adefcb: Type = 44;
    #[doc = "< permuted 6D tensor"]
    pub const dnnl_defcab: Type = 45;
    #[doc = "< permuted 7D tensor"]
    pub const dnnl_abcdegf: Type = 46;
    #[doc = "< permuted 8D tensor"]
    pub const dnnl_abcdefhg: Type = 47;
    #[doc = "< permuted 9D tensor"]
    pub const dnnl_abcdefgih: Type = 48;
    #[doc = "< permuted 10D tensor"]
    pub const dnnl_abcdefghji: Type = 49;
    #[doc = "< permuted 11D tensor"]
    pub const dnnl_abcdefghikj: Type = 50;
    #[doc = "< permuted 12D tensor"]
    pub const dnnl_abcdefghijlk: Type = 51;
    pub const dnnl_Abc16a: Type = 52;
    pub const dnnl_ABc16a16b: Type = 53;
    pub const dnnl_ABc32a32b: Type = 54;
    pub const dnnl_ABc4a4b: Type = 55;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_aBc16b: Type = 56;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_ABc16b16a: Type = 57;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_Abc4a: Type = 58;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 32"]
    pub const dnnl_aBc32b: Type = 59;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBc4b: Type = 60;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc4b16a4b: Type = 61;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc2b8a4b: Type = 62;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc16b16a4b: Type = 63;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc16b16a2b: Type = 64;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc4b4a: Type = 65;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc8a16b2a: Type = 66;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc8a8b: Type = 67;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc8a4b: Type = 68;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBc8b: Type = 69;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_ABc8b16a2b: Type = 70;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_BAc8a16b2a: Type = 71;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_ABc8b8a: Type = 72;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_Abcd16a: Type = 73;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_Abcd8a: Type = 74;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_ABcd16a16b: Type = 75;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_Abcd32a: Type = 76;
    #[doc = " 3D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_ABcd32a32b: Type = 77;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_aBcd16b: Type = 78;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_ABcd16b16a: Type = 79;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_aBCd16b16c: Type = 80;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_aBCd16c16b: Type = 81;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_Abcd4a: Type = 82;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 32"]
    pub const dnnl_aBcd32b: Type = 83;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBcd4b: Type = 84;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd4b16a4b: Type = 85;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd16b16a4b: Type = 86;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd16b16a2b: Type = 87;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd4b4a: Type = 88;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd4a4b: Type = 89;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCd2c4b2c: Type = 90;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCd4b8c2b: Type = 91;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCd4c16b4c: Type = 92;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCd2c8b4c: Type = 93;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCd16c16b4c: Type = 94;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCd16c16b2c: Type = 95;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCd4c4b: Type = 96;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCd4b4c: Type = 97;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd8a16b2a: Type = 98;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd2b8a4b: Type = 99;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd8a8b: Type = 100;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd8a4b: Type = 101;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBcd8b: Type = 102;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBCd4c8b2c: Type = 103;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_ABcd8b16a2b: Type = 104;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBCd8b16c2b: Type = 105;
    #[doc = " 4D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_BAcd8a16b2a: Type = 106;
    #[doc = " 4D tensor blocked by 1st and 2nd dimension with block size 8"]
    pub const dnnl_ABcd8b8a: Type = 107;
    #[doc = " 4D tensor blocked by 1st and 2nd dimension with block size 8"]
    pub const dnnl_aBCd8b8c: Type = 108;
    #[doc = " 4D tensor blocked by 1st and 2nd dimension with block size 8"]
    pub const dnnl_aBCd8b4c: Type = 109;
    #[doc = " 4D tensor blocked by 1st and 2nd dimension with block size 8"]
    pub const dnnl_aBCd8c16b2c: Type = 110;
    #[doc = " 4D tensor blocked by 1st and 2nd dimension with block size 8"]
    pub const dnnl_ABcde8a16b2a: Type = 111;
    #[doc = " 4D tensor blocked by 1st and 2nd dimension with block size 8"]
    pub const dnnl_aCBd8b16c2b: Type = 112;
    #[doc = " 4D tensor blocked by 1st and 2nd dimension with block size 8"]
    pub const dnnl_aBCd8c8b: Type = 113;
    #[doc = " 4D tensor blocked by 1st and 2nd dimension with block size 8"]
    pub const dnnl_Abcde16a: Type = 114;
    #[doc = " 4D tensor blocked by 1st and 2nd dimension with block size 8"]
    pub const dnnl_Abcde32a: Type = 115;
    #[doc = " 4D tensor blocked by 1st and 2nd dimension with block size 8"]
    pub const dnnl_ABcde16a16b: Type = 116;
    #[doc = " 4D tensor blocked by 1st and 2nd dimension with block size 8"]
    pub const dnnl_BAcde8a16b2a: Type = 117;
    #[doc = " 4D tensor blocked by 3rd dimension with block size 4"]
    pub const dnnl_aBCd2b4c2b: Type = 118;
    #[doc = " 5D tensor blocked by 1st dimension with block size 16"]
    pub const dnnl_ABcde4b16a4b: Type = 119;
    #[doc = " 5D tensor blocked by 1st dimension with block size 8"]
    pub const dnnl_ABcde2b8a4b: Type = 120;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_aBcde16b: Type = 121;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_ABcde16b16a: Type = 122;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_aBCde16b16c: Type = 123;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_aBCde16c16b: Type = 124;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_aBCde2c8b4c: Type = 125;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_Abcde4a: Type = 126;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 32"]
    pub const dnnl_aBcde32b: Type = 127;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBcde4b: Type = 128;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde4b4a: Type = 129;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde4a4b: Type = 130;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCde4b4c: Type = 131;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCde2c4b2c: Type = 132;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCde4b8c2b: Type = 133;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCde4c16b4c: Type = 134;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCde16c16b4c: Type = 135;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCde16c16b2c: Type = 136;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCde4c4b: Type = 137;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Abcde8a: Type = 138;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde8a8b: Type = 139;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde8a4b: Type = 140;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAcde16b16a: Type = 141;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBcde8b: Type = 142;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_ABcde8b16a2b: Type = 143;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBCde8b16c2b: Type = 144;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBCde4c8b2c: Type = 145;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aCBde8b16c2b: Type = 146;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_ABcde8b8a: Type = 147;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_ABcde32a32b: Type = 148;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBCde8b8c: Type = 149;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBCde8b4c: Type = 150;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_ABc4a8b8a4b: Type = 151;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_ABcd4a8b8a4b: Type = 152;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_ABcde4a8b8a4b: Type = 153;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_BAc4b8a8b4a: Type = 154;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_BAcd4b8a8b4a: Type = 155;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_BAcde4b8a8b4a: Type = 156;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_ABcd2a8b8a2b: Type = 157;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBCd4b8c8b4c: Type = 158;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBCde4b8c8b4c: Type = 159;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBCde2b8c8b2c: Type = 160;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBCde8c16b2c: Type = 161;
    #[doc = " 5D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBCde8c8b: Type = 162;
    #[doc = " 5D tensor blocked by 3rd dimension with block size 4"]
    pub const dnnl_aBCde2b4c2b: Type = 163;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_aBcdef16b: Type = 164;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_aBCdef16b16c: Type = 165;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_aBCdef16c16b: Type = 166;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 16"]
    pub const dnnl_aBCdef4c16b4c: Type = 167;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBCdef2c8b4c: Type = 168;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 8"]
    pub const dnnl_aBCdef4c8b2c: Type = 169;
    #[doc = " 6D tensor blocked by 3rd dimension with block size 4"]
    pub const dnnl_aBCdef2b4c2b: Type = 170;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBcdef4b: Type = 171;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef4c4b: Type = 172;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef4b4c: Type = 173;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef2c4b2c: Type = 174;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef4b8c2b: Type = 175;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef8b8c: Type = 176;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef8b4c: Type = 177;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef8c16b2c: Type = 178;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef4b8c8b4c: Type = 179;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef8b16c2b: Type = 180;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBdef8b16c2b: Type = 181;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef8c8b: Type = 182;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdc16b: Type = 183;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC16b2c: Type = 184;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC16b4c: Type = 185;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdc4b: Type = 186;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdc8b: Type = 187;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdec16b: Type = 188;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC16b2c: Type = 189;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC16b4c: Type = 190;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdec32b: Type = 191;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdec4b: Type = 192;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdec8b: Type = 193;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefc16b: Type = 194;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC16b2c: Type = 195;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBdef16c16b: Type = 196;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefc4b: Type = 197;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefc8b: Type = 198;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Abcdef16a: Type = 199;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Abcdef32a: Type = 200;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBedc16b: Type = 201;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acb16a: Type = 202;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB16a2b: Type = 203;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB16a4b: Type = 204;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acb4a: Type = 205;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acb8a: Type = 206;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBd16b16c: Type = 207;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBd16c16b: Type = 208;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBde16b16c: Type = 209;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBde16c16b: Type = 210;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acdb16a: Type = 211;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB16a2b: Type = 212;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB16a4b: Type = 213;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acdb32a: Type = 214;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acdb4a: Type = 215;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acdb8a: Type = 216;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acdeb16a: Type = 217;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB16a2b: Type = 218;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acdeb4a: Type = 219;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acdeb8a: Type = 220;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Adcb16a: Type = 221;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAc16a16b: Type = 222;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAc16b16a: Type = 223;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAcd16a16b: Type = 224;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAcd16b16a: Type = 225;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBd4c8b8c4b: Type = 226;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBde4c8b8c4b: Type = 227;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBdef4c8b8c4b: Type = 228;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAcde16a16b: Type = 229;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBdef16b16c: Type = 230;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc16b32a: Type = 231;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc16b64a: Type = 232;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc4b32a4b: Type = 233;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc4b64a4b: Type = 234;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc8b32a2b: Type = 235;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc8b64a2b: Type = 236;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB16b16a: Type = 237;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB16b32a: Type = 238;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB16b64a: Type = 239;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB8b16a2b: Type = 240;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB8b32a2b: Type = 241;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB8b64a2b: Type = 242;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB4b16a4b: Type = 243;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB4b32a4b: Type = 244;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB4b64a4b: Type = 245;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB16b16a4b: Type = 246;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd16b32a: Type = 247;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd16b64a: Type = 248;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd4b32a4b: Type = 249;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd4b64a4b: Type = 250;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd8b32a2b: Type = 251;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd8b64a2b: Type = 252;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde4b32a4b: Type = 253;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde4b64a4b: Type = 254;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde16b16a4b: Type = 255;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde16b16a2b: Type = 256;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde16b32a: Type = 257;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde16b64a: Type = 258;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde8b32a2b: Type = 259;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde8b64a2b: Type = 260;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef16c16b4c: Type = 261;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef16c16b2c: Type = 262;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB32a32b8a4b: Type = 263;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB8a4b: Type = 264;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB32a32b8a2b: Type = 265;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB8a2b: Type = 266;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abDc32d: Type = 267;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abDC32d4c: Type = 268;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abdEc32e: Type = 269;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abdEC32e2c: Type = 270;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abdEC32e4c: Type = 271;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC16b4c: Type = 272;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB16a4b: Type = 273;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd16a16b2a: Type = 274;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc16a16b2a: Type = 275;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCd16b16c2b: Type = 276;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCde16b16c2b: Type = 277;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acb32a: Type = 278;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB32a2b: Type = 279;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB32a4b: Type = 280;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acb48a: Type = 281;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB48a2b: Type = 282;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB48a4b: Type = 283;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acb64a: Type = 284;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB64a2b: Type = 285;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB64a4b: Type = 286;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_cBa2b: Type = 287;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_cBa4b: Type = 288;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdc32b: Type = 289;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC32b2c: Type = 290;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC32b4c: Type = 291;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdc48b: Type = 292;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC48b2c: Type = 293;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC48b4c: Type = 294;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdc64b: Type = 295;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC64b2c: Type = 296;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC64b4c: Type = 297;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_adCb2c: Type = 298;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_adCb4c: Type = 299;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB32a2b: Type = 300;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB32a4b: Type = 301;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acdb48a: Type = 302;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB48a2b: Type = 303;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB48a4b: Type = 304;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acdb64a: Type = 305;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB64a2b: Type = 306;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB64a4b: Type = 307;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_cdBa2b: Type = 308;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_cdBa4b: Type = 309;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC32b2c: Type = 310;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC32b4c: Type = 311;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdec48b: Type = 312;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC48b2c: Type = 313;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC48b4c: Type = 314;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdec64b: Type = 315;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC64b2c: Type = 316;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC64b4c: Type = 317;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_adeCb2c: Type = 318;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_adeCb4c: Type = 319;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acdeb32a: Type = 320;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB32a2b: Type = 321;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB32a4b: Type = 322;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acdeb48a: Type = 323;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB48a2b: Type = 324;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB48a4b: Type = 325;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acdeb64a: Type = 326;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB64a2b: Type = 327;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB64a4b: Type = 328;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_cdeBa2b: Type = 329;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_cdeBa4b: Type = 330;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefc32b: Type = 331;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC32b2c: Type = 332;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC32b4c: Type = 333;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefc48b: Type = 334;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC48b2c: Type = 335;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC48b4c: Type = 336;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefc64b: Type = 337;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC64b2c: Type = 338;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC64b4c: Type = 339;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_adefCb2c: Type = 340;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_adefCb4c: Type = 341;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB16b32a4b: Type = 342;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB16b48a4b: Type = 343;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB16b64a4b: Type = 344;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB16b16a2b: Type = 345;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB16b32a2b: Type = 346;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB16b48a2b: Type = 347;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB16b64a2b: Type = 348;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc16b32a4b: Type = 349;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc16b48a4b: Type = 350;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc16b64a4b: Type = 351;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc16b32a2b: Type = 352;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc16b48a2b: Type = 353;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc16b64a2b: Type = 354;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd16b32a4b: Type = 355;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd16b48a4b: Type = 356;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd16b64a4b: Type = 357;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd16b32a2b: Type = 358;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd16b48a2b: Type = 359;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd16b64a2b: Type = 360;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde16b32a4b: Type = 361;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde16b48a4b: Type = 362;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde16b64a4b: Type = 363;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde16b32a2b: Type = 364;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde16b48a2b: Type = 365;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde16b64a2b: Type = 366;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc32a16b: Type = 367;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd32a16b: Type = 368;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde32a16b: Type = 369;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB48a16b: Type = 370;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB48a32b: Type = 371;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc40a16b: Type = 372;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc40a32b: Type = 373;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBC48b16c: Type = 374;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBC48b32c: Type = 375;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd40a16b: Type = 376;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd40a32b: Type = 377;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abCd32c: Type = 378;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abdCe32c: Type = 379;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abdCE32c2e: Type = 380;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA16a16b2a: Type = 381;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA16a32b2a: Type = 382;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA16a48b2a: Type = 383;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA16a64b2a: Type = 384;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA16a16b4a: Type = 385;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA16a32b4a: Type = 386;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA16a48b4a: Type = 387;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA16a64b4a: Type = 388;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd8a2b: Type = 389;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC16c16b2c: Type = 390;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC16c16b4c: Type = 391;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC16c16b2c: Type = 392;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB16b16a2b: Type = 393;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB16b16a4b: Type = 394;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB16b16a2b: Type = 395;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB16b16a4b: Type = 396;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB16b16a2b: Type = 397;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC16c16b4c: Type = 398;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB16b16a4b: Type = 399;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB16b32a2b: Type = 400;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB16b32a4b: Type = 401;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB16b48a2b: Type = 402;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB16b48a4b: Type = 403;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB16b64a2b: Type = 404;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB16b64a4b: Type = 405;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC16c16b2c: Type = 406;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC16c16b4c: Type = 407;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC16c32b2c: Type = 408;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC16c32b4c: Type = 409;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC16c48b2c: Type = 410;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC16c48b4c: Type = 411;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC16c64b2c: Type = 412;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC16c64b4c: Type = 413;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB16b32a2b: Type = 414;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB16b32a4b: Type = 415;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB16b48a2b: Type = 416;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB16b48a4b: Type = 417;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB16b64a2b: Type = 418;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB16b64a4b: Type = 419;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC16c32b2c: Type = 420;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC16c32b4c: Type = 421;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC16c48b2c: Type = 422;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC16c48b4c: Type = 423;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC16c64b2c: Type = 424;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC16c64b4c: Type = 425;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB16b32a2b: Type = 426;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB16b32a4b: Type = 427;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB16b48a2b: Type = 428;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB16b48a4b: Type = 429;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB16b64a2b: Type = 430;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB16b64a4b: Type = 431;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC16c32b2c: Type = 432;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC16c32b4c: Type = 433;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC16c48b2c: Type = 434;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC16c48b4c: Type = 435;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC16c64b2c: Type = 436;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC16c64b4c: Type = 437;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_decbA16a: Type = 438;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc4a2b: Type = 439;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc8a2b: Type = 440;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCd8b2c: Type = 441;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde4a2b: Type = 442;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde8a2b: Type = 443;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde40a16b: Type = 444;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde40a32b: Type = 445;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCde8b2c: Type = 446;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde4a8b8a2b: Type = 447;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd4a8b8a2b: Type = 448;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc4a8b8a2b: Type = 449;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef4b8c8b2c: Type = 450;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCde4b8c8b2c: Type = 451;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCd4b8c8b2c: Type = 452;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAcde4b8a8b2a: Type = 453;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAcd4b8a8b2a: Type = 454;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAc4b8a8b2a: Type = 455;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBdef4c8b8c2b: Type = 456;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBde4c8b8c2b: Type = 457;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBd4c8b8c2b: Type = 458;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef8b2c: Type = 459;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB32a16b: Type = 460;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB32a32b: Type = 461;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA4b8a8b2a: Type = 462;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA4b8a8b4a: Type = 463;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBC32b16c: Type = 464;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBC32b32c: Type = 465;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB4c8b8c2b: Type = 466;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB4c8b8c4b: Type = 467;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd4a2b: Type = 468;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc2b8a16b4a: Type = 469;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd2b8a16b4a: Type = 470;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde2b8a16b4a: Type = 471;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc2a8b16a4b: Type = 472;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc2a8b16a2b: Type = 473;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc2b32a8b: Type = 474;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd2a8b16a4b: Type = 475;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd2a8b16a2b: Type = 476;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBd2c8b16c2b: Type = 477;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd2b32a8b: Type = 478;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCd2c8b16c2b: Type = 479;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde2a8b16a4b: Type = 480;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde2a8b16a2b: Type = 481;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBde2c8b16c2b: Type = 482;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde2b32a8b: Type = 483;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBC2b8c16b2c: Type = 484;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCd2b8c16b2c: Type = 485;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCde2b8c16b2c: Type = 486;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef2b8c16b2c: Type = 487;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAcde2b8a16b4a: Type = 488;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAcd2b8a16b4a: Type = 489;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAc2b8a16b4a: Type = 490;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAcde2b8a16b2a: Type = 491;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAcd2b8a16b2a: Type = 492;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAc2b8a16b2a: Type = 493;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCde2c8b16c2b: Type = 494;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef2c8b16c2b: Type = 495;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBdef2c8b16c2b: Type = 496;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCd2b8c16b4c: Type = 497;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCde2b8c16b4c: Type = 498;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA4b8a16b2a: Type = 499;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA4b8a16b4a: Type = 500;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB4c8b16c2b: Type = 501;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB4c8b16c4b: Type = 502;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA16a16b: Type = 503;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA16a32b: Type = 504;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA16a48b: Type = 505;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA16a64b: Type = 506;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB16c2b: Type = 507;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB16c4b: Type = 508;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA16b2a: Type = 509;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA16b4a: Type = 510;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBC16b16c: Type = 511;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBC16b32c: Type = 512;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB16a16b: Type = 513;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB16a32b: Type = 514;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde16a16b2a: Type = 515;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBCdef16b16c2b: Type = 516;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acedb16a: Type = 517;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdfec16b: Type = 518;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abdEC64e2c: Type = 519;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abdEC64e4c: Type = 520;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB16b16c: Type = 521;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB16b32c: Type = 522;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB16b48c: Type = 523;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB16b64c: Type = 524;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB16b16c2b: Type = 525;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB16b32c2b: Type = 526;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB16b48c2b: Type = 527;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB16b64c2b: Type = 528;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB16b16c4b: Type = 529;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB16b32c4b: Type = 530;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB16b48c4b: Type = 531;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB16b64c4b: Type = 532;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abCd4c: Type = 533;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abCde4c: Type = 534;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abCdef4c: Type = 535;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abCde32c: Type = 536;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abCdef32c: Type = 537;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd16a32b: Type = 538;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_decbA8a: Type = 539;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB16b32c2b: Type = 540;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB16b32c4b: Type = 541;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB16b48c2b: Type = 542;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB16b48c4b: Type = 543;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB16b64c2b: Type = 544;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB16b64c4b: Type = 545;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA16a32b2a: Type = 546;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA16a32b4a: Type = 547;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA16a48b2a: Type = 548;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA16a48b4a: Type = 549;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA16a64b2a: Type = 550;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA16a64b4a: Type = 551;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefb32c: Type = 552;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB32c2b: Type = 553;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB32c4b: Type = 554;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefb48c: Type = 555;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB48c2b: Type = 556;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB48c4b: Type = 557;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefb64c: Type = 558;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB64c2b: Type = 559;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB64c4b: Type = 560;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bcdea32b: Type = 561;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA32b2a: Type = 562;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA32b4a: Type = 563;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bcdea48b: Type = 564;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA48b2a: Type = 565;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA48b4a: Type = 566;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bcdea64b: Type = 567;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA64b2a: Type = 568;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA64b4a: Type = 569;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bca32b: Type = 570;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA32b2a: Type = 571;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA32b4a: Type = 572;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bca48b: Type = 573;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA48b2a: Type = 574;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA48b4a: Type = 575;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bca64b: Type = 576;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA64b2a: Type = 577;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA64b4a: Type = 578;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdb32c: Type = 579;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB32c2b: Type = 580;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB32c4b: Type = 581;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdb48c: Type = 582;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB48c2b: Type = 583;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB48c4b: Type = 584;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdb64c: Type = 585;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB64c2b: Type = 586;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB64c4b: Type = 587;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA16a16b2a: Type = 588;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA16a16b4a: Type = 589;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA16a16b2a: Type = 590;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA16a16b4a: Type = 591;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA16a16b2a: Type = 592;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA16a16b4a: Type = 593;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB16b16c2b: Type = 594;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB16b16c4b: Type = 595;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB16b16c2b: Type = 596;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB16b16c4b: Type = 597;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB16b16c2b: Type = 598;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB16b16c4b: Type = 599;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA16a32b2a: Type = 600;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA16a32b4a: Type = 601;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA16a48b2a: Type = 602;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA16a48b4a: Type = 603;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA16a64b2a: Type = 604;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA16a64b4a: Type = 605;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB16b32c2b: Type = 606;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB16b32c4b: Type = 607;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB16b48c2b: Type = 608;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB16b48c4b: Type = 609;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB16b64c2b: Type = 610;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB16b64c4b: Type = 611;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA16a32b2a: Type = 612;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA16a32b4a: Type = 613;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA16a48b2a: Type = 614;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA16a48b4a: Type = 615;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA16a64b2a: Type = 616;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA16a64b4a: Type = 617;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB16b32c2b: Type = 618;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB16b32c4b: Type = 619;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB16b48c2b: Type = 620;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB16b48c4b: Type = 621;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB16b64c2b: Type = 622;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB16b64c4b: Type = 623;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bca16b: Type = 624;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA16b2a: Type = 625;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA16b4a: Type = 626;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bcda16b: Type = 627;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA16b2a: Type = 628;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA16b4a: Type = 629;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bcdea16b: Type = 630;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA16b2a: Type = 631;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA16b4a: Type = 632;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdb16c: Type = 633;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB16c2b: Type = 634;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB16c4b: Type = 635;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeb16c: Type = 636;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB16c2b: Type = 637;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB16c4b: Type = 638;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefb16c: Type = 639;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB16c2b: Type = 640;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB16c4b: Type = 641;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bcda32b: Type = 642;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA32b2a: Type = 643;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA32b4a: Type = 644;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bcda48b: Type = 645;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA48b2a: Type = 646;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA48b4a: Type = 647;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bcda64b: Type = 648;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA64b2a: Type = 649;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA64b4a: Type = 650;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeb32c: Type = 651;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB32c2b: Type = 652;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB32c4b: Type = 653;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeb48c: Type = 654;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB48c2b: Type = 655;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB48c4b: Type = 656;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeb64c: Type = 657;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB64c2b: Type = 658;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB64c4b: Type = 659;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acb24a: Type = 660;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acdb24a: Type = 661;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Acdeb24a: Type = 662;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdc24b: Type = 663;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdec24b: Type = 664;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefc24b: Type = 665;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abDc16d: Type = 666;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abdEc16e: Type = 667;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abdCe16c: Type = 668;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB24a2b: Type = 669;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB24a2b: Type = 670;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB24a2b: Type = 671;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC24b2c: Type = 672;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC24b2c: Type = 673;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC24b2c: Type = 674;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB8a2b: Type = 675;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB8a2b: Type = 676;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB8a2b: Type = 677;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC8b2c: Type = 678;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC8b2c: Type = 679;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC8b2c: Type = 680;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB8b32a: Type = 681;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc8b32a: Type = 682;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd8b32a: Type = 683;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde8b32a: Type = 684;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB8b24a: Type = 685;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc8b24a: Type = 686;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd8b24a: Type = 687;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde8b24a: Type = 688;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB8b16a: Type = 689;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc8b16a: Type = 690;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd8b16a: Type = 691;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde8b16a: Type = 692;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB8b8a: Type = 693;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB4b8a4b: Type = 694;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB4b24a4b: Type = 695;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc4b8a4b: Type = 696;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc4b24a4b: Type = 697;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd4b8a4b: Type = 698;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd4b24a4b: Type = 699;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde4b8a4b: Type = 700;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde4b24a4b: Type = 701;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB8b24a2b: Type = 702;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc8b24a2b: Type = 703;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd8b24a2b: Type = 704;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde8b24a2b: Type = 705;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB8b8a2b: Type = 706;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc8b8a2b: Type = 707;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd8b8a2b: Type = 708;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde8b8a2b: Type = 709;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB24a4b: Type = 710;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB24a4b: Type = 711;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB24a4b: Type = 712;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC24b4c: Type = 713;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC24b4c: Type = 714;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC24b4c: Type = 715;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB8a4b: Type = 716;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB8a4b: Type = 717;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB8a4b: Type = 718;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdC8b4c: Type = 719;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdeC8b4c: Type = 720;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aBdefC8b4c: Type = 721;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bca8b: Type = 722;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA8b2a: Type = 723;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bcda8b: Type = 724;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA8b2a: Type = 725;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bcdea8b: Type = 726;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA8b2a: Type = 727;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdb8c: Type = 728;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB8c2b: Type = 729;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeb8c: Type = 730;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB8c2b: Type = 731;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefb8c: Type = 732;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB8c2b: Type = 733;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bca24b: Type = 734;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA24b2a: Type = 735;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bcda24b: Type = 736;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA24b2a: Type = 737;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Bcdea24b: Type = 738;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA24b2a: Type = 739;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdb24c: Type = 740;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB24c2b: Type = 741;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeb24c: Type = 742;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB24c2b: Type = 743;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefb24c: Type = 744;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB24c2b: Type = 745;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA8b4a: Type = 746;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA8b4a: Type = 747;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA8b4a: Type = 748;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB8c4b: Type = 749;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB8c4b: Type = 750;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB8c4b: Type = 751;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcA24b4a: Type = 752;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdA24b4a: Type = 753;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BcdeA24b4a: Type = 754;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdB24c4b: Type = 755;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdeB24c4b: Type = 756;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCdefB24c4b: Type = 757;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AB16b48a: Type = 758;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc16b48a: Type = 759;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd16b48a: Type = 760;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde16b48a: Type = 761;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABc16a4b: Type = 762;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcd16a4b: Type = 763;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_ABcde16a4b: Type = 764;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_defcbA16a: Type = 765;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_defcbA8a: Type = 766;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB16b64a: Type = 767;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB16b64a: Type = 768;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB16b64a: Type = 769;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB16b48a: Type = 770;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB16b48a: Type = 771;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB16b48a: Type = 772;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB16b32a: Type = 773;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB16b32a: Type = 774;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB16b32a: Type = 775;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB16b16a: Type = 776;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB16b16a: Type = 777;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB16b16a: Type = 778;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB8b32a: Type = 779;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB8b32a: Type = 780;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB8b32a: Type = 781;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB8b24a: Type = 782;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB8b24a: Type = 783;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB8b24a: Type = 784;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB8b16a: Type = 785;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB8b16a: Type = 786;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB8b16a: Type = 787;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB8b8a: Type = 788;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB8b8a: Type = 789;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB8b8a: Type = 790;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB8b64a2b: Type = 791;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB8b64a2b: Type = 792;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB8b64a2b: Type = 793;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB8b32a2b: Type = 794;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB8b32a2b: Type = 795;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB8b32a2b: Type = 796;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB8b24a2b: Type = 797;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB8b24a2b: Type = 798;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB8b24a2b: Type = 799;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB8b16a2b: Type = 800;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB8b16a2b: Type = 801;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB8b16a2b: Type = 802;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB8b8a2b: Type = 803;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB8b8a2b: Type = 804;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB8b8a2b: Type = 805;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB4b64a4b: Type = 806;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB4b64a4b: Type = 807;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB4b64a4b: Type = 808;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB4b32a4b: Type = 809;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB4b32a4b: Type = 810;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB4b32a4b: Type = 811;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB4b24a4b: Type = 812;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB4b24a4b: Type = 813;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB4b24a4b: Type = 814;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB4b16a4b: Type = 815;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB4b16a4b: Type = 816;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB4b16a4b: Type = 817;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcB4b8a4b: Type = 818;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdB4b8a4b: Type = 819;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_AcdeB4b8a4b: Type = 820;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Ab4a: Type = 821;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Ab8a: Type = 822;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA4b4a: Type = 823;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA8b4a: Type = 824;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA2a24b: Type = 825;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB2b24c: Type = 826;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA2a8b: Type = 827;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB2b8c: Type = 828;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA8a24b: Type = 829;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB8b24c: Type = 830;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA8a16b: Type = 831;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB8b16c: Type = 832;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA8a8b: Type = 833;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB8b8c: Type = 834;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_bcad: Type = 835;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_cabd: Type = 836;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_dabc: Type = 837;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_Ab32a: Type = 838;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBd8b8c: Type = 839;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBde8b8c: Type = 840;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAc8a8b: Type = 841;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAcd8a8b: Type = 842;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BAcde8a8b: Type = 843;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCBdef8b8c: Type = 844;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abdEC16e4c: Type = 845;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abDC16d4c: Type = 846;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_BA24b8a: Type = 847;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_aCB24c8b: Type = 848;
    #[doc = " 6D tensor blocked by 2nd dimension with block size 4"]
    pub const dnnl_abDC24d8c: Type = 849;
    #[doc = " Just a sentinel, not real memory format tag. Must be changed after new\n format tag is added."]
    pub const dnnl_format_tag_last: Type = 850;
    #[doc = " 1D tensor, an alias to #dnnl_a"]
    pub const dnnl_x: Type = 2;
    #[doc = " 2D CNN activations tensor, an alias to #dnnl_ab"]
    pub const dnnl_nc: Type = 3;
    #[doc = " 2D CNN activations tensor, an alias to #dnnl_ba"]
    pub const dnnl_cn: Type = 14;
    #[doc = " 2D RNN statistics tensor, an alias to #dnnl_ab"]
    pub const dnnl_tn: Type = 3;
    #[doc = " 2D RNN statistics tensor, an alias to #dnnl_ba"]
    pub const dnnl_nt: Type = 14;
    #[doc = " 3D CNN activations tensor, an alias to #dnnl_abc"]
    pub const dnnl_ncw: Type = 4;
    #[doc = " 3D CNN activations tensor, an alias to #dnnl_acb"]
    pub const dnnl_nwc: Type = 15;
    #[doc = " 4D CNN activations tensor, an alias to #dnnl_abcd"]
    pub const dnnl_nchw: Type = 5;
    #[doc = " 4D CNN activations tensor, an alias to #dnnl_acdb"]
    pub const dnnl_nhwc: Type = 22;
    #[doc = " 4D CNN activations tensor, an alias to #dnnl_bcda"]
    pub const dnnl_chwn: Type = 26;
    #[doc = " 5D CNN activations tensor, an alias to #dnnl_abcde"]
    pub const dnnl_ncdhw: Type = 6;
    #[doc = " 5D CNN activations tensor, an alias to #dnnl_acdeb"]
    pub const dnnl_ndhwc: Type = 33;
    #[doc = " 2D CNN weights tensor, an alias to #dnnl_ab"]
    pub const dnnl_oi: Type = 3;
    #[doc = " 2D CNN weights tensor, an alias to #dnnl_ba"]
    pub const dnnl_io: Type = 14;
    #[doc = " 3D CNN weights tensor, an alias to #dnnl_abc"]
    pub const dnnl_oiw: Type = 4;
    #[doc = " 3D CNN weights tensor, an alias to #dnnl_acb"]
    pub const dnnl_owi: Type = 15;
    #[doc = " 3D CNN weights tensor, an alias to #dnnl_cba"]
    pub const dnnl_wio: Type = 19;
    #[doc = " 3D CNN weights tensor, an alias to #dnnl_cab"]
    pub const dnnl_woi: Type = 18;
    #[doc = " 3D CNN weights tensor, an alias to #dnnl_bca"]
    pub const dnnl_iwo: Type = 17;
    #[doc = " 4D CNN weights tensor, an alias to #dnnl_abcd"]
    pub const dnnl_oihw: Type = 5;
    #[doc = " 4D CNN weights tensor, an alias to #dnnl_cdba"]
    pub const dnnl_hwio: Type = 28;
    #[doc = " 4D CNN weights tensor, an alias to #dnnl_cdab"]
    pub const dnnl_hwoi: Type = 27;
    #[doc = " 4D CNN weights tensor, an alias to #dnnl_acdb"]
    pub const dnnl_ohwi: Type = 22;
    #[doc = " 4D CNN weights tensor, an alias to #dnnl_bcda"]
    pub const dnnl_ihwo: Type = 26;
    #[doc = " 4D CNN weights tensor, an alias to #dnnl_bacd"]
    pub const dnnl_iohw: Type = 25;
    #[doc = " 5D CNN weights tensor, an alias to #dnnl_abcde"]
    pub const dnnl_oidhw: Type = 6;
    #[doc = " 5D CNN weights tensor, an alias to #dnnl_bacde"]
    pub const dnnl_iodhw: Type = 35;
    #[doc = " 5D CNN weights tensor, an alias to #dnnl_cdeba"]
    pub const dnnl_dhwio: Type = 38;
    #[doc = " 5D CNN weights tensor, an alias to #dnnl_cdeab"]
    pub const dnnl_dhwoi: Type = 37;
    #[doc = " 5D CNN weights tensor, an alias to #dnnl_acdeb"]
    pub const dnnl_odhwi: Type = 33;
    #[doc = " 5D CNN weights tensor, an alias to #dnnl_bcdea"]
    pub const dnnl_idhwo: Type = 36;
    #[doc = " 4D CNN weights tensor (incl. groups), an alias to #dnnl_abcd"]
    pub const dnnl_goiw: Type = 5;
    #[doc = " 4D CNN weights tensor (incl. groups), an alias to #dnnl_abdc"]
    pub const dnnl_gowi: Type = 20;
    #[doc = " 4D CNN weights tensor (incl. groups), an alias to #dnnl_dcab"]
    pub const dnnl_wigo: Type = 29;
    #[doc = " 5D CNN weights tensor (incl. groups), an alias to #dnnl_abcde"]
    pub const dnnl_goihw: Type = 6;
    #[doc = " 5D CNN weights tensor (incl. groups), an alias to #dnnl_abdec"]
    pub const dnnl_gohwi: Type = 31;
    #[doc = " 5D CNN weights tensor (incl. groups), an alias to #dnnl_decab"]
    pub const dnnl_hwigo: Type = 39;
    #[doc = " 5D CNN weights tensor (incl. groups), an alias to #dnnl_acbde"]
    pub const dnnl_giohw: Type = 32;
    #[doc = " 6D CNN weights tensor (incl. groups), an alias to #dnnl_abcdef"]
    pub const dnnl_goidhw: Type = 7;
    #[doc = " 6D CNN weights tensor (incl. groups), an alias to #dnnl_abdefc"]
    pub const dnnl_godhwi: Type = 41;
    #[doc = " 6D CNN weights tensor (incl. groups), an alias to #dnnl_acbdef"]
    pub const dnnl_giodhw: Type = 43;
    #[doc = " 6D CNN weights tensor (incl. groups), an alias to #dnnl_defcab"]
    pub const dnnl_dhwigo: Type = 45;
    #[doc = " 3D RNN data tensor in the format (seq_length, batch, input channels),\n an alias to #dnnl_abc."]
    pub const dnnl_tnc: Type = 4;
    #[doc = " 3D RNN data tensor in the format (batch, seq_length, input channels),\n an alias to #dnnl_bac."]
    pub const dnnl_ntc: Type = 16;
    #[doc = " 4D RNN states tensor in the format (num_layers, num_directions,\n batch, state channels), an alias to #dnnl_abcd."]
    pub const dnnl_ldnc: Type = 5;
    #[doc = " 5D RNN weights tensor in the format (num_layers, num_directions,\n input_channels, num_gates, output_channels), an alias to #dnnl_abcde.\n\n  - For LSTM cells, the gates order is input, forget, candidate\n    and output gate.\n  - For GRU cells, the gates order is update, reset and output gate."]
    pub const dnnl_ldigo: Type = 6;
    #[doc = " 5D RNN weights tensor in the format (num_layers, num_directions,\n num_gates, output_channels, input_channels), an alias to #dnnl_abdec.\n\n  - For LSTM cells, the gates order is input, forget, candidate\n    and output gate.\n  - For GRU cells, the gates order is update, reset and output gate."]
    pub const dnnl_ldgoi: Type = 31;
    #[doc = " 4D LSTM projection tensor in the format (num_layers, num_directions,\n num_channels_in_hidden_state, num_channels_in_recurrent_projection),\n an alias to #dnnl_abcd."]
    pub const dnnl_ldio: Type = 5;
    #[doc = " 4D LSTM projection tensor in the format (num_layers, num_directions,\n num_channels_in_recurrent_projection, num_channels_in_hidden_state),\n an alias to #dnnl_abdc."]
    pub const dnnl_ldoi: Type = 20;
    #[doc = " 4D RNN bias tensor in the format (num_layers, num_directions,\n num_gates, output_channels), an alias to #dnnl_abcd.\n\n  - For LSTM cells, the gates order is input, forget, candidate\n    and output gate.\n  - For GRU cells, the gates order is update, reset and output gate."]
    pub const dnnl_ldgo: Type = 5;
    #[doc = " 5D LSTM projection tensor"]
    pub const dnnl_ldOi16o: Type = 666;
    #[doc = " 5D LSTM projection tensor"]
    pub const dnnl_ldOi32o: Type = 267;
    #[doc = " 5D LSTM projection tensor"]
    pub const dnnl_ldOI16o4i: Type = 846;
    #[doc = " 5D LSTM projection tensor"]
    pub const dnnl_ldOI32o4i: Type = 268;
    #[doc = " 5D LSTM projection tensor"]
    pub const dnnl_ldIo32i: Type = 378;
    #[doc = " 6D RNN weights tensor"]
    pub const dnnl_ldgOi16o: Type = 667;
    #[doc = " 6D RNN weights tensor"]
    pub const dnnl_ldgOI16o4i: Type = 845;
    #[doc = " 6D RNN weights tensor"]
    pub const dnnl_ldgOi32o: Type = 269;
    #[doc = " 6D RNN weights tensor"]
    pub const dnnl_ldgOI32o2i: Type = 270;
    #[doc = " 6D RNN weights tensor"]
    pub const dnnl_ldgOI32o4i: Type = 271;
    #[doc = " 6D RNN weights tensor"]
    pub const dnnl_ldgOI64o2i: Type = 519;
    #[doc = " 6D RNN weights tensor"]
    pub const dnnl_ldgOI64o4i: Type = 520;
    #[doc = " 6D RNN weights tensor"]
    pub const dnnl_ldgIo16i: Type = 668;
    #[doc = " 6D RNN weights tensor"]
    pub const dnnl_ldgIo32i: Type = 379;
    #[doc = " 6D RNN weights tensor"]
    pub const dnnl_ldgIO32i2o: Type = 380;
    #[doc = " 5D CNN activations tensor blocked by channels with block size 32,\n an alias to #dnnl_aBcde32b"]
    pub const dnnl_nCdhw32c: Type = 127;
    #[doc = " 5D CNN activations tensor blocked by channels with block size 16,\n an alias to #dnnl_aBcde16b"]
    pub const dnnl_nCdhw16c: Type = 121;
    #[doc = " 5D CNN activations tensor blocked by channels with block size 4,\n an alias to #dnnl_aBcde4b"]
    pub const dnnl_nCdhw4c: Type = 128;
    #[doc = " 5D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBcde8b"]
    pub const dnnl_nCdhw8c: Type = 142;
    #[doc = " 4D CNN activations tensor blocked by channels with block size 32,\n an alias to #dnnl_aBcd32b"]
    pub const dnnl_nChw32c: Type = 83;
    #[doc = " 4D CNN activations tensor blocked by channels with block size 16,\n an alias to #dnnl_aBcd16b"]
    pub const dnnl_nChw16c: Type = 78;
    #[doc = " 4D CNN activations tensor blocked by channels with block size 4,\n an alias to #dnnl_aBcd4b"]
    pub const dnnl_nChw4c: Type = 84;
    #[doc = " 4D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBcd8b"]
    pub const dnnl_nChw8c: Type = 102;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 32,\n an alias to #dnnl_aBc32b"]
    pub const dnnl_nCw32c: Type = 59;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 16,\n an alias to #dnnl_aBc16b"]
    pub const dnnl_nCw16c: Type = 56;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 4,\n an alias to #dnnl_aBc4b"]
    pub const dnnl_nCw4c: Type = 60;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_nCw8c: Type = 69;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NCw16n16c: Type = 53;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NCdhw16n16c: Type = 116;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NChw16n16c: Type = 75;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NCw32n16c: Type = 367;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NChw32n16c: Type = 368;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NChw16n32c: Type = 538;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NCdhw32n16c: Type = 369;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NCw32n32c: Type = 54;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NChw32n32c: Type = 77;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NCdhw32n32c: Type = 148;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI16i16o: Type = 237;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI16i32o: Type = 238;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI16i48o: Type = 758;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI16i64o: Type = 239;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI8i8o2i: Type = 706;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI8i16o2i: Type = 240;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI8i24o2i: Type = 702;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI8i32o2i: Type = 241;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI8i64o2i: Type = 242;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI4i8o4i: Type = 694;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI4i16o4i: Type = 243;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI4i24o4i: Type = 695;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI4i32o4i: Type = 244;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI4i64o4i: Type = 245;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI16i16o4i: Type = 246;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI8i32o: Type = 681;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI8i24o: Type = 685;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI8i16o: Type = 689;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI8i8o: Type = 693;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOw8o8i: Type = 841;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOw16o16i: Type = 222;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOw16i16o: Type = 223;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw16i16o: Type = 57;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI16i16o: Type = 776;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw16i32o: Type = 231;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI16i32o: Type = 773;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw16i48o: Type = 759;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI16i48o: Type = 770;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw16i64o: Type = 232;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI16i64o: Type = 767;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw16o16i: Type = 53;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Oiw16o: Type = 52;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw4i8o4i: Type = 696;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI4i8o4i: Type = 818;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw4i16o4i: Type = 61;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI4i16o4i: Type = 815;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw4i24o4i: Type = 697;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI4i24o4i: Type = 812;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw4i32o4i: Type = 233;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI4i32o4i: Type = 809;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw4i64o4i: Type = 234;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI4i64o4i: Type = 806;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw2i8o4i: Type = 62;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw16i16o4i: Type = 63;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw16i16o2i: Type = 64;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw16o16i2o: Type = 275;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw4i4o: Type = 65;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw4o4i: Type = 55;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Oiw4o: Type = 58;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw8i8o2i: Type = 707;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI8i8o2i: Type = 803;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw8i16o2i: Type = 70;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI8i16o2i: Type = 800;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw8i24o2i: Type = 703;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI8i24o2i: Type = 797;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw8i32o2i: Type = 235;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI8i32o2i: Type = 794;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw8i64o2i: Type = 236;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI8i64o2i: Type = 791;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw8i8o: Type = 72;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI8i8o: Type = 788;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw8o16i2o: Type = 66;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOw8o16i2o: Type = 71;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw8o8i: Type = 67;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw8o4i: Type = 68;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Owi16o: Type = 202;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI16o2i: Type = 203;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI16o4i: Type = 204;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Iwo8i: Type = 722;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO8i2o: Type = 723;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO8i4o: Type = 746;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Iwo16i: Type = 624;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO16i2o: Type = 625;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO16i4o: Type = 626;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Iwo24i: Type = 734;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO24i2o: Type = 735;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO24i4o: Type = 752;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Owi4o: Type = 205;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Owi8o: Type = 206;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI8o2i: Type = 675;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw8i32o: Type = 682;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI8i32o: Type = 779;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw8i24o: Type = 686;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI8i24o: Type = 782;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw8i16o: Type = 690;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI8i16o: Type = 785;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI8o4i: Type = 716;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOhw16i16o: Type = 225;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOhw8o8i: Type = 842;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOhw16o16i: Type = 224;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Ohwi16o: Type = 211;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI16o2i: Type = 212;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI16o4i: Type = 213;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Ihwo8i: Type = 724;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO8i2o: Type = 725;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO8i4o: Type = 747;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Ihwo16i: Type = 627;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO16i2o: Type = 628;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO16i4o: Type = 629;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Ihwo24i: Type = 736;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO24i2o: Type = 737;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO24i4o: Type = 753;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Ohwi24o: Type = 661;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Ohwi32o: Type = 214;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Ohwi4o: Type = 215;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Ohwi8o: Type = 216;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI8o2i: Type = 676;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI8o4i: Type = 717;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw16i16o: Type = 79;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI16i16o: Type = 777;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw16i32o: Type = 247;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI16i32o: Type = 774;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw16i48o: Type = 760;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI16i48o: Type = 771;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw16i64o: Type = 248;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI16i64o: Type = 768;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw16o16i: Type = 75;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Oihw16o: Type = 73;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw4i8o4i: Type = 698;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI4i8o4i: Type = 819;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw4i16o4i: Type = 85;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI4i16o4i: Type = 816;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw4i24o4i: Type = 699;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI4i24o4i: Type = 813;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw4i32o4i: Type = 249;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI4i32o4i: Type = 810;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw4i64o4i: Type = 250;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI4i64o4i: Type = 807;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw16i16o4i: Type = 86;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw16i16o2i: Type = 87;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw16o16i2o: Type = 274;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw4i4o: Type = 88;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw4o4i: Type = 89;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Oihw4o: Type = 82;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw8i8o2i: Type = 708;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI8i8o2i: Type = 804;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw8i16o2i: Type = 104;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI8i16o2i: Type = 801;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw8i32o2i: Type = 251;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI8i32o2i: Type = 795;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw8i24o2i: Type = 704;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI8i24o2i: Type = 798;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw8i64o2i: Type = 252;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI8i64o2i: Type = 792;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw8i8o: Type = 107;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI8i8o: Type = 789;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw8o16i2o: Type = 98;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw2i8o4i: Type = 99;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOhw8o16i2o: Type = 106;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw8o8i: Type = 100;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw8o4i: Type = 101;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Owhi16o: Type = 221;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw8i32o: Type = 683;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI8i32o: Type = 780;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw8i24o: Type = 687;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI8i24o: Type = 783;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw8i16o: Type = 691;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI8i16o: Type = 786;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Odhwi16o: Type = 217;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI16o2i: Type = 218;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI16o4i: Type = 273;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Idhwo8i: Type = 726;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO8i2o: Type = 727;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO8i4o: Type = 748;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Idhwo16i: Type = 630;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO16i2o: Type = 631;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO16i4o: Type = 632;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Idhwo24i: Type = 738;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO24i2o: Type = 739;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO24i4o: Type = 754;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Odhwi4o: Type = 219;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Odhwi8o: Type = 220;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI8o2i: Type = 677;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI8o4i: Type = 718;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Odwhi16o: Type = 517;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw16i16o: Type = 122;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI16i16o: Type = 778;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw16i32o: Type = 257;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI16i32o: Type = 775;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw16i48o: Type = 761;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI16i48o: Type = 772;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw16i64o: Type = 258;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI16i64o: Type = 769;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw16o16i: Type = 116;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Oidhw16o: Type = 114;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw4i4o: Type = 129;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw4o4i: Type = 130;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Oidhw4o: Type = 126;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw8i8o2i: Type = 709;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI8i8o2i: Type = 805;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw8i16o2i: Type = 143;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI8i16o2i: Type = 802;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw8i32o2i: Type = 259;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI8i32o2i: Type = 796;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw8i24o2i: Type = 705;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI8i24o2i: Type = 799;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw8i64o2i: Type = 260;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI8i64o2i: Type = 793;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw8i8o: Type = 147;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI8i8o: Type = 790;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw8o16i2o: Type = 111;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOdhw8o16i2o: Type = 117;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw4i8o4i: Type = 700;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI4i8o4i: Type = 820;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw4i16o4i: Type = 119;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI4i16o4i: Type = 817;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw4i24o4i: Type = 701;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI4i24o4i: Type = 814;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw4i32o4i: Type = 253;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI4i32o4i: Type = 811;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw4i64o4i: Type = 254;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI4i64o4i: Type = 808;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw16i16o4i: Type = 255;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw16i16o2i: Type = 256;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw2i8o4i: Type = 120;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw8o8i: Type = 139;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw8o4i: Type = 140;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOdhw16i16o: Type = 141;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw4o8i8o4i: Type = 153;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOdhw8o8i: Type = 843;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOdhw16o16i: Type = 229;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw16o16i2o: Type = 515;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw8i32o: Type = 684;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI8i32o: Type = 781;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw8i24o: Type = 688;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI8i24o: Type = 784;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw8i16o: Type = 692;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI8i16o: Type = 787;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Goiw16g: Type = 73;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Goiw8g: Type = 74;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Goiw4g: Type = 82;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOw8o8i: Type = 839;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOw16o16i: Type = 207;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOw16i16o: Type = 208;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw16i16o: Type = 81;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw16o16i: Type = 80;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOiw16o: Type = 78;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw4i16o4i: Type = 92;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw2i8o4i: Type = 93;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw16i16o4i: Type = 94;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw16i16o2i: Type = 95;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw16o16i2o: Type = 276;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw4i4o: Type = 96;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw4o4i: Type = 97;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOiw4o: Type = 84;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw8i16o2i: Type = 110;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw8i8o: Type = 113;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw8o16i2o: Type = 105;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOw8o16i2o: Type = 112;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw8o8i: Type = 108;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw8o4i: Type = 109;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwi16o: Type = 183;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI16o2i: Type = 184;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI16o4i: Type = 185;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwo8i: Type = 728;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO8i2o: Type = 729;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO8i4o: Type = 749;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwo16i: Type = 633;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO16i2o: Type = 634;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO16i4o: Type = 635;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwo24i: Type = 740;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO24i2o: Type = 741;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO24i4o: Type = 755;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwi4o: Type = 186;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwi8o: Type = 187;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI8o2i: Type = 678;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI8o4i: Type = 719;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Goiw32g: Type = 76;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw2i4o2i: Type = 90;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw2o4i2o: Type = 118;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw4i8o2i: Type = 103;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw4o8i2o: Type = 91;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_goIw4i: Type = 533;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_goIw32i: Type = 378;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOhw16i16o: Type = 210;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOhw8o8i: Type = 840;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOhw16o16i: Type = 209;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwi16o: Type = 188;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI16o2i: Type = 189;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI16o4i: Type = 190;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwo8i: Type = 730;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO8i2o: Type = 731;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO8i4o: Type = 750;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwo16i: Type = 636;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO16i2o: Type = 637;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO16i4o: Type = 638;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwo24i: Type = 742;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO24i2o: Type = 743;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO24i4o: Type = 756;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwi32o: Type = 191;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwi24o: Type = 664;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI24o2i: Type = 673;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI24o4i: Type = 714;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwi4o: Type = 192;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwi8o: Type = 193;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI8o2i: Type = 679;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI8o4i: Type = 720;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Goihw16g: Type = 114;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw16i16o: Type = 124;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw16o16i: Type = 123;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOihw16o: Type = 121;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw2i8o4i: Type = 125;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw4i16o4i: Type = 134;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw16i16o4i: Type = 135;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw16i16o2i: Type = 136;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw16o16i2o: Type = 277;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw4i4o: Type = 137;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw4o4i: Type = 131;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOihw4o: Type = 128;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Goihw8g: Type = 138;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Goihw4g: Type = 126;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw8i16o2i: Type = 161;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw8i8o: Type = 162;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw8o16i2o: Type = 144;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOhw8o16i2o: Type = 146;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw8o8i: Type = 149;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw8o4i: Type = 150;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Goihw32g: Type = 115;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwhi16o: Type = 201;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_goIhw4i: Type = 534;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_goIhw32i: Type = 536;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw4o8i8o4i: Type = 151;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw4o8i8o4i: Type = 152;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOw4i8o8i4o: Type = 154;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOhw4i8o8i4o: Type = 155;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOdhw4i8o8i4o: Type = 156;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw2o8i8o2i: Type = 157;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw4o8i8o4i: Type = 158;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw4o8i8o4i: Type = 159;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw4o8i8o4i: Type = 179;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOw4i8o8i4o: Type = 226;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOhw4i8o8i4o: Type = 227;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOdhw4i8o8i4o: Type = 228;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw2o8i8o2i: Type = 160;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw2i4o2i: Type = 132;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw2o4i2o: Type = 163;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw4i8o2i: Type = 145;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw4o8i2o: Type = 133;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOdhw16i16o: Type = 196;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOdhw8o8i: Type = 844;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOdhw16o16i: Type = 230;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwi16o: Type = 194;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI16o2i: Type = 195;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI16o4i: Type = 272;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwo8i: Type = 732;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO8i2o: Type = 733;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO8i4o: Type = 751;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwo16i: Type = 639;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO16i2o: Type = 640;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO16i4o: Type = 641;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwo24i: Type = 744;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO24i2o: Type = 745;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO24i4o: Type = 757;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwi4o: Type = 197;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwi8o: Type = 198;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI8o2i: Type = 680;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI8o4i: Type = 721;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdwhi16o: Type = 518;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw16i16o: Type = 166;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw4i16o4i: Type = 167;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw16i16o4i: Type = 261;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw2i8o4i: Type = 168;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw16i16o2i: Type = 262;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw16o16i: Type = 165;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw16o16i2o: Type = 516;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOidhw16o: Type = 164;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw4i4o: Type = 172;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw4o4i: Type = 173;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOidhw4o: Type = 171;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw8i16o2i: Type = 178;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw8i8o: Type = 182;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw8o16i2o: Type = 180;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOdhw8o16i2o: Type = 181;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw8o8i: Type = 176;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw8o4i: Type = 177;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Goidhw16g: Type = 199;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Goidhw32g: Type = 200;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw2i4o2i: Type = 174;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw4i8o2i: Type = 169;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw2o4i2o: Type = 170;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw4o8i2o: Type = 175;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_goIdhw4i: Type = 535;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_goIdhw32i: Type = 537;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Owi24o: Type = 660;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI24o2i: Type = 669;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI24o4i: Type = 710;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Owi32o: Type = 278;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI32o2i: Type = 279;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI32o4i: Type = 280;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Owi48o: Type = 281;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI48o2i: Type = 282;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI48o4i: Type = 283;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Owi64o: Type = 284;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI64o2i: Type = 285;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI64o4i: Type = 286;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Iwo32i: Type = 570;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO32i2o: Type = 571;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO32i4o: Type = 572;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Iwo48i: Type = 573;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO48i2o: Type = 574;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO48i4o: Type = 575;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Iwo64i: Type = 576;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO64i2o: Type = 577;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO64i4o: Type = 578;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_wIo2i: Type = 287;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_wIo4i: Type = 288;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwi24o: Type = 663;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI24o2i: Type = 672;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI24o4i: Type = 713;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwi32o: Type = 289;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI32o2i: Type = 290;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI32o4i: Type = 291;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwi48o: Type = 292;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI48o2i: Type = 293;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI48o4i: Type = 294;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwi64o: Type = 295;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI64o2i: Type = 296;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI64o4i: Type = 297;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwo32i: Type = 579;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO32i2o: Type = 580;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO32i4o: Type = 581;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwo48i: Type = 582;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO48i2o: Type = 583;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO48i4o: Type = 584;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwo64i: Type = 585;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO64i2o: Type = 586;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO64i4o: Type = 587;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gwio: Type = 24;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gwIo2i: Type = 298;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gwIo4i: Type = 299;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI24o: Type = 661;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI24o2i: Type = 670;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI24o4i: Type = 711;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI32o: Type = 214;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI32o2i: Type = 300;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI32o4i: Type = 301;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Ohwi48o: Type = 302;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI48o2i: Type = 303;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI48o4i: Type = 304;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Ohwi64o: Type = 305;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI64o2i: Type = 306;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI64o4i: Type = 307;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Ihwo32i: Type = 642;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO32i2o: Type = 643;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO32i4o: Type = 644;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Ihwo48i: Type = 645;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO48i2o: Type = 646;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO48i4o: Type = 647;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Ihwo64i: Type = 648;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO64i2o: Type = 649;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO64i4o: Type = 650;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_hwIo2i: Type = 308;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_hwIo4i: Type = 309;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI24o: Type = 664;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI32o: Type = 191;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI32o2i: Type = 310;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI32o4i: Type = 311;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwi48o: Type = 312;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI48o2i: Type = 313;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI48o4i: Type = 314;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwi64o: Type = 315;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI64o2i: Type = 316;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI64o4i: Type = 317;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwo32i: Type = 651;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO32i2o: Type = 652;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO32i4o: Type = 653;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwo48i: Type = 654;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO48i2o: Type = 655;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO48i4o: Type = 656;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwo64i: Type = 657;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO64i2o: Type = 658;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO64i4o: Type = 659;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_ghwio: Type = 34;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_ghwIo2i: Type = 318;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_ghwIo4i: Type = 319;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Odhwi24o: Type = 662;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI24o2i: Type = 671;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI24o4i: Type = 712;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Odhwi32o: Type = 320;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI32o2i: Type = 321;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI32o4i: Type = 322;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Odhwi48o: Type = 323;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI48o2i: Type = 324;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI48o4i: Type = 325;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Odhwi64o: Type = 326;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI64o2i: Type = 327;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI64o4i: Type = 328;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Idhwo32i: Type = 561;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO32i2o: Type = 562;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO32i4o: Type = 563;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Idhwo48i: Type = 564;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO48i2o: Type = 565;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO48i4o: Type = 566;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_Idhwo64i: Type = 567;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO64i2o: Type = 568;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO64i4o: Type = 569;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_dhwIo2i: Type = 329;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_dhwIo4i: Type = 330;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwi24o: Type = 665;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI24o2i: Type = 674;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI24o4i: Type = 715;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwi32o: Type = 331;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI32o2i: Type = 332;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI32o4i: Type = 333;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwi48o: Type = 334;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI48o2i: Type = 335;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI48o4i: Type = 336;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwi64o: Type = 337;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI64o2i: Type = 338;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI64o4i: Type = 339;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwo32i: Type = 552;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO32i2o: Type = 553;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO32i4o: Type = 554;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwo48i: Type = 555;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO48i2o: Type = 556;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO48i4o: Type = 557;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwo64i: Type = 558;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO64i2o: Type = 559;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO64i4o: Type = 560;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gdhwio: Type = 44;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gdhwIo2i: Type = 340;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gdhwIo4i: Type = 341;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI16i32o4i: Type = 342;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI16i48o4i: Type = 343;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI16i64o4i: Type = 344;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI16i16o2i: Type = 345;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI16i32o2i: Type = 346;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI16i48o2i: Type = 347;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OI16i64o2i: Type = 348;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw16i32o4i: Type = 349;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw16i48o4i: Type = 350;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw16i64o4i: Type = 351;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw16i32o2i: Type = 352;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw16i48o2i: Type = 353;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw16i64o2i: Type = 354;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw16i32o4i: Type = 355;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw16i48o4i: Type = 356;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw16i64o4i: Type = 357;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw16i32o2i: Type = 358;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw16i48o2i: Type = 359;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw16i64o2i: Type = 360;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw16i32o4i: Type = 361;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw16i48o4i: Type = 362;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw16i64o4i: Type = 363;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw16i32o2i: Type = 364;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw16i48o2i: Type = 365;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw16i64o2i: Type = 366;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI16i16o2i: Type = 393;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI16i16o4i: Type = 394;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI16i16o2i: Type = 395;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI16i16o4i: Type = 396;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI16i16o2i: Type = 397;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI16i16o4i: Type = 399;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO16o16i2o: Type = 588;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO16o16i4o: Type = 589;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO16o16i2o: Type = 590;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO16o16i4o: Type = 591;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO16o16i2o: Type = 592;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO16o16i4o: Type = 593;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI16i16o2i: Type = 406;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI16i16o4i: Type = 407;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI16i16o2i: Type = 390;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI16i16o4i: Type = 391;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI16i16o2i: Type = 392;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI16i16o4i: Type = 398;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO16o16i2o: Type = 594;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO16o16i4o: Type = 595;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO16o16i2o: Type = 596;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO16o16i4o: Type = 597;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO16o16i2o: Type = 598;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO16o16i4o: Type = 599;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI16i32o2i: Type = 400;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI16i32o4i: Type = 401;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI16i48o2i: Type = 402;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI16i48o4i: Type = 403;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI16i64o2i: Type = 404;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OwI16i64o4i: Type = 405;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO16o32i2o: Type = 600;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO16o32i4o: Type = 601;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO16o48i2o: Type = 602;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO16o48i4o: Type = 603;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO16o64i2o: Type = 604;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IwO16o64i4o: Type = 605;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI16i32o2i: Type = 408;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI16i32o4i: Type = 409;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI16i48o2i: Type = 410;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI16i48o4i: Type = 411;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI16i64o2i: Type = 412;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOwI16i64o4i: Type = 413;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO16o32i2o: Type = 606;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO16o32i4o: Type = 607;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO16o48i2o: Type = 608;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO16o48i4o: Type = 609;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO16o64i2o: Type = 610;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIwO16o64i4o: Type = 611;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI16i32o2i: Type = 414;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI16i32o4i: Type = 415;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI16i48o2i: Type = 416;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI16i48o4i: Type = 417;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI16i64o2i: Type = 418;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OhwI16i64o4i: Type = 419;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO16o32i2o: Type = 612;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO16o32i4o: Type = 613;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO16o48i2o: Type = 614;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO16o48i4o: Type = 615;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO16o64i2o: Type = 616;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IhwO16o64i4o: Type = 617;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI16i32o2i: Type = 420;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI16i32o4i: Type = 421;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI16i48o2i: Type = 422;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI16i48o4i: Type = 423;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI16i64o2i: Type = 424;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOhwI16i64o4i: Type = 425;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO16o32i2o: Type = 618;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO16o32i4o: Type = 619;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO16o48i2o: Type = 620;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO16o48i4o: Type = 621;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO16o64i2o: Type = 622;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIhwO16o64i4o: Type = 623;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI16i32o2i: Type = 426;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI16i32o4i: Type = 427;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI16i48o2i: Type = 428;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI16i48o4i: Type = 429;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI16i64o2i: Type = 430;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OdhwI16i64o4i: Type = 431;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO16o32i2o: Type = 546;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO16o32i4o: Type = 547;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO16o48i2o: Type = 548;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO16o48i4o: Type = 549;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO16o64i2o: Type = 550;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IdhwO16o64i4o: Type = 551;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI16i32o2i: Type = 432;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI16i32o4i: Type = 433;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI16i48o2i: Type = 434;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI16i48o4i: Type = 435;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI16i64o2i: Type = 436;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOdhwI16i64o4i: Type = 437;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO16o32i2o: Type = 540;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO16o32i4o: Type = 541;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO16o48i2o: Type = 542;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO16o48i4o: Type = 543;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO16o64i2o: Type = 544;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIdhwO16o64i4o: Type = 545;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_hwioG16g: Type = 438;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_hwioG8g: Type = 539;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_dhwioG16g: Type = 765;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_dhwioG8g: Type = 766;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NCdhw40n16c: Type = 444;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NCw40n16c: Type = 372;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NChw40n16c: Type = 376;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NCw40n32c: Type = 373;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NChw40n32c: Type = 377;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NCdhw40n32c: Type = 445;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw4o8i8o2i: Type = 447;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw4o8i8o2i: Type = 448;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw4o8i8o2i: Type = 449;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw4o8i8o2i: Type = 450;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw4o8i8o2i: Type = 451;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw4o8i8o2i: Type = 452;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOdhw4i8o8i2o: Type = 453;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOhw4i8o8i2o: Type = 454;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOw4i8o8i2o: Type = 455;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOdhw4i8o8i2o: Type = 456;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOhw4i8o8i2o: Type = 457;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOw4i8o8i2o: Type = 458;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NCw2c32n8c: Type = 474;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NChw2c32n8c: Type = 478;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_NCdhw2c32n8c: Type = 483;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw2i8o16i4o: Type = 469;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw2i8o16i4o: Type = 470;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw2i8o16i4o: Type = 471;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw2o8i16o4i: Type = 472;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIw2o8i16o2i: Type = 473;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOw2i8o16i4o: Type = 490;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOw2i8o16i2o: Type = 493;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw2o8i16o4i: Type = 475;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIhw2o8i16o2i: Type = 476;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOhw2i8o16i4o: Type = 489;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOhw2i8o16i2o: Type = 492;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw2o8i16o4i: Type = 480;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_OIdhw2o8i16o2i: Type = 481;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOdhw2i8o16i4o: Type = 488;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_IOdhw2i8o16i2o: Type = 491;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw2o8i16o2i: Type = 485;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOw2i8o16i2o: Type = 477;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOhw2i8o16i2o: Type = 494;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gIOdhw2i8o16i2o: Type = 495;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw2o8i16o2i: Type = 486;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIdhw2o8i16o2i: Type = 487;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIw2o8i16o4i: Type = 497;
    #[doc = " 3D CNN activations tensor blocked by channels with block size 8,\n an alias to #dnnl_aBc8b"]
    pub const dnnl_gOIhw2o8i16o4i: Type = 498;
}
pub mod dnnl_prop_kind_t {
    #[doc = " Kinds of propagation."]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " Undefined propagation type."]
    pub const dnnl_prop_kind_undef: Type = 0;
    #[doc = " Forward data propagation (training mode). In this mode primitives\n perform computations necessary for subsequent backward propagation."]
    pub const dnnl_forward_training: Type = 64;
    #[doc = " Forward data propagation (inference mode). In this mode primitives\n perform only computations that are necessary for inference and omit\n computations that are necessary only for backward propagation."]
    pub const dnnl_forward_inference: Type = 96;
    #[doc = " Forward data propagation (alias for @c dnnl_forward_training)."]
    pub const dnnl_forward: Type = 64;
    #[doc = " Backward propagation (with respect to all parameters)."]
    pub const dnnl_backward: Type = 128;
    #[doc = " Backward data propagation."]
    pub const dnnl_backward_data: Type = 160;
    #[doc = " Backward weights propagation."]
    pub const dnnl_backward_weights: Type = 192;
    #[doc = " Backward bias propagation."]
    pub const dnnl_backward_bias: Type = 193;
}
pub mod dnnl_primitive_kind_t {
    #[doc = " Kinds of primitives. Used to implement a way to extend the library with new\n primitives without changing the ABI."]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " Undefined primitive"]
    pub const dnnl_undefined_primitive: Type = 0;
    #[doc = " A reorder primitive."]
    pub const dnnl_reorder: Type = 1;
    #[doc = " A shuffle primitive."]
    pub const dnnl_shuffle: Type = 2;
    #[doc = " A (out-of-place) concat primitive."]
    pub const dnnl_concat: Type = 3;
    #[doc = " A sum primitive."]
    pub const dnnl_sum: Type = 4;
    #[doc = " A convolution primitive."]
    pub const dnnl_convolution: Type = 5;
    #[doc = " A deconvolution primitive."]
    pub const dnnl_deconvolution: Type = 6;
    #[doc = " An element-wise primitive."]
    pub const dnnl_eltwise: Type = 7;
    #[doc = " An LRN primitive."]
    pub const dnnl_lrn: Type = 8;
    #[doc = " A batch normalization primitive."]
    pub const dnnl_batch_normalization: Type = 9;
    #[doc = " An inner product primitive."]
    pub const dnnl_inner_product: Type = 10;
    #[doc = " A rnn primitive."]
    pub const dnnl_rnn: Type = 11;
    #[doc = " A matrix multiplication primitive (internal)."]
    pub const dnnl_gemm: Type = 12;
    #[doc = " A binary primitive."]
    pub const dnnl_binary: Type = 13;
    #[doc = " A matrix multiplication primitive."]
    pub const dnnl_matmul: Type = 14;
    #[doc = " A resampling primitive."]
    pub const dnnl_resampling: Type = 15;
    #[doc = " A pooling primitive."]
    pub const dnnl_pooling: Type = 16;
    #[doc = " A reduction primitive."]
    pub const dnnl_reduction: Type = 17;
    #[doc = " A PReLU primitive."]
    pub const dnnl_prelu: Type = 18;
    #[doc = " A softmax primitive."]
    pub const dnnl_softmax: Type = 19;
    #[doc = " A layer normalization primitive."]
    pub const dnnl_layer_normalization: Type = 20;
    #[doc = " A group normalization primitive."]
    pub const dnnl_group_normalization: Type = 21;
    #[doc = " Parameter to allow internal only primitives without undefined behavior.\n This parameter is chosen to be valid for so long as sizeof(int) >= 2."]
    pub const dnnl_primitive_kind_max: Type = 32767;
}
pub mod dnnl_alg_kind_t {
    #[doc = " Kinds of algorithms."]
    pub type Type = ::std::os::raw::c_uint;
    pub const dnnl_alg_kind_undef: Type = 0;
    #[doc = " Direct convolution"]
    pub const dnnl_convolution_direct: Type = 1;
    #[doc = " Winograd convolution"]
    pub const dnnl_convolution_winograd: Type = 2;
    #[doc = " Convolution algorithm(either direct or Winograd) is chosen just in time"]
    pub const dnnl_convolution_auto: Type = 3;
    #[doc = " Direct deconvolution"]
    pub const dnnl_deconvolution_direct: Type = 10;
    #[doc = " Winograd deconvolution"]
    pub const dnnl_deconvolution_winograd: Type = 11;
    #[doc = " Eltwise: ReLU"]
    pub const dnnl_eltwise_relu: Type = 32;
    #[doc = " Eltwise: hyperbolic tangent non-linearity (tanh)"]
    pub const dnnl_eltwise_tanh: Type = 33;
    #[doc = " Eltwise: exponential linear unit (elu)"]
    pub const dnnl_eltwise_elu: Type = 34;
    #[doc = " Eltwise: square"]
    pub const dnnl_eltwise_square: Type = 35;
    #[doc = " Eltwise: abs"]
    pub const dnnl_eltwise_abs: Type = 36;
    #[doc = " Eltwise: square root"]
    pub const dnnl_eltwise_sqrt: Type = 37;
    #[doc = " Eltwise: linear"]
    pub const dnnl_eltwise_linear: Type = 38;
    #[doc = " Eltwise: soft_relu"]
    pub const dnnl_eltwise_soft_relu: Type = 39;
    #[doc = " Eltwise: hardsigmoid"]
    pub const dnnl_eltwise_hardsigmoid: Type = 40;
    #[doc = " Eltwise: logistic"]
    pub const dnnl_eltwise_logistic: Type = 41;
    #[doc = " Eltwise: exponent"]
    pub const dnnl_eltwise_exp: Type = 42;
    #[doc = " Eltwise: gelu\n\n @note Tanh approximation formula is used to approximate\n the cumulative distribution function of a Gaussian here"]
    pub const dnnl_eltwise_gelu_tanh: Type = 43;
    #[doc = " Eltwise: swish"]
    pub const dnnl_eltwise_swish: Type = 44;
    #[doc = " Eltwise: natural logarithm"]
    pub const dnnl_eltwise_log: Type = 45;
    #[doc = " Eltwise: clip"]
    pub const dnnl_eltwise_clip: Type = 46;
    #[doc = " Eltwise: clip version 2"]
    pub const dnnl_eltwise_clip_v2: Type = 47;
    #[doc = " Eltwise: pow"]
    pub const dnnl_eltwise_pow: Type = 48;
    #[doc = " Eltwise: erf-based gelu"]
    pub const dnnl_eltwise_gelu_erf: Type = 49;
    #[doc = " Eltwise: round"]
    pub const dnnl_eltwise_round: Type = 50;
    #[doc = " Eltwise: mish"]
    pub const dnnl_eltwise_mish: Type = 51;
    #[doc = " Eltwise: hardswish"]
    pub const dnnl_eltwise_hardswish: Type = 52;
    #[doc = " Eltwise: ReLU (dst for backward)"]
    pub const dnnl_eltwise_relu_use_dst_for_bwd: Type = 256;
    #[doc = " Eltwise: hyperbolic tangent non-linearity (tanh) (dst for backward)"]
    pub const dnnl_eltwise_tanh_use_dst_for_bwd: Type = 257;
    #[doc = " Eltwise: exponential linear unit (elu) (dst for backward)"]
    pub const dnnl_eltwise_elu_use_dst_for_bwd: Type = 258;
    #[doc = " Eltwise: square root (dst for backward)"]
    pub const dnnl_eltwise_sqrt_use_dst_for_bwd: Type = 259;
    #[doc = " Eltwise: logistic (dst for backward)"]
    pub const dnnl_eltwise_logistic_use_dst_for_bwd: Type = 260;
    #[doc = " Eltwise: exp (dst for backward)"]
    pub const dnnl_eltwise_exp_use_dst_for_bwd: Type = 261;
    #[doc = " Eltwise: clip version 2 (dst for backward)"]
    pub const dnnl_eltwise_clip_v2_use_dst_for_bwd: Type = 262;
    #[doc = " Max pooling"]
    pub const dnnl_pooling_max: Type = 511;
    #[doc = " Average pooling include padding"]
    pub const dnnl_pooling_avg_include_padding: Type = 767;
    #[doc = " Average pooling exclude padding"]
    pub const dnnl_pooling_avg_exclude_padding: Type = 1023;
    #[doc = " Local response normalization (LRN) across multiple channels"]
    pub const dnnl_lrn_across_channels: Type = 2815;
    #[doc = " LRN within a single channel"]
    pub const dnnl_lrn_within_channel: Type = 3071;
    #[doc = " RNN cell"]
    pub const dnnl_vanilla_rnn: Type = 8191;
    #[doc = " LSTM cell"]
    pub const dnnl_vanilla_lstm: Type = 12287;
    #[doc = " GRU cell"]
    pub const dnnl_vanilla_gru: Type = 16383;
    #[doc = " GRU cell with linear before reset\n\n Modification of original GRU cell. Differs from #dnnl_vanilla_gru\n in how the new memory gate is calculated:\n \\f[ c_t = tanh(W_c*x_t + b_{c_x} + r_t*(U_c*h_{t-1}+b_{c_h})) \\f]\n Primitive expects 4 biases on input:\n \\f$[b_{u}, b_{r}, b_{c_x}, b_{c_h}]\\f$"]
    pub const dnnl_lbr_gru: Type = 20479;
    #[doc = " AUGRU cell"]
    pub const dnnl_vanilla_augru: Type = 24575;
    #[doc = " AUGRU cell with linear before reset"]
    pub const dnnl_lbr_augru: Type = 28671;
    #[doc = " Binary add"]
    pub const dnnl_binary_add: Type = 131056;
    #[doc = " Binary mul"]
    pub const dnnl_binary_mul: Type = 131057;
    #[doc = " Binary max"]
    pub const dnnl_binary_max: Type = 131058;
    #[doc = " Binary min"]
    pub const dnnl_binary_min: Type = 131059;
    #[doc = " Binary div"]
    pub const dnnl_binary_div: Type = 131060;
    #[doc = " Binary sub"]
    pub const dnnl_binary_sub: Type = 131061;
    #[doc = " Binary greater or equal"]
    pub const dnnl_binary_ge: Type = 131062;
    #[doc = " Binary greater than"]
    pub const dnnl_binary_gt: Type = 131063;
    #[doc = " Binary less or equal"]
    pub const dnnl_binary_le: Type = 131064;
    #[doc = " Binary less than"]
    pub const dnnl_binary_lt: Type = 131065;
    #[doc = " Binary equal"]
    pub const dnnl_binary_eq: Type = 131066;
    #[doc = " Binary not equal"]
    pub const dnnl_binary_ne: Type = 131067;
    #[doc = " Binary select"]
    pub const dnnl_binary_select: Type = 131068;
    #[doc = " Nearest Neighbor Resampling Method"]
    pub const dnnl_resampling_nearest: Type = 196592;
    #[doc = " Linear Resampling Method"]
    pub const dnnl_resampling_linear: Type = 196593;
    #[doc = " Reduction using max"]
    pub const dnnl_reduction_max: Type = 196594;
    #[doc = " Reduction using min"]
    pub const dnnl_reduction_min: Type = 196595;
    #[doc = " Reduction using sum"]
    pub const dnnl_reduction_sum: Type = 196596;
    #[doc = " Reduction using mul"]
    pub const dnnl_reduction_mul: Type = 196597;
    #[doc = " Reduction using mean"]
    pub const dnnl_reduction_mean: Type = 196598;
    #[doc = " Reduction using lp norm"]
    pub const dnnl_reduction_norm_lp_max: Type = 196599;
    #[doc = " Reduction using lp norm"]
    pub const dnnl_reduction_norm_lp_sum: Type = 196600;
    #[doc = " Reduction using lp norm without final pth-root"]
    pub const dnnl_reduction_norm_lp_power_p_max: Type = 196601;
    #[doc = " Reduction using lp norm without final pth-root"]
    pub const dnnl_reduction_norm_lp_power_p_sum: Type = 196602;
    #[doc = " Softmax"]
    pub const dnnl_softmax_accurate: Type = 196608;
    #[doc = " Logsoftmax"]
    pub const dnnl_softmax_log: Type = 196609;
}
pub mod dnnl_normalization_flags_t {
    #[doc = " Flags for normalization primitives."]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " Use no normalization flags\n\n If specified\n  - on forward training propagation mean and variance are computed and\n    stored as output\n  - on backward propagation compute full derivative wrt data\n  - on backward propagation prop_kind == #dnnl_backward_data has the same\n    behavior as prop_kind == #dnnl_backward"]
    pub const dnnl_normalization_flags_none: Type = 0;
    #[doc = " Use global statistics\n\n If specified\n  - on forward propagation use mean and variance provided by user (input)\n  - on backward propagation reduces the amount of computations, since\n    mean and variance are considered as constants\n\n  If not specified:\n   - on forward propagation mean and variance are computed and stored as\n     output\n   - on backward propagation compute full derivative wrt data"]
    pub const dnnl_use_global_stats: Type = 1;
    #[doc = " Use scale parameter\n\n If specified:\n  - on forward propagation use scale for the normalization results\n  - on backward propagation (for prop_kind == #dnnl_backward) compute\n    diff wrt scale (hence one extra output used)"]
    pub const dnnl_use_scale: Type = 2;
    #[doc = " Use shift parameter\n\n If specified:\n  - on forward propagation use shift (aka bias) for the normalization\n    results\n  - on backward propagation (for prop_kind == #dnnl_backward) compute\n    diff wrt shift (hence one extra output used)"]
    pub const dnnl_use_shift: Type = 4;
    #[doc = " Fuse with ReLU\n\n The flag implies negative slope being 0. On training this is the only\n configuration supported. For inference, to use non-zero negative slope\n consider using @ref dev_guide_attributes_post_ops.\n\n If specified:\n  - on inference this option behaves the same as if the primitive were\n    fused with ReLU using post ops API with zero negative slope.\n  - on training primitive requires workspace (required to be able to\n    perform backward pass)"]
    pub const dnnl_fuse_norm_relu: Type = 8;
    #[doc = " Fuse with Add and then fuse with ReLU\n\n If specified:\n\n  - on forward propagation apply element-wise binary Add operation to\n    to the normalization results with an additional input tensor and then\n    apply ReLU with negative slope being 0.\n  - on training primitive requires workspace (required to be able to\n    perform backward pass).\n  - on backward propagation save the result of backward ReLU operation\n    with input tensor and workspace from forward pass to extra output\n    tensor and then perform backward normalization."]
    pub const dnnl_fuse_norm_add_relu: Type = 16;
}
#[doc = " @cond DO_NOT_DOCUMENT_THIS\n Hex representation for a **special** quiet NAN (!= NAN from math.h)"]
#[repr(C)]
#[derive(Copy, Clone)]
pub union _bindgen_ty_1 {
    pub u: ::std::os::raw::c_uint,
    pub f: f32,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of _bindgen_ty_1"][::std::mem::size_of::<_bindgen_ty_1>() - 4usize];
    ["Alignment of _bindgen_ty_1"][::std::mem::align_of::<_bindgen_ty_1>() - 4usize];
    ["Offset of field: _bindgen_ty_1::u"][::std::mem::offset_of!(_bindgen_ty_1, u) - 0usize];
    ["Offset of field: _bindgen_ty_1::f"][::std::mem::offset_of!(_bindgen_ty_1, f) - 0usize];
};
unsafe extern "C" {
    pub static DNNL_RUNTIME_F32_VAL_REP: _bindgen_ty_1;
}
#[doc = " @cond DO_NOT_DOCUMENT_THIS"]
pub const DNNL_RUNTIME_S32_VAL_REP: ::std::os::raw::c_int = -2147483648;
#[doc = " @struct dnnl_memory_desc\n An opaque structure to describe a memory descriptor."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_memory_desc {
    _unused: [u8; 0],
}
#[doc = " A memory descriptor handle."]
pub type dnnl_memory_desc_t = *mut dnnl_memory_desc;
#[doc = " A memory descriptor handle."]
pub type const_dnnl_memory_desc_t = *const dnnl_memory_desc;
#[doc = " @struct dnnl_memory\n An opaque structure to describe a memory."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_memory {
    _unused: [u8; 0],
}
#[doc = " A memory handle."]
pub type dnnl_memory_t = *mut dnnl_memory;
#[doc = " A constant memory handle."]
pub type const_dnnl_memory_t = *const dnnl_memory;
pub mod dnnl_rnn_flags_t {
    #[doc = " Flags for RNN cell."]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " Undefined RNN flags"]
    pub const dnnl_rnn_flags_undef: Type = 0;
    #[doc = " Do not add weights gradient to existing diff_weights memory"]
    pub const dnnl_rnn_flags_diff_weights_overwrite: Type = 1;
}
pub mod dnnl_rnn_direction_t {
    #[doc = " A direction of RNN primitive execution."]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " Undefined RNN direction."]
    pub const dnnl_rnn_direction_undef: Type = 0;
    #[doc = " Unidirectional execution of RNN primitive from left to right."]
    pub const dnnl_unidirectional_left2right: Type = 1;
    #[doc = " Unidirectional execution of RNN primitive from right to left."]
    pub const dnnl_unidirectional_right2left: Type = 2;
    #[doc = " Bidirectional execution of RNN primitive with concatenation of the\n results."]
    pub const dnnl_bidirectional_concat: Type = 3;
    #[doc = " Bidirectional execution of RNN primitive with summation of the\n results."]
    pub const dnnl_bidirectional_sum: Type = 4;
}
#[doc = " @struct dnnl_primitive_desc\n @brief An opaque structure to describe a primitive descriptor."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_primitive_desc {
    _unused: [u8; 0],
}
#[doc = " @brief A primitive descriptor handle."]
pub type dnnl_primitive_desc_t = *mut dnnl_primitive_desc;
#[doc = " @brief A constant primitive descriptor handle."]
pub type const_dnnl_primitive_desc_t = *const dnnl_primitive_desc;
pub mod dnnl_scratchpad_mode_t {
    #[doc = " Scratchpad mode"]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " The library manages the scratchpad allocation according to the policy\n specified by the `DNNL_ENABLE_CONCURRENT_EXEC`\n [build option](@ref dev_guide_build_options) (default).\n\n When `DNNL_ENABLE_CONCURRENT_EXEC=OFF` (default), the library\n scratchpad is common to all primitives to reduce the memory footprint.\n This configuration comes with limited thread-safety properties, namely\n primitives can be created and executed in parallel but cannot migrate\n between threads (in other words, each primitive should be executed in\n the same thread it was created in).\n\n When `DNNL_ENABLE_CONCURRENT_EXEC=ON`, the library scratchpad is\n private to each primitive. The memory footprint is larger than when\n using `DNNL_ENABLE_CONCURRENT_EXEC=OFF` but different primitives can be\n created and run concurrently (the same primitive cannot be run\n concurrently from two different threads though)."]
    pub const dnnl_scratchpad_mode_library: Type = 0;
    #[doc = " The user manages the scratchpad allocation by querying and providing\n the scratchpad memory to primitives. This mode is thread-safe as long\n as the scratchpad buffers are not used concurrently by two primitive\n executions."]
    pub const dnnl_scratchpad_mode_user: Type = 1;
}
pub mod dnnl_rounding_mode_t {
    #[doc = " Rounding mode"]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " rounding mode dictated by the floating-point environment"]
    pub const dnnl_rounding_mode_environment: Type = 0;
    #[doc = " stochastic rounding mode where a random bias is added to the\n trailing mantissa bits before conversion."]
    pub const dnnl_rounding_mode_stochastic: Type = 1;
}
#[doc = " @struct dnnl_primitive_attr\n @brief An opaque structure for primitive descriptor attributes.\n\n Attributes may contain:\n  - output scales (to scale the result prior to storing it to the memory)"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_primitive_attr {
    _unused: [u8; 0],
}
#[doc = " @brief A primitive descriptor attributes handle that controls primitive\n behavior."]
pub type dnnl_primitive_attr_t = *mut dnnl_primitive_attr;
#[doc = " @brief A constant primitive descriptor attributes handle."]
pub type const_dnnl_primitive_attr_t = *const dnnl_primitive_attr;
#[doc = " @struct dnnl_post_ops\n @brief An opaque structure for a chain of post operations.\n\n dnnl_post_ops can be used to perform some (trivial) operations like\n accumulation or eltwise after certain primitives like convolution.\n\n Post operations might be combined together, making a chain of post\n operations. For instance one can configure convolution followed by\n accumulation followed by eltwise. This might be especially beneficial\n for residual learning blocks.\n\n @warning\n      Of course not all combinations are supported, so the user should handle\n      errors accordingly.\n\n Supported post operations:\n  - accumulation (base primitive: convolution)\n  - eltwise (base primitive: convolution)"]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_post_ops {
    _unused: [u8; 0],
}
#[doc = " @brief A post operation chain handle."]
pub type dnnl_post_ops_t = *mut dnnl_post_ops;
#[doc = " @brief A constant post operation chain handle."]
pub type const_dnnl_post_ops_t = *const dnnl_post_ops;
#[doc = " @struct dnnl_primitive\n An opaque structure to describe a primitive."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_primitive {
    _unused: [u8; 0],
}
#[doc = " A primitive handle."]
pub type dnnl_primitive_t = *mut dnnl_primitive;
#[doc = " A constant primitive handle."]
pub type const_dnnl_primitive_t = *const dnnl_primitive;
#[doc = " A structure that contains an index and a memory object, and is used to pass\n arguments to dnnl_primitive_execute()."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_exec_arg_t {
    #[doc = "< An argument index, e.g. DNNL_ARG_SRC"]
    pub arg: ::std::os::raw::c_int,
    #[doc = "< Input/output memory"]
    pub memory: dnnl_memory_t,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of dnnl_exec_arg_t"][::std::mem::size_of::<dnnl_exec_arg_t>() - 16usize];
    ["Alignment of dnnl_exec_arg_t"][::std::mem::align_of::<dnnl_exec_arg_t>() - 8usize];
    ["Offset of field: dnnl_exec_arg_t::arg"]
        [::std::mem::offset_of!(dnnl_exec_arg_t, arg) - 0usize];
    ["Offset of field: dnnl_exec_arg_t::memory"]
        [::std::mem::offset_of!(dnnl_exec_arg_t, memory) - 8usize];
};
pub mod dnnl_query_t {
    #[doc = " Primitive descriptor query specification\n\n For generic function dnnl_primitive_desc_query(), the type of result must\n agree with the queried argument. The correspondence table:\n\n Query kind                      | Type of query result\n --------------------------------|-----------------------------\n dnnl_query_*_engine             | #dnnl_engine_t *\n #dnnl_query_primitive_kind      | #dnnl_primitive_kind_t *\n dnnl_query_*_s32                | int *\n dnnl_query_*_s64                | #dnnl_dim_t * (same as int64_t *)\n dnnl_query_*_f32                | float *\n dnnl_query_*_f64                | double *\n dnnl_query_*_str                | const char **\n dnnl_query_*_md                 | #const_dnnl_memory_desc_t *\n dnnl_query_*_pd                 | #const_dnnl_primitive_desc_t *\n dnnl_query_cache_blob_id        | const uint8_t **\n dnnl_query_strides              | const #dnnl_dims_t **\n dnnl_query_dilations            | const #dnnl_dims_t **\n dnnl_query_padding_l            | const #dnnl_dims_t **\n dnnl_query_padding_r            | const #dnnl_dims_t **\n dnnl_query_flags                | unsigned *\n dnnl_query_alg_kind             | #dnnl_alg_kind_t *\n dnnl_query_factors              | const float **\n dnnl_query_cell_kind            | #dnnl_alg_kind_t *\n dnnl_query_direction            | #dnnl_rnn_direction_t *\n dnnl_query_activation_kind      | #dnnl_alg_kind_t *\n dnnl_query_kernel               | const #dnnl_dims_t **\n dnnl_query_dims                 | const #dnnl_dims_t **\n dnnl_query_data_type            | #dnnl_data_type_t *\n dnnl_query_padded_dims          | const #dnnl_dims_t **\n dnnl_query_padded_offsets       | const #dnnl_dims_t **\n dnnl_query_format_kind          | #dnnl_format_kind_t *\n dnnl_query_inner_blks           | const #dnnl_dims_t **\n dnnl_query_inner_idxs           | const #dnnl_dims_t **\n dnnl_query_sparse_encoding      | #dnnl_sparse_encoding_t *\n\n @note\n     Rule of thumb: all opaque types and structures are returned by\n     reference. All numbers are returned by value.\n\n @warning\n     All returned references point to constant objects and are valid only\n     during the lifetime of the queried primitive descriptor. Returned objects\n     must not be destroyed by the user. If you need to keep the object longer\n     than the lifetime of the queried primitive descriptor, use\n     dnnl_primitive_desc_clone() to make a copy."]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = "< no query"]
    pub const dnnl_query_undef: Type = 0;
    #[doc = "< execution engine"]
    pub const dnnl_query_engine: Type = 1;
    #[doc = "< primitive kind"]
    pub const dnnl_query_primitive_kind: Type = 2;
    #[doc = "< number of inputs expected"]
    pub const dnnl_query_num_of_inputs_s32: Type = 3;
    #[doc = "< number of outputs expected"]
    pub const dnnl_query_num_of_outputs_s32: Type = 4;
    #[doc = "< runtime estimation (seconds)"]
    pub const dnnl_query_time_estimate_f64: Type = 5;
    #[doc = "< memory consumption -- extra"]
    pub const dnnl_query_memory_consumption_s64: Type = 6;
    #[doc = "< scratchpad engine -- engine to be used"]
    pub const dnnl_query_scratchpad_engine: Type = 7;
    #[doc = "< implementation name"]
    pub const dnnl_query_impl_info_str: Type = 8;
    #[doc = "< source engine"]
    pub const dnnl_query_reorder_src_engine: Type = 9;
    #[doc = "< destination engine"]
    pub const dnnl_query_reorder_dst_engine: Type = 10;
    #[doc = "< propagation kind"]
    pub const dnnl_query_prop_kind: Type = 11;
    #[doc = "< size of cache blob ID in bytes"]
    pub const dnnl_query_cache_blob_id_size_s64: Type = 12;
    #[doc = "< cache blob  ID (pointer to array)"]
    pub const dnnl_query_cache_blob_id: Type = 13;
    #[doc = "< strides"]
    pub const dnnl_query_strides: Type = 14;
    #[doc = "< dilations"]
    pub const dnnl_query_dilations: Type = 15;
    #[doc = "< left padding"]
    pub const dnnl_query_padding_l: Type = 16;
    #[doc = "< right padding"]
    pub const dnnl_query_padding_r: Type = 17;
    #[doc = "< epsilon"]
    pub const dnnl_query_epsilon_f32: Type = 18;
    #[doc = "< flags"]
    pub const dnnl_query_flags: Type = 19;
    #[doc = "< algorithm kind"]
    pub const dnnl_query_alg_kind: Type = 20;
    #[doc = "< alpha"]
    pub const dnnl_query_alpha_f32: Type = 21;
    #[doc = "< beta"]
    pub const dnnl_query_beta_f32: Type = 22;
    #[doc = "< axis"]
    pub const dnnl_query_axis_s32: Type = 23;
    #[doc = "< LRN parameter local size"]
    pub const dnnl_query_local_size_s64: Type = 24;
    #[doc = "< LRN parameter K"]
    pub const dnnl_query_k_f32: Type = 25;
    #[doc = "< Reduction parameter P"]
    pub const dnnl_query_p_f32: Type = 26;
    #[doc = "< Resampling parameter factors"]
    pub const dnnl_query_factors: Type = 27;
    #[doc = "< RNN parameter cell kind"]
    pub const dnnl_query_cell_kind: Type = 28;
    #[doc = "< RNN parameter direction"]
    pub const dnnl_query_direction: Type = 29;
    #[doc = "< RNN parameter activation kind"]
    pub const dnnl_query_activation_kind: Type = 30;
    #[doc = "< Pooling parameter kernel"]
    pub const dnnl_query_kernel: Type = 31;
    #[doc = "< Shuffle parameter group size"]
    pub const dnnl_query_group_size_s64: Type = 32;
    #[doc = "< stub"]
    pub const dnnl_query_some_md: Type = 128;
    #[doc = "< source memory desc"]
    pub const dnnl_query_src_md: Type = 129;
    #[doc = "< source gradient memory desc"]
    pub const dnnl_query_diff_src_md: Type = 130;
    #[doc = "< weights memory descriptor desc"]
    pub const dnnl_query_weights_md: Type = 131;
    #[doc = "< weights grad. memory desc"]
    pub const dnnl_query_diff_weights_md: Type = 132;
    #[doc = "< destination memory desc"]
    pub const dnnl_query_dst_md: Type = 133;
    #[doc = "< destination grad. memory desc"]
    pub const dnnl_query_diff_dst_md: Type = 134;
    #[doc = "< workspace memory desc"]
    pub const dnnl_query_workspace_md: Type = 135;
    #[doc = "< scratchpad memory desc"]
    pub const dnnl_query_scratchpad_md: Type = 136;
    #[doc = "< memory desc of an execute argument"]
    pub const dnnl_query_exec_arg_md: Type = 255;
    #[doc = "< number of dimensions"]
    pub const dnnl_query_ndims_s32: Type = 256;
    #[doc = "< vector of dimensions"]
    pub const dnnl_query_dims: Type = 257;
    #[doc = "< data type"]
    pub const dnnl_query_data_type: Type = 258;
    #[doc = "< submemory offset"]
    pub const dnnl_query_submemory_offset_s64: Type = 259;
    #[doc = "< vector of padded dimensions"]
    pub const dnnl_query_padded_dims: Type = 260;
    #[doc = "< vector of padded offsets"]
    pub const dnnl_query_padded_offsets: Type = 261;
    #[doc = "< format kind"]
    pub const dnnl_query_format_kind: Type = 262;
    #[doc = "< number of innermost blocks"]
    pub const dnnl_query_inner_nblks_s32: Type = 263;
    #[doc = "< vector of sizes of the innermost blocks"]
    pub const dnnl_query_inner_blks: Type = 264;
    #[doc = "< vector of logical indices of the blocks"]
    pub const dnnl_query_inner_idxs: Type = 265;
    pub const dnnl_query_max: Type = 32767;
}
pub mod dnnl_cpu_isa_t {
    #[doc = " CPU instruction set flags"]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " Library choice of ISA (excepting those listed as initial support)"]
    pub const dnnl_cpu_isa_default: Type = 0;
    #[doc = " Intel Streaming SIMD Extensions 4.1 (Intel SSE4.1)"]
    pub const dnnl_cpu_isa_sse41: Type = 1;
    #[doc = " Intel Advanced Vector Extensions (Intel AVX)"]
    pub const dnnl_cpu_isa_avx: Type = 3;
    #[doc = " Intel Advanced Vector Extensions 2 (Intel AVX2)"]
    pub const dnnl_cpu_isa_avx2: Type = 7;
    #[doc = " Intel AVX2 and Intel Deep Learning Boost (Intel DL Boost) support"]
    pub const dnnl_cpu_isa_avx2_vnni: Type = 15;
    #[doc = " Intel AVX2 and Intel Deep Learning Boost (Intel DL Boost)\n with 8-bit integer, float16 and bfloat16 support"]
    pub const dnnl_cpu_isa_avx2_vnni_2: Type = 31;
    #[doc = " Intel AVX-512 subset for Intel Xeon Scalable processor family\n and Intel Core processor family."]
    pub const dnnl_cpu_isa_avx512_core: Type = 39;
    #[doc = " Intel AVX-512 and Intel Deep Learning Boost (Intel DL Boost) support\n for Intel Xeon Scalable processor family\n and Intel Core processor family."]
    pub const dnnl_cpu_isa_avx512_core_vnni: Type = 103;
    #[doc = " Intel AVX-512, Intel DL Boost and bfloat16 support\n for Intel Xeon Scalable processor family\n and Intel Core processor family."]
    pub const dnnl_cpu_isa_avx512_core_bf16: Type = 231;
    #[doc = " Intel AVX-512 with float16, Intel DL Boost and bfloat16 support\n for Intel Xeon Scalable processor family\n and Intel Core processor family."]
    pub const dnnl_cpu_isa_avx10_1_512: Type = 495;
    #[doc = " @copydoc dnnl_cpu_isa_avx10_1_512"]
    pub const dnnl_cpu_isa_avx512_core_fp16: Type = 495;
    #[doc = " Intel AVX-512 with float16, Intel DL Boost and bfloat16 support and\n Intel AMX with 8-bit integer and bfloat16 support"]
    pub const dnnl_cpu_isa_avx10_1_512_amx: Type = 4079;
    #[doc = " @copydoc dnnl_cpu_isa_avx10_1_512_amx"]
    pub const dnnl_cpu_isa_avx512_core_amx: Type = 4079;
    #[doc = " Intel AVX-512 with float16, Intel DL Boost and bfloat16 support and\n Intel AMX with 8-bit integer, bfloat16 and float16 support"]
    pub const dnnl_cpu_isa_avx10_1_512_amx_fp16: Type = 8175;
    #[doc = " @copydoc dnnl_cpu_isa_avx10_1_512_amx_fp16"]
    pub const dnnl_cpu_isa_avx512_core_amx_fp16: Type = 8175;
}
pub mod dnnl_cpu_isa_hints_t {
    #[doc = " CPU ISA hints flags"]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " No hints (use default features)"]
    pub const dnnl_cpu_isa_no_hints: Type = 0;
    #[doc = " Prefer to exclusively use Ymm registers for computations"]
    pub const dnnl_cpu_isa_prefer_ymm: Type = 1;
}
unsafe extern "C" {
    #[doc = " Changes the primitive descriptor to point to the next available\n implementation.\n\n @param primitive_desc A primitive descriptor to change.\n @returns #dnnl_success on success and a status describing the error\n     otherwise.\n @returns #dnnl_last_impl_reached if no more implementations available,\n in which case the primitive descriptor itself is kept unchanged."]
    pub fn dnnl_primitive_desc_next_impl(
        primitive_desc: dnnl_primitive_desc_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Clones a primitive descriptor. The resulting primitive descriptor must be\n destroyed separately.\n\n @param primitive_desc Output primitive descriptor.\n @param existing_primitive_desc Primitive descriptor to clone.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_desc_clone(
        primitive_desc: *mut dnnl_primitive_desc_t,
        existing_primitive_desc: const_dnnl_primitive_desc_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns a constant reference to the attributes of a primitive descriptor.\n\n @warning\n     It is an error to destroy the resulting @p attr.\n\n @warning\n     The lifetime of an @p attr is the same as that of a @p\n     primitive_desc, so it is an error to use the @p attr once the @p\n     primitive_desc has been destroyed.\n\n @param primitive_desc Primitive descriptor.\n @param attr Output primitive attributes.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_desc_get_attr(
        primitive_desc: const_dnnl_primitive_desc_t,
        attr: *mut const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Destroys a primitive descriptor.\n\n @param primitive_desc Primitive descriptor to destroy.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_desc_destroy(
        primitive_desc: dnnl_primitive_desc_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Queries a primitive descriptor for various pieces of information.\n\n The most common use case is to query a primitive descriptor, created with\n source, weights, and destination memory descriptors with format tags set\n to #dnnl_format_tag_any, for the corresponding memory descriptors (in this\n case the @p what is set to #dnnl_query_src_md, #dnnl_query_weights_md, and\n #dnnl_query_dst_md respectively) so that it is possible to create memory\n objects and reorder primitives if necessary.\n\n Another typical use case is to query a primitive descriptor for workspace\n memory descriptor (with @p what set to #dnnl_query_workspace_md). If this\n query returns #dnnl_not_required status, then workspace memory is not\n required.\n\n @note\n     When querying for a memory descriptor for a scratchpad, a workspace,\n     or an optional parameter, the query will return a pointer to a zero\n     memory descriptor if the parameter is not needed.\n\n A few other use cases:\n  - query a primitive descriptor for the implementation information string\n    (#dnnl_query_impl_info_str)\n  - query a primitive descriptor for the number of inputs and outputs\n    (#dnnl_query_num_of_inputs_s32 and #dnnl_query_num_of_outputs_s32\n    respectively)\n\n @sa dnnl_query_t for more options\n\n @param primitive_desc Primitive descriptor.\n @param what Parameter to query.\n @param index Index of the parameter to query for.\n @param result Output result. The type depends on the query. For example,\n     it must be a @c dnnl_memory_desc_t* if querying for a memory\n     descriptor.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_desc_query(
        primitive_desc: const_dnnl_primitive_desc_t,
        what: dnnl_query_t::Type,
        index: ::std::os::raw::c_int,
        result: *mut ::std::os::raw::c_void,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Queries primitive descriptor for a memory descriptor.\n\n @note\n     This function is a convenience version of\n     #dnnl_primitive_desc_query().\n\n @param primitive_desc Primitive descriptor.\n @param what Kind of memory descriptor parameter to query for.\n @param index Index of the parameter to query.\n @returns A pointer to the requested memory descriptor.\n @returns A pointer to a zero memory descriptor if the parameter is not\n          needed.\n @returns NULL in case of any error.\n"]
    pub fn dnnl_primitive_desc_query_md(
        primitive_desc: const_dnnl_primitive_desc_t,
        what: dnnl_query_t::Type,
        index: ::std::os::raw::c_int,
    ) -> const_dnnl_memory_desc_t;
}
unsafe extern "C" {
    #[doc = " Queries primitive descriptor for a signed 32bit int.\n\n @note\n     This function is a convenience version of\n     #dnnl_primitive_desc_query().\n\n @param primitive_desc Primitive descriptor.\n @param what Kind of the value to query for.\n @param index Index of the parameter to query.\n @returns The requested value.\n @returns 0 in case of any error (in particular if the queried entity is\n     not of type int32_t). Note that 0 may also be the actual returned\n     value."]
    pub fn dnnl_primitive_desc_query_s32(
        primitive_desc: const_dnnl_primitive_desc_t,
        what: dnnl_query_t::Type,
        index: ::std::os::raw::c_int,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Creates a primitive.\n\n @param primitive Output primitive.\n @param primitive_desc Primitive descriptor used to create the primitive.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_create(
        primitive: *mut dnnl_primitive_t,
        primitive_desc: const_dnnl_primitive_desc_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive from a cache blob.\n\n @param primitive Output primitive.\n @param primitive_desc Primitive descriptor used to create the primitive.\n @param size Size of the cache blob in bytes.\n @param cache_blob Cache blob of size @p size.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_create_from_cache_blob(
        primitive: *mut dnnl_primitive_t,
        primitive_desc: const_dnnl_primitive_desc_t,
        size: usize,
        cache_blob: *const u8,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " @note If any argument in @p args is padded (padded_dims >\n dims), the primitive execution will assume properly zero-padded\n input arguments, and produce zero-padded output arguments."]
    pub fn dnnl_primitive_execute(
        primitive: const_dnnl_primitive_t,
        stream: dnnl_stream_t,
        nargs: ::std::os::raw::c_int,
        args: *const dnnl_exec_arg_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Retrieves a constant reference to the primitive descriptor of a given\n primitive.\n\n @warning\n     It is an error to destroy the returned object. It is owned by the\n     primitive. The @c const qualifier of the returned object prevents\n     such attempts.\n\n @param primitive Primitive to query for the primitive descriptor.\n @param primitive_desc Output primitive descriptor.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_get_primitive_desc(
        primitive: const_dnnl_primitive_t,
        primitive_desc: *mut const_dnnl_primitive_desc_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Retrieves a cache blob associated with the given primitive.\n\n @param primitive Primitive to query for the cache blob.\n @param size Size of the cache blob in bytes.\n @param cache_blob Cache blob of size @p size. If the @p cache_blob is\n     nullptr then the size of the cache blob is returned in @p size.\n @returns #dnnl_success on success and a status describing the error\n     otherwise.\n\n @note The cache blob can be empty. It's the user's responsibility to check\n     whether it's empty prior to passing it to\n     #dnnl_primitive_create_from_cache_blob()."]
    pub fn dnnl_primitive_get_cache_blob(
        primitive: const_dnnl_primitive_t,
        size: *mut usize,
        cache_blob: *mut u8,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Destroys a primitive.\n\n @param primitive The primitive to destroy.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_destroy(primitive: dnnl_primitive_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates an empty (default) primitive attributes with all the parameters\n set to their default values.\n\n Empty attributes are implied whenever the respective argument is NULL.\n\n @param attr Output primitive attributes.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_create(attr: *mut dnnl_primitive_attr_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Clones primitive attributes.\n\n @param attr Output primitive attributes.\n @param existing_attr Primitive attributes to clone.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_clone(
        attr: *mut dnnl_primitive_attr_t,
        existing_attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Destroys primitive attributes.\n\n @param attr Primitive attributes to destroy.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_destroy(attr: dnnl_primitive_attr_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns probability for output dropout primitive attribute.\n\n @param attr Primitive attributes.\n @param dropout_desc Output dropout memory descriptor\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_get_dropout(
        attr: const_dnnl_primitive_attr_t,
        dropout_desc: *mut const_dnnl_memory_desc_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets probability for output dropout primitive attribute.\n\n @param attr Primitive attributes.\n @param dropout_desc Output dropout memory descriptor\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_set_dropout(
        attr: dnnl_primitive_attr_t,
        dropout_desc: const_dnnl_memory_desc_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the floating-point math mode primitive attribute.\n\n @param attr Primitive attributes.\n @param mode Output FP math mode.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_get_fpmath_mode(
        attr: const_dnnl_primitive_attr_t,
        mode: *mut dnnl_fpmath_mode_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets the floating-point math mode primitive attributes.\n\n @param attr Primitive attributes.\n @param mode FP math mode. The possible values are:\n     #dnnl_fpmath_mode_strict (default),\n     #dnnl_fpmath_mode_bf16,\n     #dnnl_fpmath_mode_f16,\n     #dnnl_fpmath_mode_tf32,\n     #dnnl_fpmath_mode_any.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_set_fpmath_mode(
        attr: dnnl_primitive_attr_t,
        mode: dnnl_fpmath_mode_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the floating-point math mode primitive attribute.\n\n @param attr Primitive attributes.\n @param mode Output FP math mode.\n @param apply_to_int Output use floating-point arithmetic for integer primitives.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_get_fpmath_mode_v2(
        attr: const_dnnl_primitive_attr_t,
        mode: *mut dnnl_fpmath_mode_t::Type,
        apply_to_int: *mut ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets the floating-point math mode primitive attributes.\n\n @param attr Primitive attributes.\n @param mode FP math mode. The possible values are:\n     #dnnl_fpmath_mode_strict (default),\n     #dnnl_fpmath_mode_bf16,\n     #dnnl_fpmath_mode_f16,\n     #dnnl_fpmath_mode_tf32,\n     #dnnl_fpmath_mode_any.\n @param apply_to_int Boolean. Use of floating-point arithmetic for integer primitives.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_set_fpmath_mode_v2(
        attr: dnnl_primitive_attr_t,
        mode: dnnl_fpmath_mode_t::Type,
        apply_to_int: ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the deterministic primitive attribute value.\n\n @param attr Primitive attributes.\n @param value Output deterministic attribute value\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_get_deterministic(
        attr: const_dnnl_primitive_attr_t,
        value: *mut ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets the deterministic primitive attribute value.\n\n @param attr Primitive attributes.\n @param value Boolean value to set deterministic attribute.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_set_deterministic(
        attr: dnnl_primitive_attr_t,
        value: ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the accumulation mode primitive attribute.\n\n @param attr Primitive attributes.\n @param mode Output accumulation mode.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_get_accumulation_mode(
        attr: const_dnnl_primitive_attr_t,
        mode: *mut dnnl_accumulation_mode_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets the accumulation mode primitive attribute.\n\n @param attr Primitive attributes.\n @param mode Accumulation mode. The possible values are:\n     #dnnl_accumulation_mode_strict (default), which is s32 for quantized primitives, f32/f64 otherwise\n     #dnnl_accumulation_mode_relaxed, which is same as strict but allows intermediate accumulators to be in src/dst datatype\n     #dnnl_accumulation_mode_any, which allows accumulators to be src/dst datatype or any wider type.\n     #dnnl_accumulation_mode_f32,\n     #dnnl_accumulation_mode_s32,\n     #dnnl_accumulation_mode_f16.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_set_accumulation_mode(
        attr: dnnl_primitive_attr_t,
        mode: dnnl_accumulation_mode_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the primitive attributes scratchpad mode.\n\n @param attr Primitive attributes.\n @param mode Output scratchpad mode.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_get_scratchpad_mode(
        attr: const_dnnl_primitive_attr_t,
        mode: *mut dnnl_scratchpad_mode_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets primitive attributes scratchpad mode.\n\n @param attr Primitive attributes.\n @param mode Scratchpad mode. The possible values are:\n     #dnnl_scratchpad_mode_library (default) and\n     #dnnl_scratchpad_mode_user.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_set_scratchpad_mode(
        attr: dnnl_primitive_attr_t,
        mode: dnnl_scratchpad_mode_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets primitive attributes scaling factors for primitive operations for a\n given memory argument. The scaling factors must be passed at execution time\n as an argument with index #DNNL_ARG_ATTR_SCALES | arg.\n\n @sa dnnl_primitive_attr_set_scales_mask\n\n\n @param attr Primitive attributes.\n @param arg Parameter argument index as passed to the\n     dnnl_primitive_execute() call.\n @param mask Scaling factors correspondence mask that defines the\n     correspondence between the tensor dimensions and the @p scales array.\n     The set i-th bit indicates that a dedicated scaling factor is used for\n     each index along that dimension. Set the mask to 0 to use a common\n     scaling factor for the whole output tensor.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_set_scales_mask(
        attr: dnnl_primitive_attr_t,
        arg: ::std::os::raw::c_int,
        mask: ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets primitive attributes scaling factors for primitive operations for a\n given memory argument. The scaling factors must be passed at execution time\n as an argument with index #DNNL_ARG_ATTR_SCALES | arg.\n\n @sa dnnl_primitive_attr_set_scales\n\n\n @param attr Primitive attributes.\n @param arg Parameter argument index as passed to the\n     dnnl_primitive_execute() call.\n @param mask Scaling factors correspondence mask that defines the\n     correspondence between the tensor dimensions and the @p scales array.\n     The set i-th bit indicates that a dedicated scaling factor is used for\n     each index along that dimension. Set the mask to 0 to use a common\n     scaling factor for the whole output tensor.\n @param ndims Number of group dimensions.\n @param group_dims Scaling factors correspondence groups that define the\n     correspondence between the tensor dimensions and the scales array.\n     The group dimensions should only be provided for each logical dimension\n     that has correspondence mask @p mask set.\n @param data_type Scaling factors data_type.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_set_scales(
        attr: dnnl_primitive_attr_t,
        arg: ::std::os::raw::c_int,
        mask: ::std::os::raw::c_int,
        ndims: ::std::os::raw::c_int,
        group_dims: *const dnnl_dim_t,
        data_type: dnnl_data_type_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets primitive attributes zero points for primitive operations for a given\n memory argument. The zero points must be passed at execution time\n as an argument with index #DNNL_ARG_ATTR_ZERO_POINTS | arg.\n\n @sa dnnl_primitive_attr_set_zero_points_mask\n\n\n @param attr Primitive attributes.\n @param arg Parameter argument index as passed to the\n     dnnl_primitive_execute() call.\n @param mask Zero point correspondence mask that defines the\n     correspondence between the tensor dimensions and the @p\n     zero_points array. The set i-th bit indicates that a dedicated\n     zero point is used for each index along that dimension. Set the\n     mask to 0 to use a common zero point for the whole output tensor.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_set_zero_points_mask(
        attr: dnnl_primitive_attr_t,
        arg: ::std::os::raw::c_int,
        mask: ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets primitive attributes zero points for primitive operations for a given\n memory argument. The zero points must be passed at execution time\n as an argument with index #DNNL_ARG_ATTR_ZERO_POINTS | arg.\n\n @sa dnnl_primitive_attr_set_zero_points\n\n\n @param attr Primitive attributes.\n @param arg Parameter argument index as passed to the\n     dnnl_primitive_execute() call.\n @param mask Zero point correspondence mask that defines the\n     correspondence between the tensor dimensions and the @p\n     zero_points array. The set i-th bit indicates that a dedicated\n     zero point is used for each index along that dimension. Set the\n     mask to 0 to use a common zero point for the whole output tensor.\n @param ndims Number of group dimensions.\n @param group_dims Zero point factors correspondence groups that define the\n     correspondence between the tensor dimensions and the zero_points array.\n     The group dimensions should be only provided for each logical dimension\n     that has the bit set correspondence mask @p mask set.\n @param data_type Zero points factors data_type.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_set_zero_points(
        attr: dnnl_primitive_attr_t,
        arg: ::std::os::raw::c_int,
        mask: ::std::os::raw::c_int,
        ndims: ::std::os::raw::c_int,
        group_dims: *const dnnl_dim_t,
        data_type: dnnl_data_type_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets the rounding mode attribute value for a given argument\n\n @param attr Primitive attributes.\n @param arg Argument for which rounding mode should be set.\n @param mode Rounding mode to apply to the argument.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_set_rounding(
        attr: dnnl_primitive_attr_t,
        arg: ::std::os::raw::c_int,
        mode: dnnl_rounding_mode_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the rounding mode attribute value for a given argument\n\n @param attr Primitive attributes.\n @param arg Argument for which rounding mode query applies.\n @param mode Output rounding mode.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_get_rounding(
        attr: dnnl_primitive_attr_t,
        arg: ::std::os::raw::c_int,
        mode: *mut dnnl_rounding_mode_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns primitive attributes post-ops.\n\n @warning\n     The output @p post_ops points to the internal @p attr field, so it is\n     an error to modify or destroy them. The lifetime of @p post_ops is\n     the same as that of the @p attr it belongs to, so it is an error to\n     use @p post_ops after @p attr has been destroyed.\n\n @param attr Primitive attributes.\n @param post_ops Output post-ops.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_get_post_ops(
        attr: const_dnnl_primitive_attr_t,
        post_ops: *mut const_dnnl_post_ops_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets primitive attributes post-ops.\n\n @note\n     There is no way to check whether the post-ops would be supported by\n     the target primitive. Any error will be reported by the\n     dnnl_<primitive name>_[propagation kind]_primitive_desc_create() function call.\n\n @param attr Primitive attributes.\n @param post_ops Post-ops to set.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_set_post_ops(
        attr: dnnl_primitive_attr_t,
        post_ops: const_dnnl_post_ops_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates empty post-ops sequence.\n\n @param post_ops Output post-ops.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_post_ops_create(post_ops: *mut dnnl_post_ops_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Clones post-ops primitive attribute.\n\n @param post_ops Output post-ops primitive attribute.\n @param existing_post_ops Post-ops primitive attribute to clone.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_post_ops_clone(
        post_ops: *mut dnnl_post_ops_t,
        existing_post_ops: const_dnnl_post_ops_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Destroys post-ops.\n\n @param post_ops Post-ops to destroy.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_post_ops_destroy(post_ops: dnnl_post_ops_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the length of post-ops.\n\n @param post_ops Post-ops.\n @returns The number of post-ops entries."]
    pub fn dnnl_post_ops_len(post_ops: const_dnnl_post_ops_t) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Returns the kind of a post-op entry.\n\n @param post_ops Post-ops.\n @param index Post-op entry index.\n @returns The kind of the post-op with the specified index.\n @returns #dnnl_undefined_primitive if there is no post-op at the specified\n     index."]
    pub fn dnnl_post_ops_get_kind(
        post_ops: const_dnnl_post_ops_t,
        index: ::std::os::raw::c_int,
    ) -> dnnl_primitive_kind_t::Type;
}
unsafe extern "C" {
    #[doc = " Appends an accumulation v3 (sum) to post-ops. Prior to accumulating the\n result, a zero point is subtracted from the previous value and is\n multiplied by the scale.\n\n The kind of this post-op is #dnnl_sum.\n\n This feature may improve performance for cases like dequantize the\n asymmetrically quantized sum's src1 tensor to f32 domain before performing\n the sum operation by subtracting the @p zero_point before the scaling.\n\n In the simplest case where accumulation is the only post-op, the\n computations will be:\n\n     dst[:] <- scale * (dst[:] - zero_point) + op(...)\n                                             // instead of dst[:] <- op(...)\n\n If @p data_type is specified, original dst tensor will be reinterpreted\n as a tensor with provided data type. Since it is reinterpretation,\n data_type and dst data type should have the same size.\n As a result, computations will be:\n\n     dst[:] <- scale * (as_data_type(dst[:]) - zero_point) + op(...)\n                                        // instead of dst[:] <- op(...)\n @note\n     This post-op executes in-place and does not change the\n     destination layout.\n\n @param post_ops Post-ops.\n @param scale Accumulation scaling factor.\n @param zero_point Single scalar int32_t value of zero point.\n @param data_type Accumulation data_type.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_post_ops_append_sum(
        post_ops: dnnl_post_ops_t,
        scale: f32,
        zero_point: i32,
        data_type: dnnl_data_type_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the parameters of an accumulation (sum) post-op with\n zero point and data type parameter.\n\n @param post_ops Post-ops.\n @param index Index of the sum post-op.\n @param scale Output accumulation scaling factor.\n @param zero_point Zero point.\n @param data_type Data type for accumulation.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_post_ops_get_params_sum(
        post_ops: const_dnnl_post_ops_t,
        index: ::std::os::raw::c_int,
        scale: *mut f32,
        zero_point: *mut i32,
        data_type: *mut dnnl_data_type_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Appends an elementwise post-op.\n\n The kind of this post operation is #dnnl_eltwise.\n\n In the simplest case when the elementwise is the only post operation, the\n computations would be:\n\n     dst[:] <- eltwise_op (op(...)) // instead of dst[:] <- op(...)\n\n where eltwise_op is configured with the given parameters.\n\n @param post_ops Post-ops.\n @param alg_kind Elementwise algorithm for the post-op.\n @param alpha Alpha parameter for the elementwise algorithm.\n @param beta Beta parameter for the elementwise algorithm.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_post_ops_append_eltwise(
        post_ops: dnnl_post_ops_t,
        alg_kind: dnnl_alg_kind_t::Type,
        alpha: f32,
        beta: f32,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the parameters of an elementwise post-op.\n\n @param post_ops Post-ops.\n @param index Index of the elementwise post-op.\n @param alg_kind Output elementwise algorithm kind.\n @param alpha Output alpha parameter for the elementwise algorithm.\n @param beta Output beta parameter for the elementwise algorithm.\n @returns #dnnl_success on success and a status describing the error\n     otherwise.\n @returns #dnnl_invalid_arguments if @p index does not refer to an\n     elementwise post-op."]
    pub fn dnnl_post_ops_get_params_eltwise(
        post_ops: const_dnnl_post_ops_t,
        index: ::std::os::raw::c_int,
        alg_kind: *mut dnnl_alg_kind_t::Type,
        alpha: *mut f32,
        beta: *mut f32,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Appends a depthwise post-op convolution.\n\n This post-op can only be fused with a 2D 1x1 convolution (convolution with\n weights spatial dimensions equal to 1 i.e., kh=kw=1).\n\n The kind of this post-op is #dnnl_convolution.\n\n The number of outputs for primitive with fusion is one. The output spatial\n size can be derived as below:\n\n output_height = ceil(output_height_1x1_convolution, stride)\n output_width = ceil(output_width_1x1_convolution, stride)\n\n See @ref dev_guide_attributes_post_ops_depthwise and\n @ref dev_guide_attributes_post_ops_depthwise_fusion for more info.\n\n @param post_ops Post-ops.\n @param weights_data_type Weights data type of depthwise post-op\n @param bias_data_type Bias data type of depthwise post-op\n @param dst_data_type Output data type of depthwise post-op\n @param kernel_size Size of kernel of depthwise post-op\n @param stride_size Size of stride of depthwise post-op\n @param padding_l_size Size of left and top paddings of depthwise post-op\n @returns #dnnl_success on success and a status describing the error\n     otherwise"]
    pub fn dnnl_post_ops_append_dw(
        post_ops: dnnl_post_ops_t,
        weights_data_type: dnnl_data_type_t::Type,
        bias_data_type: dnnl_data_type_t::Type,
        dst_data_type: dnnl_data_type_t::Type,
        kernel_size: dnnl_dim_t,
        stride_size: dnnl_dim_t,
        padding_l_size: dnnl_dim_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the parameters of an depthwise post-op.\n\n @param post_ops Post-ops.\n @param index Index of the elementwise post-op.\n @param weights_data_type Weights data type of depthwise post-op\n @param bias_data_type Bias data type of depthwise post-op\n @param dst_data_type Output data type of depthwise post-op\n @param kernel_size Size of kernel of depthwise post-op\n @param stride_size Size of stride of depthwise post-op\n @param padding_l_size Size of left and top paddings of depthwise post-op\n @returns #dnnl_success on success and a status describing the error\n     otherwise"]
    pub fn dnnl_post_ops_get_params_dw(
        post_ops: const_dnnl_post_ops_t,
        index: ::std::os::raw::c_int,
        weights_data_type: *mut dnnl_data_type_t::Type,
        bias_data_type: *mut dnnl_data_type_t::Type,
        dst_data_type: *mut dnnl_data_type_t::Type,
        kernel_size: *mut dnnl_dim_t,
        stride_size: *mut dnnl_dim_t,
        padding_l_size: *mut dnnl_dim_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Appends a binary post-op.\n\n The kind of this post operation is #dnnl_binary.\n\n In the simplest case when the binary is the only post operation, the\n computations would be:\n\n     dst[:] <- binary_op (dst[:], another_input[:])\n\n where binary_op is configured with the given parameters. binary_op supports\n broadcast semantics for a second operand.\n\n @param post_ops Post-ops.\n @param alg_kind Binary algorithm for the post-op.\n @param src1_desc Memory descriptor of a second operand.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_post_ops_append_binary(
        post_ops: dnnl_post_ops_t,
        alg_kind: dnnl_alg_kind_t::Type,
        src1_desc: const_dnnl_memory_desc_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the parameters of a binary post-op.\n\n @param post_ops Post-ops.\n @param index Index of the binary post-op.\n @param alg_kind Output binary algorithm kind.\n @param src1_desc Output memory descriptor of a second operand.\n @returns #dnnl_success on success and a status describing the error\n     otherwise.\n @returns #dnnl_invalid_arguments if @p index does not refer to a binary\n     post-op."]
    pub fn dnnl_post_ops_get_params_binary(
        post_ops: const_dnnl_post_ops_t,
        index: ::std::os::raw::c_int,
        alg_kind: *mut dnnl_alg_kind_t::Type,
        src1_desc: *mut const_dnnl_memory_desc_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Appends a prelu forward post-op.\n\n The kind of this post-op is #dnnl::primitive::kind::prelu.\n\n The post-op can be defined as:\n\n      dst[:] <- prelu(dst[:], weights[:])\n      prelu:\n      dst[:] <- dst[:] if dst[:] > 0\n      dst[:] <- dst[:] * weights[:] if dst[:] <= 0\n\n\n @note\n     The order of dimensions does not depend on how elements are laid\n     out in memory. For example:\n     - for a 2D CNN activations tensor the order is always (n, c)\n     - for a 4D CNN activations tensor the order is always (n, c, h, w)\n     - for a 5D CNN weights tensor the order is always\n        (g, oc, ic, kh, kw)\n\n    Prelu weights tensor is passed in runtime execution phase. Prelu\n    weights tensor data type is implicitly assumed as f32 using plain\n    layout (a, ab, acb, acdb, acdeb)\n\n @param post_ops Post-ops.\n @param mask Defines the correspondence between the output tensor\n     dimensions and the prelu weights tensor. The set i-th bit indicates\n     that a dedicated weights value is used for each index along that\n     dimension. Set the mask to 0 to use a common weights value\n     for the whole output tensor.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_post_ops_append_prelu(
        post_ops: dnnl_post_ops_t,
        mask: ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the parameters of a prelu post-op.\n\n @param post_ops Post-ops.\n @param index Index of the prelu post-op.\n @param mask Mask of the prelu post-op.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_post_ops_get_params_prelu(
        post_ops: const_dnnl_post_ops_t,
        index: ::std::os::raw::c_int,
        mask: *mut ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Destroys a memory descriptor.\n\n @param memory_desc Memory descriptor to destroy.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_desc_destroy(memory_desc: dnnl_memory_desc_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Clones a memory descriptor. The resulting memory descriptor must be\n destroyed separately.\n\n @param memory_desc Output memory descriptor.\n @param existing_memory_desc Memory descriptor to clone.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_desc_clone(
        memory_desc: *mut dnnl_memory_desc_t,
        existing_memory_desc: const_dnnl_memory_desc_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Retrieves a binary blob associated with the given memory descriptor\n\n @param blob Output pointer to binary blob.\n     If not nullptr, size bytes of the memory descriptor blob are written.\n @param size Output pointer to the size of the binary blob in bytes.\n     Size is written if blob is nullptr.\n @param memory_desc input memory descriptor to serialize\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_desc_get_blob(
        blob: *mut u8,
        size: *mut usize,
        memory_desc: const_dnnl_memory_desc_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a memory descriptor from a memory descriptor binary blob.\n\n @param memory_desc Output pointer to a newly allocated memory descriptor.\n @param blob Pointer to a memory descriptor binary blob.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_desc_create_with_blob(
        memory_desc: *mut dnnl_memory_desc_t,
        blob: *const u8,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a memory descriptor using dimensions and strides.\n\n @note\n     As always, the logical order of dimensions corresponds to the `abc...`\n     format tag, and the physical meaning of the dimensions depends on both\n     the primitive that consumes the memory and the context of that\n     consumption.\n\n @param memory_desc Output memory descriptor.\n @param ndims Number of dimensions\n @param dims Array of dimensions.\n @param data_type Elements data type.\n @param strides Strides in each dimension.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_desc_create_with_strides(
        memory_desc: *mut dnnl_memory_desc_t,
        ndims: ::std::os::raw::c_int,
        dims: *const dnnl_dim_t,
        data_type: dnnl_data_type_t::Type,
        strides: *const dnnl_dim_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a memory descriptor using dimensions and memory format tag.\n\n @note\n     As always, the logical order of dimensions corresponds to the `abc...`\n     format tag, and the physical meaning of the dimensions depends on both\n     the primitive that consumes the memory and the context of that\n     consumption.\n\n @param memory_desc Output memory descriptor.\n @param ndims Number of dimensions\n @param dims Array of dimensions.\n @param data_type Elements data type.\n @param tag Memory format tag. Can be #dnnl_format_tag_any which would\n     allow a primitive to chose the final memory format. In this case the\n     format_kind field of the memory descriptor would be set to\n     #dnnl_format_kind_any.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_desc_create_with_tag(
        memory_desc: *mut dnnl_memory_desc_t,
        ndims: ::std::os::raw::c_int,
        dims: *const dnnl_dim_t,
        data_type: dnnl_data_type_t::Type,
        tag: dnnl_format_tag_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " @param memory_desc Output memory descriptor.\n @param parent_memory_desc An existing memory descriptor.\n @param dims Sizes of the region.\n @param offsets Offsets to the region from the encompassing\n     memory object in each dimension\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_desc_create_submemory(
        memory_desc: *mut dnnl_memory_desc_t,
        parent_memory_desc: const_dnnl_memory_desc_t,
        dims: *const dnnl_dim_t,
        offsets: *const dnnl_dim_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a memory descriptor by reshaping an existing one. The new\n memory descriptor inherits the data type. This operation is valid only for\n memory descriptors that have format_kind #dnnl_blocked or\n #dnnl_format_kind_any.\n\n The resulting memory descriptor must be destroyed separately.\n\n The operation ensures the transformation of the physical memory format\n corresponds to the transformation of the logical dimensions. If such\n transformation is impossible, the function returns #dnnl_invalid_arguments.\n\n The reshape operation can be described as a combination of the following\n basic operations:\n 1. Add a dimension of size `1`. This is always possible.\n 2. Remove a dimension of size `1`. This is possible only if the dimension\n    has no padding (i.e. `padded_dims[dim] == dims[dim] && dims[dim] == 1`).\n 3. Split a dimension into multiple ones. This is possible only if the size\n    of the dimension is exactly equal to the product of the split ones and\n    the dimension does not have padding (i.e.\n    `padded_dims[dim] = dims[dim]`).\n 4. Joining multiple consecutive dimensions into a single one. As in the\n    cases above, this requires that the dimensions do not have padding and\n    that the memory format is such that in physical memory these dimensions\n    are dense and have the same order as their logical counterparts. This\n    also assumes that these dimensions are not blocked.\n    - Here, dense means:\n      `stride for dim[i] == (stride for dim[i + 1]) * dim[i + 1]`;\n    - And same order means:\n      `i < j` if and only if `stride for dim[j] <= stride for dim[i]`.\n\n @warning\n     Some combinations of physical memory layout and/or offsets or\n     dimensions may result in a failure to make a reshape.\n\n @param out_memory_desc Output memory descriptor.\n @param in_memory_desc An existing memory descriptor. Must have format_kind\n     set to #dnnl_blocked or #dnnl_format_kind_any.\n @param ndims Number of dimensions for the output memory descriptor.\n @param dims Dimensions for the output memory descriptor.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_desc_reshape(
        out_memory_desc: *mut dnnl_memory_desc_t,
        in_memory_desc: const_dnnl_memory_desc_t,
        ndims: ::std::os::raw::c_int,
        dims: *const dnnl_dim_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a memory descriptor by permuting axes in an existing one.\n\n The physical memory layout representation is adjusted accordingly to\n maintain the consistency between the logical and physical parts of the\n memory descriptor.\n\n The resulting memory descriptor must be destroyed separately.\n\n The new memory descriptor inherits the data type. This operation is valid\n only for memory descriptors that have format_kind set to #dnnl_blocked or\n #dnnl_format_kind_any.\n\n The logical axes will be permuted in the following manner:\n ```\n for (i: 0 .. in_memory_desc->ndims)\n     out_memory_desc->dims[permutation[i]] = in_memory_desc->dims[i];\n ```\n\n Example:\n @code\n     dnnl_memory_desc_t in_md, out_md, expect_out_md;\n\n     const int permutation[] = {1, 0}; // swap the first and the second axes\n\n     dnnl_dims_t in_dims = {2, 3}, out_dims = {3, 2};\n     dnnl_format_tag_t in_tag = dnnl_ab, out_tag = dnnl_ba;\n\n     dnnl_memory_desc_create_with_tag(\n             &in_md, 2, in_dims, data_type, in_tag);\n     dnnl_memory_desc_create_with_tag(\n             &expect_out_md, 2, out_dims, data_type, out_tag);\n\n     dnnl_memory_desc_permute_axes(&out_md, in_md, permutation);\n     assert(dnnl_memory_desc_equal(out_md, expect_out_md));\n\n     dnnl_memory_desc_destroy(in_md);\n     dnnl_memory_desc_destroy(out_md);\n     dnnl_memory_desc_destroy(expect_out_md);\n @endcode\n\n @param out_memory_desc Output memory descriptor.\n @param in_memory_desc An existing memory descriptor. Must have format_kind\n     set to #dnnl_blocked or #dnnl_format_kind_any.\n @param permutation Axes permutation (of size `in_memory_desc->ndims`).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_desc_permute_axes(
        out_memory_desc: *mut dnnl_memory_desc_t,
        in_memory_desc: const_dnnl_memory_desc_t,
        permutation: *const ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Queries a memory descriptor for various pieces of information.\n\n The following information can be queried:\n  - Number of dimensions (#dnnl_query_ndims_s32)\n  - Dimensions (#dnnl_query_dims) in the following order:\n    - CNN data tensors: mini-batch, channel, spatial\n      (<code>{N, C, [[D,] H,] W}</code>)\n    - CNN weight tensors: group (optional), output channel, input channel,\n      spatial (<code>{[G,] O, I, [[D,] H,] W}</code>)\n    - RNN data tensors: time, mini-batch, channels (<code>{T, N, C}</code>)\n      or layers, directions, states, mini-batch, channels\n      (<code>{L, D, S, N, C}</code>)\n    - RNN weight tensor: layers, directions, input channel, gates, output\n      channels (<code>{L, D, I, G, O}</code>)\n  - Data type of the tensor elements (#dnnl_query_data_type)\n  - Padded dimensions (#dnnl_query_padded_dims) - size of the data including\n    padding in each dimension\n  - Padded offsets (#dnnl_query_padded_offsets) - per-dimension offset from\n    the padding to actual data, the top-level tensor with offsets applied\n    must lie within the padding area.\n  - Submemory offset (#dnnl_query_submemory_offset_s64) - offset from memory\n    origin to the current block, non-zero only in a description of a memory\n    sub-block.\n  - Format kind (#dnnl_query_format_kind) - memory format kind\n\n @note\n    The order of dimensions does not depend on the memory format, so\n    whether the data is laid out in #dnnl_nchw or #dnnl_nhwc\n    the dims for 4D CN data tensor would be <code>{N, C, H, W}</code>.\n\n The following queries are applicable only to format kind #dnnl_blocked.\n  - Strides (#dnnl_query_strides) between the outermost blocks or in case\n    of plain (non-blocked) formats the strides between dimensions\n  - Number of innermost blocks (#dnnl_query_inner_nblks_s32), e.g.\n    `{4, 16, 4}` in case of `OIhw_4i16o4i`\n  - Size of the innermost blocks (#dnnl_query_inner_blks), e.g. 3 in case\n    of `OIhw_4i16o4i_`\n  - Logical indices of the blocks (#dnnl_query_inner_idxs), e.g. `{1, 0, 1}`\n    in case of `4i16o4i`, because `i` is the 1st dim and `o` is the 0st dim\n\n @param memory_desc Memory descriptor.\n @param what Parameter to query.\n @param result Output result. The type depends on the query. For example,\n     it must be a @c dnnl_dims_t** if querying for a strides.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_desc_query(
        memory_desc: const_dnnl_memory_desc_t,
        what: dnnl_query_t::Type,
        result: *mut ::std::os::raw::c_void,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Compares two memory descriptors.\n\n Use this function to identify whether a reorder is required between the\n two memories\n\n @param lhs Left-hand side of the comparison.\n @param rhs Right-hand side of the comparison.\n @returns 1 if the descriptors are the same.\n @returns 0 if the descriptors are different."]
    pub fn dnnl_memory_desc_equal(
        lhs: const_dnnl_memory_desc_t,
        rhs: const_dnnl_memory_desc_t,
    ) -> ::std::os::raw::c_int;
}
unsafe extern "C" {
    #[doc = " Returns the size of a memory descriptor.\n\n @param memory_desc Memory descriptor.\n @returns The number of bytes required for memory described by a memory\n     descriptor."]
    pub fn dnnl_memory_desc_get_size(memory_desc: const_dnnl_memory_desc_t) -> usize;
}
unsafe extern "C" {
    #[doc = " Returns the size of data type.\n\n @param data_type Data type.\n @returns The number of bytes occupied by data type."]
    pub fn dnnl_data_type_size(data_type: dnnl_data_type_t::Type) -> usize;
}
unsafe extern "C" {
    #[doc = " Creates a memory object.\n\n Unless @p handle is equal to DNNL_MEMORY_NONE, the constructed memory\n object will have the underlying buffer set. In this case, the buffer will\n be initialized as if dnnl_memory_set_data_handle() had been called.\n\n @sa dnnl_memory_set_data_handle()\n\n @param memory Output memory object.\n @param memory_desc Memory descriptor.\n @param engine Engine to use.\n @param handle Handle of the memory buffer to use as an underlying storage.\n     - A pointer to the user-allocated buffer. In this case the library\n       doesn't own the buffer.\n     - The DNNL_MEMORY_ALLOCATE special value. Instructs the library to\n       allocate the buffer for the memory object. In this case the library\n       owns the buffer.\n     - DNNL_MEMORY_NONE to create dnnl_memory without an underlying buffer.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_create(
        memory: *mut dnnl_memory_t,
        memory_desc: const_dnnl_memory_desc_t,
        engine: dnnl_engine_t,
        handle: *mut ::std::os::raw::c_void,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the memory descriptor for a memory object.\n\n @param memory Memory object.\n @param memory_desc Output memory descriptor (a copy).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_get_memory_desc(
        memory: const_dnnl_memory_t,
        memory_desc: *mut const_dnnl_memory_desc_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the engine of a memory object.\n\n @param memory Memory object.\n @param engine Output engine on which the memory is located.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_get_engine(
        memory: const_dnnl_memory_t,
        engine: *mut dnnl_engine_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Maps a memory object and returns a host-side pointer to a memory buffer\n with a copy of its contents.\n\n Mapping enables explicit direct access to memory contents for the engines\n that do not support it implicitly.\n\n Mapping is an exclusive operation - a memory object cannot be used in\n other operations until this memory object is unmapped.\n\n @note\n     Any primitives working with @p memory should be completed before\n     the memory is mapped. Use dnnl_stream_wait to synchronize the\n     corresponding execution stream.\n\n @note\n     The dnnl_memory_map_data() and dnnl_memory_unmap_data() functions are\n     mainly provided for debug and testing purposes, and their performance\n     may be suboptimal.\n\n @param memory Memory object.\n @param mapped_ptr Output pointer to the mapped buffer.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_map_data(
        memory: const_dnnl_memory_t,
        mapped_ptr: *mut *mut ::std::os::raw::c_void,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Unmaps a memory object and writes back any changes made to the previously\n mapped memory buffer. The pointer to the mapped buffer must be obtained\n via the dnnl_memory_map_data() call.\n\n @note\n     The dnnl_memory_map_data() and dnnl_memory_unmap_data() functions are\n     mainly provided for debug and testing purposes, and their performance\n     may be suboptimal.\n\n @param memory Memory object.\n @param mapped_ptr Pointer to the mapped buffer that must have been\n     obtained using the dnnl_memory_map_data() function.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_unmap_data(
        memory: const_dnnl_memory_t,
        mapped_ptr: *mut ::std::os::raw::c_void,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns memory object's data handle.\n\n @param memory Memory object.\n @param handle Output data handle. For the CPU engine, the data handle is a\n     pointer to the actual data. For OpenCL it is a cl_mem.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_get_data_handle(
        memory: const_dnnl_memory_t,
        handle: *mut *mut ::std::os::raw::c_void,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets the underlying memory buffer.\n\n @param memory Memory object.\n @param handle Data handle. For the CPU engine or when USM is used, the\n     memory buffer is a pointer to the actual data. For OpenCL it is a\n     `cl_mem`.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_set_data_handle(
        memory: dnnl_memory_t,
        handle: *mut ::std::os::raw::c_void,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Destroys a memory object.\n\n @param memory Memory object to destroy.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_memory_destroy(memory: dnnl_memory_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a reorder primitive.\n\n @param reorder_primitive_desc Output primitive descriptor.\n @param src_desc Source memory descriptor.\n @param src_engine Engine on which the source memory object will be\n     located.\n @param dst_desc Destination memory descriptor.\n @param dst_engine Engine on which the destination memory object\n     will be located.\n @param attr Primitive attributes to use (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_reorder_primitive_desc_create(
        reorder_primitive_desc: *mut dnnl_primitive_desc_t,
        src_desc: const_dnnl_memory_desc_t,
        src_engine: dnnl_engine_t,
        dst_desc: const_dnnl_memory_desc_t,
        dst_engine: dnnl_engine_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for an out-of-place concatenation\n primitive.\n\n @param concat_primitive_desc Output primitive descriptor.\n @param dst_desc Destination memory descriptor.\n @param n Number of source parameters.\n @param concat_dimension Source tensors will be concatenated over\n     dimension with this index. Note that order of dimensions does\n     not depend on memory format.\n @param src_descs Array of source memory descriptors with @p n elements.\n @param attr Primitive attributes to use (can be NULL).\n @param engine Engine to use.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_concat_primitive_desc_create(
        concat_primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        dst_desc: const_dnnl_memory_desc_t,
        n: ::std::os::raw::c_int,
        concat_dimension: ::std::os::raw::c_int,
        src_descs: *const const_dnnl_memory_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for an (out-of-place) sum primitive.\n\n @param sum_primitive_desc Output primitive descriptor.\n @param dst_desc Destination memory descriptor.\n @param n Number of source parameters.\n @param scales Vector of scales to multiply data in each source\n     memory by.\n @param src_descs Array of source memory descriptors having @p n elements.\n @param attr Primitive attributes to use (can be NULL).\n @param engine Engine to use.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_sum_primitive_desc_create(
        sum_primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        dst_desc: const_dnnl_memory_desc_t,
        n: ::std::os::raw::c_int,
        scales: *const f32,
        src_descs: *const const_dnnl_memory_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a binary primitive.\n\n @note\n     Memory descriptors @p src1_desc and @p dst_desc are allowed to be\n     initialized with #dnnl_format_tag_any or with format_kind set to\n     #dnnl_format_kind_any.\n\n @note\n     Both memory descriptors must have the same number of dimensions.\n     Element broadcasting is supported for memory descriptor @p src1_desc\n     and are applied to @p src1_desc dimensions that have size equal to 1.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param alg_kind Algorithm kind. Valid values are #dnnl_binary_add,\n     #dnnl_binary_mul, #dnnl_binary_max, #dnnl_binary_min, #dnnl_binary_div,\n     #dnnl_binary_sub, #dnnl_binary_ge, #dnnl_binary_gt, #dnnl_binary_le,\n     #dnnl_binary_lt, #dnnl_binary_eq and #dnnl_binary_ne.\n @param src0_desc Source 0 memory descriptor.\n @param src1_desc Source 1 memory descriptor.\n @param dst_desc Destination memory descriptor.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_binary_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        alg_kind: dnnl_alg_kind_t::Type,
        src0_desc: const_dnnl_memory_desc_t,
        src1_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a binary primitive with support of\n ternary operators.\n\n @note\n     Memory descriptors @p src1_desc, @p src2_desc and @p dst_desc are\n     allowed to be initialized with #dnnl_format_tag_any or with format_kind\n     set to #dnnl_format_kind_any.\n\n @note\n     All memory descriptors must have the same number of dimensions.\n     Element broadcasting is supported for memory descriptor @p src1_desc\n     and is applied to @p src1_desc dimensions that have a size equal to 1.\n     There is no broadcasting support for @p src2_desc.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param alg_kind Algorithm kind.\n @param src0_desc Source 0 memory descriptor.\n @param src1_desc Source 1 memory descriptor.\n @param src2_desc Source memory descriptor for ternary operations. Might\n     be empty.\n @param dst_desc Destination memory descriptor.\n @param attr Primitive attributes.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_binary_primitive_desc_create_v2(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        alg_kind: dnnl_alg_kind_t::Type,
        src0_desc: const_dnnl_memory_desc_t,
        src1_desc: const_dnnl_memory_desc_t,
        src2_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a convolution forward propagation\n     primitive.\n\n @note\n     Memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n Arrays @p strides, @p dilates, @p padding_l, and @p padding_r contain\n values for spatial dimensions only and hence must have the same number of\n elements as there are spatial dimensions. The order of values is the same\n as in the tensor: depth (for 3D tensors), height (for 3D and 2D tensors),\n and width.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param alg_kind Convolution algorithm. Possible values are\n     #dnnl_convolution_direct, #dnnl_convolution_winograd,\n     #dnnl_convolution_auto.\n @param src_desc Source memory descriptor.\n @param weights_desc Weights memory descriptor.\n @param bias_desc Bias memory descriptor. Passing NULL, a zero memory\n     descriptor, or a memory descriptor with format_kind set to\n     #dnnl_format_kind_undef disables the bias term.\n @param dst_desc Destination memory descriptor.\n @param strides Array of strides for spatial dimension.\n @param dilates Array of dilations for spatial dimension. A zero value\n     means no dilation in the corresponding dimension.\n @param padding_l Array of padding values for low indices for each spatial\n     dimension `([[front,] top,] left)`.\n @param padding_r Array of padding values for high indices for each spatial\n     dimension `([[back,] bottom,] right)`. Can be NULL in which case\n     padding is considered to be symmetrical.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_convolution_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        alg_kind: dnnl_alg_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        weights_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        strides: *const dnnl_dim_t,
        dilates: *const dnnl_dim_t,
        padding_l: *const dnnl_dim_t,
        padding_r: *const dnnl_dim_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a convolution backward propagation\n     primitive.\n\n @note\n     Memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n Arrays @p strides, @p dilates, @p padding_l, and @p padding_r contain\n values for spatial dimensions only and hence must have the same number of\n elements as there are spatial dimensions. The order of values is the same\n as in the tensor: depth (for 3D tensors), height (for 3D and 2D tensors),\n and width.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param alg_kind Convolution algorithm. Possible values are\n     #dnnl_convolution_direct, #dnnl_convolution_winograd,\n     #dnnl_convolution_auto.\n @param diff_src_desc Diff source memory descriptor.\n @param weights_desc Weights memory descriptor.\n @param diff_dst_desc Diff destination memory descriptor.\n @param strides Array of strides for spatial dimension.\n @param dilates Array of dilations for spatial dimension. A zero value\n     means no dilation in the corresponding dimension.\n @param padding_l Array of padding values for low indices for each spatial\n     dimension `([[front,] top,] left)`.\n @param padding_r Array of padding values for high indices for each spatial\n     dimension `([[back,] bottom,] right)`. Can be NULL in which case\n     padding is considered to be symmetrical.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_convolution_backward_data_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        alg_kind: dnnl_alg_kind_t::Type,
        diff_src_desc: const_dnnl_memory_desc_t,
        weights_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        strides: *const dnnl_dim_t,
        dilates: *const dnnl_dim_t,
        padding_l: *const dnnl_dim_t,
        padding_r: *const dnnl_dim_t,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a convolution weights gradient primitive.\n\n @note\n     Memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n Arrays @p strides, @p dilates, @p padding_l, and @p padding_r contain\n values for spatial dimensions only and hence must have the same number of\n elements as there are spatial dimensions. The order of values is the same\n as in the tensor: depth (for 3D tensors), height (for 3D and 2D tensors),\n and width.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param alg_kind Convolution algorithm. Possible values are\n     #dnnl_convolution_direct, #dnnl_convolution_winograd,\n     #dnnl_convolution_auto.\n @param src_desc Source memory descriptor.\n @param diff_weights_desc Diff weights memory descriptor.\n @param diff_bias_desc Diff bias memory descriptor. Passing NULL, a zero\n     memory descriptor, or a memory descriptor with format_kind set to\n     #dnnl_format_kind_undef disables the bias term.\n @param diff_dst_desc Diff destination memory descriptor.\n @param strides Array of strides for spatial dimension.\n @param dilates Array of dilations for spatial dimension. A zero value\n     means no dilation in the corresponding dimension.\n @param padding_l Array of padding values for low indices for each spatial\n     dimension `([[front,] top,] left)`.\n @param padding_r Array of padding values for high indices for each spatial\n     dimension `([[back,] bottom,] right)`. Can be NULL in which case\n     padding is considered to be symmetrical.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_convolution_backward_weights_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        alg_kind: dnnl_alg_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        diff_weights_desc: const_dnnl_memory_desc_t,
        diff_bias_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        strides: *const dnnl_dim_t,
        dilates: *const dnnl_dim_t,
        padding_l: *const dnnl_dim_t,
        padding_r: *const dnnl_dim_t,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a deconvolution forward propagation\n     primitive.\n\n @note\n     Memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n Arrays @p strides, @p dilates, @p padding_l, and @p padding_r contain\n values for spatial dimensions only and hence must have the same number of\n elements as there are spatial dimensions. The order of values is the same\n as in the tensor: depth (for 3D tensors), height (for 3D and 2D tensors),\n and width.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param alg_kind Deconvolution algorithm. Possible values are\n     #dnnl_deconvolution_direct, #dnnl_deconvolution_winograd.\n @param src_desc Source memory descriptor.\n @param weights_desc Weights memory descriptor.\n @param bias_desc Bias memory descriptor. Passing NULL, a zero memory\n     descriptor, or a memory descriptor with format_kind set to\n     #dnnl_format_kind_undef disables the bias term.\n @param dst_desc Destination memory descriptor.\n @param strides Array of strides for spatial dimension.\n @param dilates Array of dilations for spatial dimension. A zero value\n     means no dilation in the corresponding dimension.\n @param padding_l Array of padding values for low indices for each spatial\n     dimension `([[front,] top,] left)`.\n @param padding_r Array of padding values for high indices for each spatial\n     dimension `([[back,] bottom,] right)`. Can be NULL in which case\n     padding is considered to be symmetrical.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_deconvolution_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        alg_kind: dnnl_alg_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        weights_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        strides: *const dnnl_dim_t,
        dilates: *const dnnl_dim_t,
        padding_l: *const dnnl_dim_t,
        padding_r: *const dnnl_dim_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a deconvolution backward propagation\n     primitive.\n\n @note\n     Memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n Arrays @p strides, @p dilates, @p padding_l, and @p padding_r contain\n values for spatial dimensions only and hence must have the same number of\n elements as there are spatial dimensions. The order of values is the same\n as in the tensor: depth (for 3D tensors), height (for 3D and 2D tensors),\n and width.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param alg_kind Deconvolution algorithm. Possible values are\n     #dnnl_deconvolution_direct, #dnnl_deconvolution_winograd.\n @param diff_src_desc Diff source memory descriptor.\n @param weights_desc Weights memory descriptor.\n @param diff_dst_desc Diff destination memory descriptor.\n @param strides Array of strides for spatial dimension.\n @param dilates Array of dilations for spatial dimension. A zero value\n     means no dilation in the corresponding dimension.\n @param padding_l Array of padding values for low indices for each spatial\n     dimension `([[front,] top,] left)`.\n @param padding_r Array of padding values for high indices for each spatial\n     dimension `([[back,] bottom,] right)`. Can be NULL in which case\n     padding is considered to be symmetrical.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_deconvolution_backward_data_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        alg_kind: dnnl_alg_kind_t::Type,
        diff_src_desc: const_dnnl_memory_desc_t,
        weights_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        strides: *const dnnl_dim_t,
        dilates: *const dnnl_dim_t,
        padding_l: *const dnnl_dim_t,
        padding_r: *const dnnl_dim_t,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a deconvolution weights gradient\n     primitive.\n\n @note\n     Memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n Arrays @p strides, @p dilates, @p padding_l, and @p padding_r contain\n values for spatial dimensions only and hence must have the same number of\n elements as there are spatial dimensions. The order of values is the same\n as in the tensor: depth (for 3D tensors), height (for 3D and 2D tensors),\n and width.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param alg_kind Deconvolution algorithm. Possible values are\n     #dnnl_deconvolution_direct, #dnnl_deconvolution_winograd.\n @param src_desc Source memory descriptor.\n @param diff_weights_desc Diff weights memory descriptor.\n @param diff_bias_desc Diff bias memory descriptor. Passing NULL, a zero\n     memory descriptor, or a memory descriptor with format_kind set to\n     #dnnl_format_kind_undef disables the bias term.\n @param diff_dst_desc Diff destination memory descriptor.\n @param strides Array of strides for spatial dimension.\n @param dilates Array of dilations for spatial dimension. A zero value\n     means no dilation in the corresponding dimension.\n @param padding_l Array of padding values for low indices for each spatial\n     dimension `([[front,] top,] left)`.\n @param padding_r Array of padding values for high indices for each spatial\n     dimension `([[back,] bottom,] right)`. Can be NULL in which case\n     padding is considered to be symmetrical.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_deconvolution_backward_weights_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        alg_kind: dnnl_alg_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        diff_weights_desc: const_dnnl_memory_desc_t,
        diff_bias_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        strides: *const dnnl_dim_t,
        dilates: *const dnnl_dim_t,
        padding_l: *const dnnl_dim_t,
        padding_r: *const dnnl_dim_t,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a shuffle forward propagation primitive\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param src_desc Source memory descriptor.\n @param dst_desc Destination memory descriptor.\n @param axis The axis along which the data is shuffled.\n @param group_size Shuffle group size.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_shuffle_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        axis: ::std::os::raw::c_int,
        group_size: dnnl_dim_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a shuffle backward propagation primitive\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param diff_src_desc Diff source memory descriptor.\n @param diff_dst_desc Diff destination memory descriptor.\n @param axis The axis along which the data is shuffled.\n @param group_size Shuffle group size.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_shuffle_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        diff_src_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        axis: ::std::os::raw::c_int,
        group_size: dnnl_dim_t,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for an eltwise forward propagation primitive.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param alg_kind Elementwise algorithm kind.\n @param src_desc Source memory descriptor.\n @param dst_desc Destination memory descriptor.\n @param alpha The alpha parameter for the elementwise operation. Specific\n     meaning depends on the algorithm.\n @param beta The beta parameter for the elementwise operation. Specific\n     meaning depends on the algorithm.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_eltwise_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        alg_kind: dnnl_alg_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        alpha: f32,
        beta: f32,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for an eltwise backward propagation\n     primitive.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param alg_kind Elementwise algorithm kind.\n @param diff_src_desc Diff source memory descriptor.\n @param diff_dst_desc Diff destination memory descriptor.\n @param data_desc Destination memory descriptor if one of the\n     \"use_dst_for_bwd\" algorithms are used (such as\n     #dnnl_eltwise_relu_use_dst_for_bwd), source memory descriptor otherwise.\n @param alpha The alpha parameter for the elementwise operation. Specific\n     meaning depends on the algorithm.\n @param beta The beta parameter for the elementwise operation. Specific\n     meaning depends on the algorithm.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_eltwise_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        alg_kind: dnnl_alg_kind_t::Type,
        diff_src_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        data_desc: const_dnnl_memory_desc_t,
        alpha: f32,
        beta: f32,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a softmax forward propagation primitive.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param alg_kind Softmax algorithm kind: either #dnnl_softmax_accurate, or\n     #dnnl_softmax_log.\n @param src_desc Source memory descriptor.\n @param dst_desc Destination memory descriptor.\n @param softmax_axis Axis over which softmax is computed.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_softmax_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        alg_kind: dnnl_alg_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        softmax_axis: ::std::os::raw::c_int,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a softmax backward propagation primitive.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param alg_kind Softmax algorithm kind: either #dnnl_softmax_accurate, or\n     #dnnl_softmax_log.\n @param diff_src_desc Diff source memory descriptor.\n @param diff_dst_desc Diff destination memory descriptor.\n @param dst_desc Destination memory descriptor.\n @param softmax_axis Axis over which softmax is computed.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_softmax_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        alg_kind: dnnl_alg_kind_t::Type,
        diff_src_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        softmax_axis: ::std::os::raw::c_int,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a pooling forward propagation\n     primitive.\n\n Arrays @p strides, @p kernel, @p dilation, @p padding_l and @p padding_r\n contain values for spatial dimensions only and hence must have the same\n number of elements as there are spatial dimensions. The order of values\n is the same as in the tensor: depth (for 3D tensors),\n height (for 3D and 2D tensors), and width.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param alg_kind Pooling algorithm kind: either #dnnl_pooling_max,\n     #dnnl_pooling_avg_include_padding, or #dnnl_pooling_avg_exclude_padding.\n @param src_desc Source memory descriptor.\n @param dst_desc Destination memory descriptor.\n @param strides Array of strides for spatial dimension.\n @param kernel Array of kernel spatial dimensions.\n @param dilation Array of dilations for spatial dimension.\n @param padding_l Array of padding values for low indices for each spatial\n     dimension `([[front,] top,] left)`.\n @param padding_r Array of padding values for high indices for each spatial\n     dimension `([[back,] bottom,] right)`. Can be NULL in which case\n     padding is considered to be symmetrical.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_pooling_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        alg_kind: dnnl_alg_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        strides: *const dnnl_dim_t,
        kernel: *const dnnl_dim_t,
        dilation: *const dnnl_dim_t,
        padding_l: *const dnnl_dim_t,
        padding_r: *const dnnl_dim_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a pooling backward propagation\n     primitive.\n\n Arrays @p strides, @p kernel, @p dilation, @p padding_l and @p padding_r\n contain values for spatial dimensions only and hence must have the same\n number of elements as there are spatial dimensions. The order of values\n is the same as in the tensor: depth (for 3D tensors),\n height (for 3D and 2D tensors), and width.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param alg_kind Pooling algorithm kind: either #dnnl_pooling_max,\n     #dnnl_pooling_avg_include_padding, or #dnnl_pooling_avg_exclude_padding.\n @param diff_src_desc Diff source memory descriptor.\n @param diff_dst_desc Diff destination memory descriptor.\n @param strides Array of strides for spatial dimension.\n @param kernel Array of kernel spatial dimensions.\n @param dilation Array of dilations for spatial dimension.\n @param padding_l Array of padding values for low indices for each spatial\n     dimension `([[front,] top,] left)`.\n @param padding_r Array of padding values for high indices for each spatial\n     dimension `([[back,] bottom,] right)`. Can be NULL in which case\n     padding is considered to be symmetrical.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_pooling_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        alg_kind: dnnl_alg_kind_t::Type,
        diff_src_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        strides: *const dnnl_dim_t,
        kernel: *const dnnl_dim_t,
        dilation: *const dnnl_dim_t,
        padding_l: *const dnnl_dim_t,
        padding_r: *const dnnl_dim_t,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a PReLU (leaky ReLU with trainable\n     alpha parameter) forward propagation primitive.\n\n @note\n     weights descriptor is allowed to be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param src_desc Source memory descriptor.\n @param weights_desc Alpha parameters memory descriptor.\n @param dst_desc Destination memory descriptor.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_prelu_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        weights_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a PReLU (leaky ReLU with trainable\n     alpha parameter) backward propagation primitive.\n\n @note\n     weights descriptor and diff_weights descriptor are allowed\n     to be initialized with #dnnl_format_tag_any or with format_kind\n     set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param src_desc Source memory descriptor.\n @param weights_desc Alpha parameters memory descriptor.\n @param diff_src_desc Diff source memory descriptor.\n @param diff_weights_desc Diff alpha parameters memory descriptor.\n @param diff_dst_desc Diff destination memory descriptor.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_prelu_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        src_desc: const_dnnl_memory_desc_t,
        weights_desc: const_dnnl_memory_desc_t,
        diff_src_desc: const_dnnl_memory_desc_t,
        diff_weights_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for an LRN forward propagation primitive.\n\n @param primitive_desc Output primitive_descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param alg_kind LRN algorithm kind: either #dnnl_lrn_across_channels or\n     #dnnl_lrn_within_channel.\n @param src_desc Source memory descriptor.\n @param dst_desc Destination memory descriptor.\n @param local_size Regularization local size.\n @param alpha The alpha regularization parameter.\n @param beta The beta regularization parameter.\n @param k The k regularization parameter.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_lrn_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        alg_kind: dnnl_alg_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        local_size: dnnl_dim_t,
        alpha: f32,
        beta: f32,
        k: f32,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for an LRN backward propagation primitive.\n\n @param primitive_desc Output primitive_descriptor.\n @param engine Engine to use.\n @param alg_kind LRN algorithm kind: either #dnnl_lrn_across_channels or\n     #dnnl_lrn_within_channel.\n @param diff_src_desc Diff source memory descriptor.\n @param diff_dst_desc Diff destination memory descriptor.\n @param src_desc Source memory descriptor.\n @param local_size Regularization local size.\n @param alpha The alpha regularization parameter.\n @param beta The beta regularization parameter.\n @param k The k regularization parameter.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_lrn_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        alg_kind: dnnl_alg_kind_t::Type,
        diff_src_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        src_desc: const_dnnl_memory_desc_t,
        local_size: dnnl_dim_t,
        alpha: f32,
        beta: f32,
        k: f32,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a batch normalization forward propagation\n     primitive.\n\n @note\n     In-place operation is supported: the dst can refer to the same memory\n     as the src.\n\n @param primitive_desc Output primitive_descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param src_desc Source memory descriptor.\n @param dst_desc Destination memory descriptor.\n @param epsilon Batch normalization epsilon parameter.\n @param flags Batch normalization flags (@ref dnnl_normalization_flags_t).\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_batch_normalization_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        epsilon: f32,
        flags: ::std::os::raw::c_uint,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a batch normalization backward\n     propagation primitive.\n\n @note\n     In-place operation is supported: the diff_dst can refer to the same\n     memory as the diff_src.\n\n @param primitive_desc Output primitive_descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_backward_data and #dnnl_backward (diffs for all parameters are\n     computed in this case).\n @param diff_src_desc Diff source memory descriptor.\n @param diff_dst_desc Diff destination memory descriptor.\n @param src_desc Source memory descriptor.\n @param epsilon Batch normalization epsilon parameter.\n @param flags Batch normalization flags (@ref dnnl_normalization_flags_t).\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_batch_normalization_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        diff_src_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        src_desc: const_dnnl_memory_desc_t,
        epsilon: f32,
        flags: ::std::os::raw::c_uint,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a group normalization forward propagation\n     primitive.\n\n @note\n     In-place operation is supported: the dst can refer to the same memory\n     as the src.\n\n @param primitive_desc Output primitive_descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param src_desc Source memory descriptor.\n @param dst_desc Destination memory descriptor.\n @param groups Group normalization groups parameter.\n @param epsilon Group normalization epsilon parameter.\n @param flags Group normalization flags (@ref dnnl_normalization_flags_t).\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_group_normalization_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        groups: dnnl_dim_t,
        epsilon: f32,
        flags: ::std::os::raw::c_uint,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a group normalization backward\n     propagation primitive.\n\n @note\n     In-place operation is supported: the diff_dst can refer to the same\n     memory as the diff_src.\n\n @param primitive_desc Output primitive_descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_backward_data and #dnnl_backward (diffs for all parameters are\n     computed in this case).\n @param diff_src_desc Diff source memory descriptor.\n @param diff_dst_desc Diff destination memory descriptor.\n @param src_desc Source memory descriptor.\n @param groups Group normalization groups parameter.\n @param epsilon Group normalization epsilon parameter.\n @param flags Group normalization flags (@ref dnnl_normalization_flags_t).\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_group_normalization_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        diff_src_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        src_desc: const_dnnl_memory_desc_t,
        groups: dnnl_dim_t,
        epsilon: f32,
        flags: ::std::os::raw::c_uint,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a layer normalization forward propagation\n     primitive.\n\n @note\n     In-place operation is supported: the dst can refer to the same memory\n     as the src.\n\n @param primitive_desc Output primitive_descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param src_desc Source memory descriptor.\n @param dst_desc Destination memory descriptor.\n @param stat_desc Memory descriptor for mean and variance. If this\n     parameter is NULL, a zero memory descriptor, or a memory descriptor\n     with format_kind set to #dnnl_format_kind_undef, then the memory\n     descriptor for stats is derived from @p src_desc by removing the last\n     dimension.\n @param epsilon Layer normalization epsilon parameter.\n @param flags Layer normalization flags (@ref dnnl_normalization_flags_t).\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_layer_normalization_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        stat_desc: const_dnnl_memory_desc_t,
        epsilon: f32,
        flags: ::std::os::raw::c_uint,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a layer normalization backward\n     propagation primitive.\n\n @note\n     In-place operation is supported: the diff_dst can refer to the same\n     memory as the diff_src.\n\n @param primitive_desc Output primitive_descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_backward_data and #dnnl_backward (diffs for all parameters are\n     computed in this case).\n @param diff_src_desc Diff source memory descriptor.\n @param diff_dst_desc Diff destination memory descriptor.\n @param src_desc Source memory descriptor.\n @param stat_desc Memory descriptor for mean and variance. If this\n     parameter is NULL, a zero memory descriptor, or a memory descriptor\n     with format_kind set to #dnnl_format_kind_undef, then the memory\n     descriptor for stats is derived from @p src_desc by removing the last\n     dimension.\n @param epsilon Layer normalization epsilon parameter.\n @param flags Layer normalization flags (@ref dnnl_normalization_flags_t).\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_layer_normalization_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        diff_src_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        src_desc: const_dnnl_memory_desc_t,
        stat_desc: const_dnnl_memory_desc_t,
        epsilon: f32,
        flags: ::std::os::raw::c_uint,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a layer normalization forward propagation\n     primitive with a user-provided data type for the scale and shift\n     memory objects.\n\n @note\n     In-place operation is supported: the dst can refer to the same memory\n     as the src.\n\n @param primitive_desc Output primitive_descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param src_desc Source memory descriptor.\n @param dst_desc Destination memory descriptor.\n @param stat_desc Memory descriptor for mean and variance. If this\n     parameter is NULL, a zero memory descriptor, or a memory descriptor\n     with format_kind set to #dnnl_format_kind_undef, then the memory\n     descriptor for stats is derived from @p src_desc by removing the last\n     dimension.\n @param scale_shift_data_type Data type of scale and shift memory. If neither scale\n     nor shift flag are specified the parameter is ignored.\n @param epsilon Layer normalization epsilon parameter.\n @param flags Layer normalization flags (@ref dnnl_normalization_flags_t).\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_layer_normalization_forward_primitive_desc_create_v2(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        stat_desc: const_dnnl_memory_desc_t,
        scale_shift_data_type: dnnl_data_type_t::Type,
        epsilon: f32,
        flags: ::std::os::raw::c_uint,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a layer normalization backward\n     propagation primitive with a user-provided data type for the\n     scale and shift memory objects.\n\n @note\n     In-place operation is supported: the diff_dst can refer to the same\n     memory as the diff_src.\n\n @param primitive_desc Output primitive_descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_backward_data and #dnnl_backward (diffs for all parameters are\n     computed in this case).\n @param diff_src_desc Diff source memory descriptor.\n @param diff_dst_desc Diff destination memory descriptor.\n @param src_desc Source memory descriptor.\n @param stat_desc Memory descriptor for mean and variance. If this\n     parameter is NULL, a zero memory descriptor, or a memory descriptor\n     with format_kind set to #dnnl_format_kind_undef, then the memory\n     descriptor for stats is derived from @p src_desc by removing the last\n     dimension.\n @param diff_scale_shift_data_type Data type of diff scale and shift memory. If neither scale\n     nor shift flag are specified the parameter is ignored.\n @param scale_shift_data_type Data type of scale and shift memory. If neither scale\n     nor shift flag are specified the parameter is ignored.\n @param epsilon Layer normalization epsilon parameter.\n @param flags Layer normalization flags (@ref dnnl_normalization_flags_t).\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_layer_normalization_backward_primitive_desc_create_v2(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        diff_src_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        src_desc: const_dnnl_memory_desc_t,
        stat_desc: const_dnnl_memory_desc_t,
        diff_scale_shift_data_type: dnnl_data_type_t::Type,
        scale_shift_data_type: dnnl_data_type_t::Type,
        epsilon: f32,
        flags: ::std::os::raw::c_uint,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for an inner product forward propagation\n     primitive.\n\n @note\n     Memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive_descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param src_desc Source memory descriptor.\n @param weights_desc Weights memory descriptor.\n @param bias_desc Bias memory descriptor. Passing NULL, a zero memory\n     descriptor, or a memory descriptor with format_kind set to\n     #dnnl_format_kind_undef disables the bias term.\n @param dst_desc Destination memory descriptor.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_inner_product_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        weights_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for an inner product backward propagation\n     primitive.\n\n @note\n     Memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive_descriptor.\n @param engine Engine to use.\n @param diff_src_desc Diff source memory descriptor.\n @param weights_desc Weights memory descriptor.\n @param diff_dst_desc Diff destination memory descriptor.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_inner_product_backward_data_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        diff_src_desc: const_dnnl_memory_desc_t,
        weights_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for an inner product  weights gradient\n     primitive.\n\n @note\n     Memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive_descriptor.\n @param engine Engine to use.\n @param src_desc Source memory descriptor.\n @param diff_weights_desc Diff weights memory descriptor.\n @param diff_bias_desc Diff bias memory descriptor. Passing NULL, a zero\n     memory descriptor, or a memory descriptor with format_kind set to\n     #dnnl_format_kind_undef disables the bias term.\n @param diff_dst_desc Diff destination memory descriptor.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_inner_product_backward_weights_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        src_desc: const_dnnl_memory_desc_t,
        diff_weights_desc: const_dnnl_memory_desc_t,
        diff_bias_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Set quantization scale and shift parameters for RNN data tensors.\n\n For performance reasons, the low-precision configuration of the RNN\n primitives expects input activations to have the unsigned 8-bit integer\n data type. The scale and shift parameters are used to quantize\n floating-point data to unsigned integer and must be passed to the RNN\n primitive using attributes.\n\n The quantization formula is `scale * data + shift`.\n\n @note\n     Quantization scale and shift are common for src_layer, src_iter,\n     dst_iter, and dst_layer.\n\n Example usage:\n @code\n     // RNN parameters\n     int l = 2, t = 2, mb = 32, sic = 32, slc = 32, dic = 32, dlc = 32;\n     // Activations quantization parameters\n     float scale = 63.f, shift = 64.f;\n\n     dnnl_primitive_attr_t rnn_attr;\n     // Create default attributes\n     dnnl_primitive_attr_create(&rnn_attr);\n\n     // Set scale and shift for int8 quantization of activation\n     dnnl_primitive_attr_set_rnn_data_qparams(rnn_attr, scale, shift);\n\n     // Create an RNN primitive descriptor.\n     dnnl_primitive_desc_t rnn_pd;\n     dnnl_vanilla_rnn_forward_primitive_desc_create(&rnn_pd,\n             engine, /* arguments */, attr);\n @endcode\n\n @param attr Primitive attributes.\n @param scale The value to scale the data by.\n @param shift The value to shift the data by.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_set_rnn_data_qparams(
        attr: dnnl_primitive_attr_t,
        scale: f32,
        shift: f32,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the quantization scale and shift parameters for RNN data tensors.\n\n @note\n     Quantization scale and shift are common for src_layer, src_iter,\n     dst_iter, and dst_layer.\n\n @param attr Primitive attributes.\n @param scale The value to scale the data by.\n @param shift The value to shift the data by.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_get_rnn_data_qparams(
        attr: const_dnnl_primitive_attr_t,
        scale: *mut f32,
        shift: *mut f32,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets quantization scaling factors for RNN weights tensors. The\n low-precision configuration of the RNN primitives expects input weights to\n use the signed 8-bit integer data type. The scaling factors are used to\n quantize floating-point data to signed integer and must be passed to RNN\n primitives using attributes.\n\n @note\n     The dimension order is always native and does not depend on the actual\n     layout used. For example, five-dimensional weights always have (l, d,\n     i, g, o) logical dimension ordering.\n\n @note\n     Quantization scales are common for weights_layer and weights_iteration\n\n @param attr Primitive attributes.\n @param count Number of elements in the @p scales array.\n @param mask Scaling factors correspondence mask that defines the\n     correspondence between the output tensor dimensions and the @p\n     scales vector. The set i-th bit indicates that a dedicated scaling\n     factor should be used for each index along that dimension. Set the\n     mask to 0 to use a common scaling factor for the whole output\n     tensor.\n @param scales Array of output scaling factors that must contain @p count\n     values and the following equality must hold:\n     \\f[count = \\prod\\limits_{d \\in mask} weights.dims[d].\\f]\n     Violations can only be detected when the attributes are used to create\n     a primitive descriptor.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_set_rnn_weights_qparams(
        attr: dnnl_primitive_attr_t,
        count: dnnl_dim_t,
        mask: ::std::os::raw::c_int,
        scales: *const f32,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the quantization scaling factors for RNN weights tensors.\n\n @param attr Primitive attributes.\n @param count Number of elements in the @p scales array.\n @param mask Scaling factors correspondence mask that defines the\n     correspondence between the output tensor dimensions and the @p\n     scales vector. The set i-th bit indicates that a dedicated scaling\n     factor should be used for each index along that dimension. Set the\n     mask to 0 to use a common scaling factor for the whole output\n     tensor.\n @param scales Array of output scaling factors that contain @p count\n     values and the following equality must hold:\n     \\f[count = \\prod\\limits_{d \\in mask} weights.dims[d].\\f]\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_get_rnn_weights_qparams(
        attr: const_dnnl_primitive_attr_t,
        count: *mut dnnl_dim_t,
        mask: *mut ::std::os::raw::c_int,
        scales: *mut *const f32,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets quantization scaling factors for RNN projection weights tensors. The\n low-precision configuration of the RNN primitives expects input weights to\n use the signed 8-bit integer data type. The scaling factors are used to\n quantize floating-point data to signed integer and must be passed to RNN\n primitives using attributes.\n\n @note\n     The dimension order is always native and does not depend on the actual\n     layout used. For example, five-dimensional weights always have (l, d,\n     i, g, o) logical dimension ordering.\n\n @param attr Primitive attributes.\n @param count Number of elements in the @p scales array.\n @param mask Scaling factors correspondence mask that defines the\n     correspondence between the output tensor dimensions and the @p\n     scales vector. The set i-th bit indicates that a dedicated scaling\n     factor should be used for each index along that dimension. Set the\n     mask to 0 to use a common scaling factor for the whole output\n     tensor.\n @param scales Array of output scaling factors that must contain @p count\n     values and the following equality must hold:\n     \\f[count = \\prod\\limits_{d \\in mask} weights.dims[d].\\f]\n     Violations can only be detected when the attributes are used to create\n     a primitive descriptor.\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_set_rnn_weights_projection_qparams(
        attr: dnnl_primitive_attr_t,
        count: dnnl_dim_t,
        mask: ::std::os::raw::c_int,
        scales: *const f32,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the quantization scaling factors for RNN projection weights tensors.\n\n @param attr Primitive attributes.\n @param count Number of elements in the @p scales array.\n @param mask Scaling factors correspondence mask that defines the\n     correspondence between the output tensor dimensions and the @p\n     scales vector. The set i-th bit indicates that a dedicated scaling\n     factor should be used for each index along that dimension. Set the\n     mask to 0 to use a common scaling factor for the whole output\n     tensor.\n @param scales Array of output scaling factors that contain @p count\n     values and the following equality must hold:\n     \\f[count = \\prod\\limits_{d \\in mask} weights.dims[d].\\f]\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_primitive_attr_get_rnn_weights_projection_qparams(
        attr: const_dnnl_primitive_attr_t,
        count: *mut dnnl_dim_t,
        mask: *mut ::std::os::raw::c_int,
        scales: *mut *const f32,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for vanilla RNN forward propagation\n     primitive.\n\n The following arguments may either be @c NULL or point to a zero memory\n descriptor:\n - @p src_iter_desc,\n - @p bias_desc,\n - @p dst_iter_desc.\n\n This would then indicate that the RNN forward propagation primitive should\n not use them and should default to zero values instead.\n\n @note\n     All memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param activation Activation kind. Possible values are #dnnl_eltwise_relu,\n     #dnnl_eltwise_tanh or #dnnl_eltwise_logistic.\n @param direction RNN direction. See @ref dnnl_rnn_direction_t for more\n     info.\n @param src_layer_desc Memory descriptor for the input vector.\n @param src_iter_desc Memory descriptor for the input recurrent hidden\n     state vector.\n @param weights_layer_desc Memory descriptor for the weights applied to the\n     layer input.\n @param weights_iter_desc Memory descriptor for the weights applied to the\n     recurrent input.\n @param bias_desc Bias memory descriptor.\n @param dst_layer_desc Memory descriptor for the output vector.\n @param dst_iter_desc Memory descriptor for the output recurrent hidden\n     state vector.\n @param flags Unused.\n @param alpha Negative slope if activation is #dnnl_eltwise_relu.\n @param beta Unused.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_vanilla_rnn_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        activation: dnnl_alg_kind_t::Type,
        direction: dnnl_rnn_direction_t::Type,
        src_layer_desc: const_dnnl_memory_desc_t,
        src_iter_desc: const_dnnl_memory_desc_t,
        weights_layer_desc: const_dnnl_memory_desc_t,
        weights_iter_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_layer_desc: const_dnnl_memory_desc_t,
        dst_iter_desc: const_dnnl_memory_desc_t,
        flags: ::std::os::raw::c_uint,
        alpha: f32,
        beta: f32,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for vanilla RNN backward propagation\n     primitive.\n\n The following arguments may either be @c NULL or point to a zero memory\n descriptor:\n - @p src_iter_desc together with @p diff_src_iter_desc,\n - @p bias_desc together with @p diff_bias_desc,\n - @p dst_iter_desc together with @p diff_dst_iter_desc.\n\n This would then indicate that the RNN backward propagation primitive should\n not use the respective data and should use zero values instead.\n\n @note\n     All memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Must be #dnnl_backward.\n @param activation Activation kind. Possible values are #dnnl_eltwise_relu,\n     #dnnl_eltwise_tanh or #dnnl_eltwise_logistic.\n @param direction RNN direction. See @ref dnnl_rnn_direction_t for more\n     info.\n @param src_layer_desc Memory descriptor for the input vector.\n @param src_iter_desc Memory descriptor for the input recurrent hidden\n     state vector.\n @param weights_layer_desc Memory descriptor for the weights applied to the\n     layer input.\n @param weights_iter_desc Memory descriptor for the weights applied to the\n     recurrent input.\n @param bias_desc Bias memory descriptor.\n @param dst_layer_desc Memory descriptor for the output vector.\n @param dst_iter_desc Memory descriptor for the output recurrent hidden\n     state vector.\n @param diff_src_layer_desc Memory descriptor for the diff of input vector.\n @param diff_src_iter_desc Memory descriptor for the diff of input recurrent\n     hidden state vector.\n @param diff_weights_layer_desc Memory descriptor for the diff of weights\n     applied to the layer input.\n @param diff_weights_iter_desc Memory descriptor for the diff of weights\n     applied to the recurrent input.\n @param diff_bias_desc Diff bias memory descriptor.\n @param diff_dst_layer_desc Memory descriptor for the diff of output\n     vector.\n @param diff_dst_iter_desc Memory descriptor for the diff of output\n     recurrent hidden state vector.\n @param flags Unused.\n @param alpha Negative slope if activation is #dnnl_eltwise_relu.\n @param beta Unused.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_vanilla_rnn_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        activation: dnnl_alg_kind_t::Type,
        direction: dnnl_rnn_direction_t::Type,
        src_layer_desc: const_dnnl_memory_desc_t,
        src_iter_desc: const_dnnl_memory_desc_t,
        weights_layer_desc: const_dnnl_memory_desc_t,
        weights_iter_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_layer_desc: const_dnnl_memory_desc_t,
        dst_iter_desc: const_dnnl_memory_desc_t,
        diff_src_layer_desc: const_dnnl_memory_desc_t,
        diff_src_iter_desc: const_dnnl_memory_desc_t,
        diff_weights_layer_desc: const_dnnl_memory_desc_t,
        diff_weights_iter_desc: const_dnnl_memory_desc_t,
        diff_bias_desc: const_dnnl_memory_desc_t,
        diff_dst_layer_desc: const_dnnl_memory_desc_t,
        diff_dst_iter_desc: const_dnnl_memory_desc_t,
        flags: ::std::os::raw::c_uint,
        alpha: f32,
        beta: f32,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for an LSTM forward propagation primitive.\n\n The following arguments may either be @c NULL or point to a zero memory\n descriptor:\n - @p src_iter_desc together with @p src_iter_c_desc,\n - @p weights_peephole_desc,\n - @p bias_desc,\n - @p dst_iter_desc together with @p dst_iter_c_desc.\n\n This would then indicate that the LSTM forward propagation primitive should\n not use them and should default to zero values instead.\n\n The @p weights_projection_desc could either be @c NULL or point to a zero\n memory descriptor. This would then indicate that the LSTM doesn't have\n recurrent projection layer.\n\n @note\n     All memory descriptors can be initialized with #dnnl_format_tag_any or\n     with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param direction RNN direction. See @ref dnnl_rnn_direction_t for more\n     info.\n @param src_layer_desc Memory descriptor for the input vector.\n @param src_iter_desc Memory descriptor for the input recurrent hidden\n     state vector.\n @param src_iter_c_desc Memory descriptor for the input recurrent cell\n     state vector.\n @param weights_layer_desc Memory descriptor for the weights applied to the\n     layer input.\n @param weights_iter_desc Memory descriptor for the weights applied to the\n     recurrent input.\n @param weights_peephole_desc Memory descriptor for the weights applied to\n     the cell states (according to the Peephole LSTM formula).\n @param weights_projection_desc Memory descriptor for the weights applied to\n     the hidden states to get the recurrent projection (according to the\n     Projection LSTM formula).\n @param bias_desc Bias memory descriptor.\n @param dst_layer_desc Memory descriptor for the output vector.\n @param dst_iter_desc Memory descriptor for the output recurrent hidden\n     state vector.\n @param dst_iter_c_desc Memory descriptor for the output recurrent cell\n     state vector.\n @param flags Unused.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_lstm_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        direction: dnnl_rnn_direction_t::Type,
        src_layer_desc: const_dnnl_memory_desc_t,
        src_iter_desc: const_dnnl_memory_desc_t,
        src_iter_c_desc: const_dnnl_memory_desc_t,
        weights_layer_desc: const_dnnl_memory_desc_t,
        weights_iter_desc: const_dnnl_memory_desc_t,
        weights_peephole_desc: const_dnnl_memory_desc_t,
        weights_projection_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_layer_desc: const_dnnl_memory_desc_t,
        dst_iter_desc: const_dnnl_memory_desc_t,
        dst_iter_c_desc: const_dnnl_memory_desc_t,
        flags: ::std::os::raw::c_uint,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for an LSTM backward propagation primitive.\n\n The following arguments may either be @c NULL or point to a zero memory\n descriptor:\n - @p src_iter_desc together with @p src_iter_c_desc, @p diff_src_iter_desc,\n   and @p diff_src_iter_c_desc,\n - @p weights_peephole_desc together with @p diff_weights_peephole_desc,\n - @p bias_desc together with @p diff_bias_desc,\n - @p dst_iter_desc together with @p dst_iter_c_desc, @p diff_dst_iter_desc,\n   and @p diff_dst_iter_c_desc.\n\n This would then indicate that the LSTM backward propagation primitive\n should not use them and should default to zero values instead.\n\n The @p weights_projection_desc together with @p\n diff_weights_projection_desc could either be @c NULL or point to a zero\n memory descriptor. This would then indicate that the LSTM doesn't have\n recurrent projection layer.\n\n @note\n     All memory descriptors can be initialized with #dnnl_format_tag_any or\n     with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Must be #dnnl_backward.\n @param direction RNN direction. See @ref dnnl_rnn_direction_t for more\n     info.\n @param src_layer_desc Memory descriptor for the input vector.\n @param src_iter_desc Memory descriptor for the input recurrent hidden\n     state vector.\n @param src_iter_c_desc Memory descriptor for the input recurrent cell\n     state vector.\n @param weights_layer_desc Memory descriptor for the weights applied to the\n     layer input.\n @param weights_iter_desc Memory descriptor for the weights applied to the\n     recurrent input.\n @param weights_peephole_desc Memory descriptor for the weights applied to\n     the cell states (according to the Peephole LSTM formula).\n @param weights_projection_desc Memory descriptor for the weights applied to\n     the hidden states to get the recurrent projection (according to the\n     Projection LSTM formula).\n @param bias_desc Bias memory descriptor.\n @param dst_layer_desc Memory descriptor for the output vector.\n @param dst_iter_desc Memory descriptor for the output recurrent hidden\n     state vector.\n @param dst_iter_c_desc Memory descriptor for the output recurrent cell\n     state vector.\n @param diff_src_layer_desc Memory descriptor for the diff of input vector.\n @param diff_src_iter_desc Memory descriptor for the diff of input recurrent\n     hidden state vector.\n @param diff_src_iter_c_desc Memory descriptor for the diff of input\n recurrent cell state vector.\n @param diff_weights_layer_desc Memory descriptor for the diff of weights\n     applied to the layer input.\n @param diff_weights_iter_desc Memory descriptor for the diff of weights\n     applied to the recurrent input.\n @param diff_weights_peephole_desc Memory descriptor for the diff of weights\n     applied to the cell states (according to the Peephole LSTM formula).\n @param diff_weights_projection_desc Memory descriptor for the diff of\n     weights applied to the hidden states to get the recurrent projection\n     (according to the Projection LSTM formula).\n @param diff_bias_desc Diff bias memory descriptor.\n @param diff_dst_layer_desc Memory descriptor for the diff of output\n     vector.\n @param diff_dst_iter_desc Memory descriptor for the diff of output\n     recurrent hidden state vector.\n @param diff_dst_iter_c_desc Memory descriptor for the diff of output\n     recurrent cell state vector.\n @param flags Unused.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_lstm_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        direction: dnnl_rnn_direction_t::Type,
        src_layer_desc: const_dnnl_memory_desc_t,
        src_iter_desc: const_dnnl_memory_desc_t,
        src_iter_c_desc: const_dnnl_memory_desc_t,
        weights_layer_desc: const_dnnl_memory_desc_t,
        weights_iter_desc: const_dnnl_memory_desc_t,
        weights_peephole_desc: const_dnnl_memory_desc_t,
        weights_projection_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_layer_desc: const_dnnl_memory_desc_t,
        dst_iter_desc: const_dnnl_memory_desc_t,
        dst_iter_c_desc: const_dnnl_memory_desc_t,
        diff_src_layer_desc: const_dnnl_memory_desc_t,
        diff_src_iter_desc: const_dnnl_memory_desc_t,
        diff_src_iter_c_desc: const_dnnl_memory_desc_t,
        diff_weights_layer_desc: const_dnnl_memory_desc_t,
        diff_weights_iter_desc: const_dnnl_memory_desc_t,
        diff_weights_peephole_desc: const_dnnl_memory_desc_t,
        diff_weights_projection_desc: const_dnnl_memory_desc_t,
        diff_bias_desc: const_dnnl_memory_desc_t,
        diff_dst_layer_desc: const_dnnl_memory_desc_t,
        diff_dst_iter_desc: const_dnnl_memory_desc_t,
        diff_dst_iter_c_desc: const_dnnl_memory_desc_t,
        flags: ::std::os::raw::c_uint,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for GRU forward propagation primitive.\n\n The following arguments may either be @c NULL or point to a zero memory\n descriptor:\n - @p src_iter_desc,\n - @p bias_desc,\n - @p dst_iter_desc.\n\n This would then indicate that the GRU forward propagation primitive should\n not use them and should default to zero values instead.\n\n @note\n     All memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param direction RNN direction. See @ref dnnl_rnn_direction_t for more\n     info.\n @param src_layer_desc Memory descriptor for the input vector.\n @param src_iter_desc Memory descriptor for the input recurrent hidden\n     state vector.\n @param weights_layer_desc Memory descriptor for the weights applied to the\n     layer input.\n @param weights_iter_desc Memory descriptor for the weights applied to the\n     recurrent input.\n @param bias_desc Bias memory descriptor.\n @param dst_layer_desc Memory descriptor for the output vector.\n @param dst_iter_desc Memory descriptor for the output recurrent hidden\n     state vector.\n @param flags Unused.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_gru_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        direction: dnnl_rnn_direction_t::Type,
        src_layer_desc: const_dnnl_memory_desc_t,
        src_iter_desc: const_dnnl_memory_desc_t,
        weights_layer_desc: const_dnnl_memory_desc_t,
        weights_iter_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_layer_desc: const_dnnl_memory_desc_t,
        dst_iter_desc: const_dnnl_memory_desc_t,
        flags: ::std::os::raw::c_uint,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for GRU backward propagation primitive.\n\n The following arguments may either be @c NULL or point to a zero memory\n descriptor:\n - @p src_iter_desc together with @p diff_src_iter_desc,\n - @p bias_desc together with @p diff_bias_desc,\n - @p dst_iter_desc together with @p diff_dst_iter_desc.\n\n This would then indicate that the GRU backward propagation primitive\n should not use them and should default to zero values instead.\n\n @note\n     All memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Must be #dnnl_backward.\n @param direction RNN direction. See @ref dnnl_rnn_direction_t for more\n     info.\n @param src_layer_desc Memory descriptor for the input vector.\n @param src_iter_desc Memory descriptor for the input recurrent hidden\n     state vector.\n @param weights_layer_desc Memory descriptor for the weights applied to the\n     layer input.\n @param weights_iter_desc Memory descriptor for the weights applied to the\n     recurrent input.\n @param bias_desc Bias memory descriptor.\n @param dst_layer_desc Memory descriptor for the output vector.\n @param dst_iter_desc Memory descriptor for the output recurrent hidden\n     state vector.\n @param diff_src_layer_desc Memory descriptor for the diff of input vector.\n @param diff_src_iter_desc Memory descriptor for the diff of input recurrent\n     hidden state vector.\n @param diff_weights_layer_desc Memory descriptor for the diff of weights\n     applied to the layer input.\n @param diff_weights_iter_desc Memory descriptor for the diff of weights\n     applied to the recurrent input.\n @param diff_bias_desc Diff bias memory descriptor.\n @param diff_dst_layer_desc Memory descriptor for the diff of output\n     vector.\n @param diff_dst_iter_desc Memory descriptor for the diff of output\n     recurrent hidden state vector.\n @param flags Unused.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_gru_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        direction: dnnl_rnn_direction_t::Type,
        src_layer_desc: const_dnnl_memory_desc_t,
        src_iter_desc: const_dnnl_memory_desc_t,
        weights_layer_desc: const_dnnl_memory_desc_t,
        weights_iter_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_layer_desc: const_dnnl_memory_desc_t,
        dst_iter_desc: const_dnnl_memory_desc_t,
        diff_src_layer_desc: const_dnnl_memory_desc_t,
        diff_src_iter_desc: const_dnnl_memory_desc_t,
        diff_weights_layer_desc: const_dnnl_memory_desc_t,
        diff_weights_iter_desc: const_dnnl_memory_desc_t,
        diff_bias_desc: const_dnnl_memory_desc_t,
        diff_dst_layer_desc: const_dnnl_memory_desc_t,
        diff_dst_iter_desc: const_dnnl_memory_desc_t,
        flags: ::std::os::raw::c_uint,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a descriptor for LBR GRU forward propagation primitive.\n\n The following arguments may either be @c NULL or point to a zero memory\n descriptor:\n - @p src_iter_desc,\n - @p bias_desc,\n - @p dst_iter_desc.\n\n This would then indicate that the LBR GRU forward propagation primitive\n should not use them and should default to zero values instead.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param direction RNN direction. See @ref dnnl_rnn_direction_t for more\n     info.\n @param src_layer_desc Memory descriptor for the input vector.\n @param src_iter_desc Memory descriptor for the input recurrent hidden\n     state vector.\n @param weights_layer_desc Memory descriptor for the weights applied to the\n     layer input.\n @param weights_iter_desc Memory descriptor for the weights applied to the\n     recurrent input.\n @param bias_desc Bias memory descriptor.\n @param dst_layer_desc Memory descriptor for the output vector.\n @param dst_iter_desc Memory descriptor for the output recurrent hidden\n     state vector.\n @param flags Unused.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_lbr_gru_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        direction: dnnl_rnn_direction_t::Type,
        src_layer_desc: const_dnnl_memory_desc_t,
        src_iter_desc: const_dnnl_memory_desc_t,
        weights_layer_desc: const_dnnl_memory_desc_t,
        weights_iter_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_layer_desc: const_dnnl_memory_desc_t,
        dst_iter_desc: const_dnnl_memory_desc_t,
        flags: ::std::os::raw::c_uint,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for LBR GRU backward propagation primitive.\n\n The following arguments may either be @c NULL or point to a zero memory\n descriptor:\n - @p src_iter_desc together with @p diff_src_iter_desc,\n - @p bias_desc together with @p diff_bias_desc,\n - @p dst_iter_desc together with @p diff_dst_iter_desc.\n\n This would then indicate that the LBR GRU backward propagation primitive\n should not use them and should default to zero values instead.\n\n @note\n     All memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Must be #dnnl_backward.\n @param direction RNN direction. See @ref dnnl_rnn_direction_t for more\n     info.\n @param src_layer_desc Memory descriptor for the input vector.\n @param src_iter_desc Memory descriptor for the input recurrent hidden\n     state vector.\n @param weights_layer_desc Memory descriptor for the weights applied to the\n     layer input.\n @param weights_iter_desc Memory descriptor for the weights applied to the\n     recurrent input.\n @param bias_desc Bias memory descriptor.\n @param dst_layer_desc Memory descriptor for the output vector.\n @param dst_iter_desc Memory descriptor for the output recurrent hidden\n     state vector.\n @param diff_src_layer_desc Memory descriptor for the diff of input vector.\n @param diff_src_iter_desc Memory descriptor for the diff of input recurrent\n     hidden state vector.\n @param diff_weights_layer_desc Memory descriptor for the diff of weights\n     applied to the layer input.\n @param diff_weights_iter_desc Memory descriptor for the diff of weights\n     applied to the recurrent input.\n @param diff_bias_desc Diff bias memory descriptor.\n @param diff_dst_layer_desc Memory descriptor for the diff of output\n     vector.\n @param diff_dst_iter_desc Memory descriptor for the diff of output\n     recurrent hidden state vector.\n @param flags Unused.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_lbr_gru_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        direction: dnnl_rnn_direction_t::Type,
        src_layer_desc: const_dnnl_memory_desc_t,
        src_iter_desc: const_dnnl_memory_desc_t,
        weights_layer_desc: const_dnnl_memory_desc_t,
        weights_iter_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_layer_desc: const_dnnl_memory_desc_t,
        dst_iter_desc: const_dnnl_memory_desc_t,
        diff_src_layer_desc: const_dnnl_memory_desc_t,
        diff_src_iter_desc: const_dnnl_memory_desc_t,
        diff_weights_layer_desc: const_dnnl_memory_desc_t,
        diff_weights_iter_desc: const_dnnl_memory_desc_t,
        diff_bias_desc: const_dnnl_memory_desc_t,
        diff_dst_layer_desc: const_dnnl_memory_desc_t,
        diff_dst_iter_desc: const_dnnl_memory_desc_t,
        flags: ::std::os::raw::c_uint,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for AUGRU forward propagation primitive.\n\n The following arguments may either be @c NULL or point to a zero memory\n descriptor:\n - @p src_iter_desc,\n - @p bias_desc,\n - @p dst_iter_desc.\n\n This would then indicate that the AUGRU forward propagation primitive should\n not use them and should default to zero values instead.\n\n @note\n     All memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param direction RNN direction. See @ref dnnl_rnn_direction_t for more\n     info.\n @param src_layer_desc Memory descriptor for the input vector.\n @param src_iter_desc Memory descriptor for the input recurrent hidden\n     state vector.\n @param attention_desc Memory descriptor for the attention vector.\n @param weights_layer_desc Memory descriptor for the weights applied to the\n     layer input.\n @param weights_iter_desc Memory descriptor for the weights applied to the\n     recurrent input.\n @param bias_desc Bias memory descriptor.\n @param dst_layer_desc Memory descriptor for the output vector.\n @param dst_iter_desc Memory descriptor for the output recurrent hidden\n     state vector.\n @param flags Unused.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_augru_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        direction: dnnl_rnn_direction_t::Type,
        src_layer_desc: const_dnnl_memory_desc_t,
        src_iter_desc: const_dnnl_memory_desc_t,
        attention_desc: const_dnnl_memory_desc_t,
        weights_layer_desc: const_dnnl_memory_desc_t,
        weights_iter_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_layer_desc: const_dnnl_memory_desc_t,
        dst_iter_desc: const_dnnl_memory_desc_t,
        flags: ::std::os::raw::c_uint,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for AUGRU backward propagation primitive.\n\n The following arguments may either be @c NULL or point to a zero memory\n descriptor:\n - @p src_iter_desc together with @p diff_src_iter_desc,\n - @p bias_desc together with @p diff_bias_desc,\n - @p dst_iter_desc together with @p diff_dst_iter_desc.\n\n This would then indicate that the AUGRU backward propagation primitive\n should not use them and should default to zero values instead.\n\n @note\n     All memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Must be #dnnl_backward.\n @param direction RNN direction. See @ref dnnl_rnn_direction_t for more\n     info.\n @param src_layer_desc Memory descriptor for the input vector.\n @param src_iter_desc Memory descriptor for the input recurrent hidden\n     state vector.\n @param attention_desc Memory descriptor for the attention vector.\n @param weights_layer_desc Memory descriptor for the weights applied to the\n     layer input.\n @param weights_iter_desc Memory descriptor for the weights applied to the\n     recurrent input.\n @param bias_desc Bias memory descriptor.\n @param dst_layer_desc Memory descriptor for the output vector.\n @param dst_iter_desc Memory descriptor for the output recurrent hidden\n     state vector.\n @param diff_src_layer_desc Memory descriptor for the diff of input vector.\n @param diff_src_iter_desc Memory descriptor for the diff of input recurrent\n     hidden state vector.\n @param diff_attention_desc Memory descriptor for the diff of attention vector.\n @param diff_weights_layer_desc Memory descriptor for the diff of weights\n     applied to the layer input.\n @param diff_weights_iter_desc Memory descriptor for the diff of weights\n     applied to the recurrent input.\n @param diff_bias_desc Diff bias memory descriptor.\n @param diff_dst_layer_desc Memory descriptor for the diff of output\n     vector.\n @param diff_dst_iter_desc Memory descriptor for the diff of output\n     recurrent hidden state vector.\n @param flags Unused.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_augru_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        direction: dnnl_rnn_direction_t::Type,
        src_layer_desc: const_dnnl_memory_desc_t,
        src_iter_desc: const_dnnl_memory_desc_t,
        attention_desc: const_dnnl_memory_desc_t,
        weights_layer_desc: const_dnnl_memory_desc_t,
        weights_iter_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_layer_desc: const_dnnl_memory_desc_t,
        dst_iter_desc: const_dnnl_memory_desc_t,
        diff_src_layer_desc: const_dnnl_memory_desc_t,
        diff_src_iter_desc: const_dnnl_memory_desc_t,
        diff_attention_desc: const_dnnl_memory_desc_t,
        diff_weights_layer_desc: const_dnnl_memory_desc_t,
        diff_weights_iter_desc: const_dnnl_memory_desc_t,
        diff_bias_desc: const_dnnl_memory_desc_t,
        diff_dst_layer_desc: const_dnnl_memory_desc_t,
        diff_dst_iter_desc: const_dnnl_memory_desc_t,
        flags: ::std::os::raw::c_uint,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for LBR AUGRU forward propagation primitive.\n\n The following arguments may either be @c NULL or point to a zero memory\n descriptor:\n - @p src_iter_desc,\n - @p bias_desc,\n - @p dst_iter_desc.\n\n This would then indicate that the LBR AUGRU forward propagation primitive\n should not use them and should default to zero values instead.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param direction RNN direction. See @ref dnnl_rnn_direction_t for more\n     info.\n @param src_layer_desc Memory descriptor for the input vector.\n @param src_iter_desc Memory descriptor for the input recurrent hidden\n     state vector.\n @param attention_desc Memory descriptor for the attention vector.\n @param weights_layer_desc Memory descriptor for the weights applied to the\n     layer input.\n @param weights_iter_desc Memory descriptor for the weights applied to the\n     recurrent input.\n @param bias_desc Bias memory descriptor.\n @param dst_layer_desc Memory descriptor for the output vector.\n @param dst_iter_desc Memory descriptor for the output recurrent hidden\n     state vector.\n @param flags Unused.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_lbr_augru_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        direction: dnnl_rnn_direction_t::Type,
        src_layer_desc: const_dnnl_memory_desc_t,
        src_iter_desc: const_dnnl_memory_desc_t,
        attention_desc: const_dnnl_memory_desc_t,
        weights_layer_desc: const_dnnl_memory_desc_t,
        weights_iter_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_layer_desc: const_dnnl_memory_desc_t,
        dst_iter_desc: const_dnnl_memory_desc_t,
        flags: ::std::os::raw::c_uint,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for LBR AUGRU backward propagation primitive.\n\n The following arguments may either be @c NULL or point to a zero memory\n descriptor:\n - @p src_iter_desc together with @p diff_src_iter_desc,\n - @p bias_desc together with @p diff_bias_desc,\n - @p dst_iter_desc together with @p diff_dst_iter_desc.\n\n This would then indicate that the LBR AUGRU backward propagation primitive\n should not use them and should default to zero values instead.\n\n @note\n     All memory descriptors can be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Must be #dnnl_backward.\n @param direction RNN direction. See @ref dnnl_rnn_direction_t for more\n     info.\n @param src_layer_desc Memory descriptor for the input vector.\n @param src_iter_desc Memory descriptor for the input recurrent hidden\n     state vector.\n @param attention_desc Memory descriptor for the attention vector.\n @param weights_layer_desc Memory descriptor for the weights applied to the\n     layer input.\n @param weights_iter_desc Memory descriptor for the weights applied to the\n     recurrent input.\n @param bias_desc Bias memory descriptor.\n @param dst_layer_desc Memory descriptor for the output vector.\n @param dst_iter_desc Memory descriptor for the output recurrent hidden\n     state vector.\n @param diff_src_layer_desc Memory descriptor for the diff of input vector.\n @param diff_src_iter_desc Memory descriptor for the diff of input recurrent\n     hidden state vector.\n @param diff_attention_desc Memory descriptor for the diff of attention vector.\n @param diff_weights_layer_desc Memory descriptor for the diff of weights\n     applied to the layer input.\n @param diff_weights_iter_desc Memory descriptor for the diff of weights\n     applied to the recurrent input.\n @param diff_bias_desc Diff bias memory descriptor.\n @param diff_dst_layer_desc Memory descriptor for the diff of output\n     vector.\n @param diff_dst_iter_desc Memory descriptor for the diff of output\n     recurrent hidden state vector.\n @param flags Unused.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_lbr_augru_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        direction: dnnl_rnn_direction_t::Type,
        src_layer_desc: const_dnnl_memory_desc_t,
        src_iter_desc: const_dnnl_memory_desc_t,
        attention_desc: const_dnnl_memory_desc_t,
        weights_layer_desc: const_dnnl_memory_desc_t,
        weights_iter_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_layer_desc: const_dnnl_memory_desc_t,
        dst_iter_desc: const_dnnl_memory_desc_t,
        diff_src_layer_desc: const_dnnl_memory_desc_t,
        diff_src_iter_desc: const_dnnl_memory_desc_t,
        diff_attention_desc: const_dnnl_memory_desc_t,
        diff_weights_layer_desc: const_dnnl_memory_desc_t,
        diff_weights_iter_desc: const_dnnl_memory_desc_t,
        diff_bias_desc: const_dnnl_memory_desc_t,
        diff_dst_layer_desc: const_dnnl_memory_desc_t,
        diff_dst_iter_desc: const_dnnl_memory_desc_t,
        flags: ::std::os::raw::c_uint,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a matrix multiplication primitive.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param src_desc Source memory descriptor (matrix A)\n @param weights_desc Weights memory descriptor (matrix B)\n @param bias_desc Bias memory descriptor. Passing NULL, a zero memory\n     descriptor, or a memory descriptor with format_kind set to\n     #dnnl_format_kind_undef disables the bias term.\n @param dst_desc Destination memory descriptor (matrix C).\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_matmul_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        src_desc: const_dnnl_memory_desc_t,
        weights_desc: const_dnnl_memory_desc_t,
        bias_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a resampling forward propagation\n     primitive.\n\n @note\n     Destination memory descriptor is allowed to be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param prop_kind Propagation kind. Possible values are\n     #dnnl_forward_training and #dnnl_forward_inference.\n @param alg_kind resampling algorithm kind: either #dnnl_resampling_nearest,\n     or #dnnl_resampling_linear.\n @param factors Array of scaling factors for spatial dimension.\n @param src_desc Source memory descriptor.\n @param dst_desc Destination memory descriptor.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_resampling_forward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        prop_kind: dnnl_prop_kind_t::Type,
        alg_kind: dnnl_alg_kind_t::Type,
        factors: *const f32,
        src_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a resampling backward propagation\n     primitive.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param alg_kind resamplinging algorithm kind: either\n     #dnnl_resampling_nearest, or #dnnl_resampling_linear.\n @param diff_src_desc Diff source memory descriptor.\n @param diff_dst_desc Diff destination memory descriptor.\n @param factors Array of scaling factors for spatial dimension.\n @param hint_fwd_pd Primitive descriptor for a respective forward propagation\n     primitive.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise.\n"]
    pub fn dnnl_resampling_backward_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        alg_kind: dnnl_alg_kind_t::Type,
        factors: *const f32,
        diff_src_desc: const_dnnl_memory_desc_t,
        diff_dst_desc: const_dnnl_memory_desc_t,
        hint_fwd_pd: const_dnnl_primitive_desc_t,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a primitive descriptor for a reduction primitive.\n\n @note\n     Destination memory descriptor is allowed to be initialized with\n     #dnnl_format_tag_any or with format_kind set to #dnnl_format_kind_any.\n\n @param primitive_desc Output primitive descriptor.\n @param engine Engine to use.\n @param alg_kind reduction algorithm kind. Possible values:\n     #dnnl_reduction_max, #dnnl_reduction_min, #dnnl_reduction_sum,\n     #dnnl_reduction_mul, #dnnl_reduction_mean, #dnnl_reduction_norm_lp_max,\n     #dnnl_reduction_norm_lp_sum, #dnnl_reduction_norm_lp_power_p_max,\n     #dnnl_reduction_norm_lp_power_p_sum.\n @param p Algorithm specific parameter.\n @param eps Algorithm specific parameter.\n @param src_desc Source memory descriptor.\n @param dst_desc Destination memory descriptor.\n @param attr Primitive attributes (can be NULL).\n @returns #dnnl_success on success and a status describing the error\n     otherwise."]
    pub fn dnnl_reduction_primitive_desc_create(
        primitive_desc: *mut dnnl_primitive_desc_t,
        engine: dnnl_engine_t,
        alg_kind: dnnl_alg_kind_t::Type,
        src_desc: const_dnnl_memory_desc_t,
        dst_desc: const_dnnl_memory_desc_t,
        p: f32,
        eps: f32,
        attr: const_dnnl_primitive_attr_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the number of primitives that can be held in the primitive cache\n at the same time.\n\n @param capacity Primitive cache capacity to query. Concurrently\n accessing @p capacity is safe.\n @returns #dnnl_invalid_arguments/#dnnl::status::invalid_arguments if the\n     @p capacity value is invalid, and #dnnl_success/#dnnl::status::success on\n     success."]
    pub fn dnnl_get_primitive_cache_capacity(
        capacity: *mut ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets a number of primitives that can be held in the primitive cache\n at a time.\n\n @param capacity Primitive cache capacity to set. If a new @p capacity is\n less than a number of primitives that the primitive cache already has\n then the excess entries will be evicted. Setting the @p capacity to 0\n clears the primitive cache and disables it. Concurrently modifying\n @p capacity is safe.\n @returns #dnnl_invalid_arguments/#dnnl::status::invalid_arguments if the\n     @p capacity value is invalid, and #dnnl_success/#dnnl::status::success on\n     success."]
    pub fn dnnl_set_primitive_cache_capacity(
        capacity: ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Configures dumping of JIT-generated code.\n\n @note\n     This setting overrides the DNNL_JIT_DUMP environment variable.\n\n @param enable Flag value. Set to 0 to disable and set to 1 to enable.\n @returns #dnnl_invalid_arguments/#dnnl::status::invalid_arguments if the\n     @p flag value is invalid, and #dnnl_success/#dnnl::status::success on\n     success."]
    pub fn dnnl_set_jit_dump(enable: ::std::os::raw::c_int) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets library profiling flags. The flags define which profilers are\n supported.\n\n @note\n     This setting overrides DNNL_JIT_PROFILE environment variable.\n\n @sa @ref dev_guide_profilers\n\n @param flags Profiling flags that can contain the following bits:\n     - @ref DNNL_JIT_PROFILE_VTUNE -- integration with VTune Profiler\n         (on by default)\n     - @ref DNNL_JIT_PROFILE_LINUX_JITDUMP -- produce Linux-specific\n         jit-pid.dump output (off by default). The location of the output\n         is controlled via JITDUMPDIR environment variable or via\n         dnnl_set_jit_profiling_jitdumpdir() function.\n     - @ref DNNL_JIT_PROFILE_LINUX_PERFMAP -- produce Linux-specific\n         perf-pid.map output (off by default). The output is always placed\n         into /tmp.\n\n     Passing @ref DNNL_JIT_PROFILE_NONE disables profiling completely.\n\n @returns #dnnl_invalid_arguments/#dnnl::status::invalid_arguments if the\n     @p flags value is invalid, and #dnnl_success/#dnnl::status::success on\n     success."]
    pub fn dnnl_set_jit_profiling_flags(flags: ::std::os::raw::c_uint) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets JIT dump output path. Only applicable to Linux and is only\n used when profiling flags have DNNL_JIT_PROFILE_LINUX_PERF bit set.\n\n After the first JIT kernel is generated, the jitdump output will be placed\n into temporary directory created using the mkdtemp template\n 'dir/.debug/jit/dnnl.XXXXXX'.\n\n @sa @ref dev_guide_profilers\n\n @note\n     This setting overrides JITDUMPDIR environment variable.  If\n     JITDUMPDIR is not set, and this function is never called, the path\n     defaults to HOME. Passing NULL reverts the value to default.\n\n @note\n     The directory is accessed only when the first JIT kernel is being\n     created. JIT profiling will be disabled in case of any errors\n     accessing or creating this directory.\n\n @param dir JIT dump output path.\n @returns #dnnl_success/#dnnl::status::success if the\n     output directory was set correctly and an error status otherwise.\n @returns #dnnl_unimplemented/#dnnl::status::unimplemented on Windows."]
    pub fn dnnl_set_jit_profiling_jitdumpdir(
        dir: *const ::std::os::raw::c_char,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets the maximal ISA the library can dispatch to on the CPU. See\n #dnnl_cpu_isa_t and #dnnl::cpu_isa for the list of the values accepted by\n the C and C++ API functions respectively.\n\n This function has effect only once, and returns an error on subsequent\n calls. It should also be invoked before any other oneDNN API call, otherwise\n it may return an error.\n\n This function overrides the DNNL_MAX_CPU_ISA environment variable. The\n environment variable can be set to the desired maximal ISA name in upper\n case and with dnnl_cpu_isa prefix removed. For example:\n `DNNL_MAX_CPU_ISA=AVX2`.\n\n @note\n     The ISAs are only partially ordered:\n         - SSE41 < AVX < AVX2 < AVX2_VNNI < AVX2_VNNI_2,\n         - AVX2 < AVX512_CORE < AVX512_CORE_VNNI < AVX512_CORE_BF16\n           < AVX10_1_512 < AVX10_1_512_AMX < AVX10_1_512_AMX_FP16,\n         - AVX2_VNNI < AVX10_1_512.\n     Aliases:\n         - AVX512_CORE_FP16 = AVX10_1_512\n         - AVX512_CORE_AMX = AVX10_1_512_AMX\n         - AVX512_CORE_AMX_FP16 = AVX10_1_512_AMX_FP16\n\n @sa @ref dev_guide_cpu_dispatcher_control for more details\n\n @param isa Maximal ISA the library should dispatch to. Pass\n     #dnnl_cpu_isa_default/#dnnl::cpu_isa::isa_default to remove ISA restrictions\n     (except for ISAs with initial support in the library).\n @returns #dnnl_success/#dnnl::status::success on success and a\n     #dnnl_invalid_arguments/#dnnl::status::invalid_arguments if the @p isa\n     parameter is invalid or the ISA cannot be changed at this time.\n @returns #dnnl_unimplemented/#dnnl::status::unimplemented if the feature\n     was disabled at build time (see @ref dev_guide_build_options for more\n     details)."]
    pub fn dnnl_set_max_cpu_isa(isa: dnnl_cpu_isa_t::Type) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Gets the maximal ISA the library can dispatch to on the CPU. See\n #dnnl_cpu_isa_t and #dnnl::cpu_isa for the list of the values returned by\n the C and C++ API functions respectively.\n\n @sa @ref dev_guide_cpu_dispatcher_control for more details\n\n @returns #dnnl_cpu_isa_t value reflecting the maximal ISA the library may\n     dispatch to."]
    pub fn dnnl_get_effective_cpu_isa() -> dnnl_cpu_isa_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets the hints flag for the CPU ISA. See #dnnl_cpu_isa_hints_t and\n #dnnl::cpu_isa_hints for the list of the values accepted by the C and C++\n API functions respectively.\n\n This function has effect only once, and returns an error on subsequent\n calls. It should also be invoked before any other oneDNN API call, otherwise\n it may return an error.\n\n This function overrides the DNNL_CPU_ISA_HINTS environment variable.\n @sa @ref dev_guide_cpu_isa_hints for more details\n\n @param isa_hints CPU ISA hints to be passed over to the implementation.\n     Pass #dnnl_cpu_isa_no_hints/#dnnl::cpu_isa_hints::no_hints to use\n     default features i.e. no hints.\n @returns #dnnl_success/#dnnl::status::success on success and a\n     #dnnl_runtime_error/#dnnl::status::runtime_error if the ISA hints cannot\n     be specified at the current time.\n @returns #dnnl_unimplemented/#dnnl::status::unimplemented if the feature\n     was disabled at build time (see @ref dev_guide_build_options for more\n     details)."]
    pub fn dnnl_set_cpu_isa_hints(isa_hints: dnnl_cpu_isa_hints_t::Type) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Gets the ISA specific hints that library can follow. See\n #dnnl_cpu_isa_hints_t and #dnnl::cpu_isa_hints for the list of the values\n  returned by the C and C++ API functions respectively.\n\n @sa @ref dev_guide_cpu_isa_hints for more details\n\n @returns #dnnl_cpu_isa_hints_t value reflecting the ISA specific hints the\n library can follow."]
    pub fn dnnl_get_cpu_isa_hints() -> dnnl_cpu_isa_hints_t::Type;
}
unsafe extern "C" {
    #[doc = " Performs single-precision matrix-matrix multiply.\n\n The operation is defined as:\n\n `C := alpha * op( A ) * op( B ) + beta * C`\n\n where\n  - `op( X ) = X` or `op( X ) = X**T`,\n  - `alpha` and `beta` are scalars, and\n  - `A`, `B`, and `C` are matrices:\n     - `op( A )` is an `MxK` matrix,\n     - `op( B )` is an `KxN` matrix,\n     - `C` is an `MxN` matrix.\n\n The matrices are assumed to be stored in row-major order (the elements in\n each of the matrix rows are contiguous in memory).\n\n @note\n     This API does not support XERBLA. Instead, unlike the standard BLAS\n     functions, this one returns a dnnl_status_t value to allow error\n     handling.\n\n @param transa Transposition flag for matrix A: 'N' or 'n' means A is not\n     transposed, and 'T' or 't' means that A is transposed.\n @param transb Transposition flag for matrix B: 'N' or 'n' means B is not\n     transposed, and 'T' or 't' means that B is transposed.\n @param M The M dimension.\n @param N The N dimension.\n @param K The K dimension.\n @param alpha The alpha parameter that is used to scale the product of\n     matrices A and B.\n @param A A pointer to the A matrix data.\n @param lda The leading dimension for the matrix A.\n @param B A pointer to the B matrix data.\n @param ldb The leading dimension for the matrix B.\n @param beta The beta parameter that is used to scale the matrix C.\n @param C A pointer to the C matrix data.\n @param ldc The leading dimension for the matrix C.\n @returns #dnnl_success/#dnnl::status::success on success and a status\n     describing the error otherwise."]
    pub fn dnnl_sgemm(
        transa: ::std::os::raw::c_char,
        transb: ::std::os::raw::c_char,
        M: dnnl_dim_t,
        N: dnnl_dim_t,
        K: dnnl_dim_t,
        alpha: f32,
        A: *const f32,
        lda: dnnl_dim_t,
        B: *const f32,
        ldb: dnnl_dim_t,
        beta: f32,
        C: *mut f32,
        ldc: dnnl_dim_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Performs integer matrix-matrix multiply on 8-bit unsigned matrix A, 8-bit\n signed matrix B, and 32-bit signed resulting matrix C.\n\n The operation is defined as:\n\n `C := alpha * (op(A) - A_offset) * (op(B) - B_offset) + beta * C + C_offset`\n\n where\n  - `op( X ) = X` or `op( X ) = X**T`,\n  - `alpha` and `beta` are scalars, and\n  - `A`, `B`, and `C` are matrices:\n     - `op( A )` is an `MxK` matrix,\n     - `op( B )` is an `KxN` matrix,\n     - `C` is an `MxN` matrix.\n  - `A_offset` is an `MxK` matrix with every element equal the `ao` value,\n  - `B_offset` is an `KxN` matrix with every element equal the `bo` value,\n  - `C_offset` is an `MxN` matrix which is defined by the `co` array of size `len`:\n    - if `offsetc = F`: the `len` must be at least `1`,\n    - if `offsetc = C`: the `len` must be at least `max(1, m)`,\n    - if `offsetc = R`: the `len` must be at least `max(1, n)`,\n\n The matrices are assumed to be stored in row-major order (the elements in\n each of the matrix rows are contiguous in memory).\n\n @note\n     This API does not support XERBLA. Instead, unlike the standard BLAS\n     functions, this one returns a dnnl_status_t value to allow error\n     handling.\n\n @warning\n     On some architectures saturation may happen during intermediate\n     computations, which would lead to unexpected results. For more\n     details, refer to @ref dev_guide_int8_computations.\n\n @param transa Transposition flag for matrix A: 'N' or 'n' means A is not\n     transposed, and 'T' or 't' means that A is transposed.\n @param transb Transposition flag for matrix B: 'N' or 'n' means B is not\n     transposed, and 'T' or 't' means that B is transposed.\n @param offsetc Flag specifying how offsets should be applied to matrix C:\n     - 'F' means that the same offset will be applied to each element of\n         the matrix C,\n     - 'C' means that individual offset will be applied to each element\n         within each column,\n     - 'R' means that individual offset will be applied to each element\n         within each row.\n @param M The M dimension.\n @param N The N dimension.\n @param K The K dimension.\n @param alpha The alpha parameter that is used to scale the product of\n     matrices A and B.\n @param A A pointer to the A matrix data.\n @param lda The leading dimension for the matrix A.\n @param ao The offset value for the matrix A.\n @param B A pointer to the B matrix data.\n @param ldb The leading dimension for the matrix B.\n @param bo The offset value for the matrix B.\n @param beta The beta parameter that is used to scale the matrix C.\n @param C A pointer to the C matrix data.\n @param ldc The leading dimension for the matrix C.\n @param co An array of offset values for the matrix C. The number of\n     elements in the array depends on the value of @p offsetc.\n @returns #dnnl_success/#dnnl::status::success on success and a status\n     describing the error otherwise."]
    pub fn dnnl_gemm_u8s8s32(
        transa: ::std::os::raw::c_char,
        transb: ::std::os::raw::c_char,
        offsetc: ::std::os::raw::c_char,
        M: dnnl_dim_t,
        N: dnnl_dim_t,
        K: dnnl_dim_t,
        alpha: f32,
        A: *const u8,
        lda: dnnl_dim_t,
        ao: u8,
        B: *const i8,
        ldb: dnnl_dim_t,
        bo: i8,
        beta: f32,
        C: *mut i32,
        ldc: dnnl_dim_t,
        co: *const i32,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Performs integer matrix-matrix multiply on 8-bit signed matrix A, 8-bit\n signed matrix B, and 32-bit signed resulting matrix C.\n\n The operation is defined as:\n\n `C := alpha * (op(A) - A_offset) * (op(B) - B_offset) + beta * C + C_offset`\n\n where\n  - `op( X ) = X` or `op( X ) = X**T`,\n  - `alpha` and `beta` are scalars, and\n  - `A`, `B`, and `C` are matrices:\n     - `op( A )` is an `MxK` matrix,\n     - `op( B )` is an `KxN` matrix,\n     - `C` is an `MxN` matrix.\n  - `A_offset` is an `MxK` matrix with every element equal the `ao` value,\n  - `B_offset` is an `KxN` matrix with every element equal the `bo` value,\n  - `C_offset` is an `MxN` matrix which is defined by the `co` array of size `len`:\n    - if `offsetc = F`: the `len` must be at least `1`,\n    - if `offsetc = C`: the `len` must be at least `max(1, m)`,\n    - if `offsetc = R`: the `len` must be at least `max(1, n)`,\n\n The matrices are assumed to be stored in row-major order (the elements in\n each of the matrix rows are contiguous in memory).\n\n @note\n     This API does not support XERBLA. Instead, unlike the standard BLAS\n     functions, this one returns a dnnl_status_t value to allow error\n     handling.\n\n @warning\n     On some architectures saturation may happen during intermediate\n     computations, which would lead to unexpected results. For more\n     details, refer to @ref dev_guide_int8_computations.\n\n @param transa Transposition flag for matrix A: 'N' or 'n' means A is not\n     transposed, and 'T' or 't' means that A is transposed.\n @param transb Transposition flag for matrix B: 'N' or 'n' means B is not\n     transposed, and 'T' or 't' means that B is transposed.\n @param offsetc Flag specifying how offsets should be applied to matrix C:\n     - 'F' means that the same offset will be applied to each element of\n         the matrix C,\n     - 'C' means that individual offset will be applied to each element\n         within each column,\n     - 'R' means that individual offset will be applied to each element\n         within each row.\n @param M The M dimension.\n @param N The N dimension.\n @param K The K dimension.\n @param alpha The alpha parameter that is used to scale the product of\n     matrices A and B.\n @param A A pointer to the A matrix data.\n @param lda The leading dimension for the matrix A.\n @param ao The offset value for the matrix A.\n @param B A pointer to the B matrix data.\n @param ldb The leading dimension for the matrix B.\n @param bo The offset value for the matrix B.\n @param beta The beta parameter that is used to scale the matrix C.\n @param C A pointer to the C matrix data.\n @param ldc The leading dimension for the matrix C.\n @param co An array of offset values for the matrix C. The number of\n     elements in the array depends on the value of @p offsetc.\n @returns #dnnl_success/#dnnl::status::success on success and a status\n     describing the error otherwise."]
    pub fn dnnl_gemm_s8s8s32(
        transa: ::std::os::raw::c_char,
        transb: ::std::os::raw::c_char,
        offsetc: ::std::os::raw::c_char,
        M: dnnl_dim_t,
        N: dnnl_dim_t,
        K: dnnl_dim_t,
        alpha: f32,
        A: *const i8,
        lda: dnnl_dim_t,
        ao: i8,
        B: *const i8,
        ldb: dnnl_dim_t,
        bo: i8,
        beta: f32,
        C: *mut i32,
        ldc: dnnl_dim_t,
        co: *const i32,
    ) -> dnnl_status_t::Type;
}
pub mod dnnl_graph_layout_type_t {
    #[doc = " Layout type specification"]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " Undefined layout type"]
    pub const dnnl_graph_layout_type_undef: Type = 0;
    #[doc = " Any means to let the library to decide the layout for a tensor during\n partition compilation."]
    pub const dnnl_graph_layout_type_any: Type = 1;
    #[doc = " Strided means that the layout of a tensor is determined by the strides\n field in the logical tensor."]
    pub const dnnl_graph_layout_type_strided: Type = 2;
    #[doc = " Opaque means that the layout of a tensor is the library specific.\n Usually, an opaque layout is generated by a partition which is compiled\n with layout type any."]
    pub const dnnl_graph_layout_type_opaque: Type = 3;
}
pub mod dnnl_graph_tensor_property_t {
    #[doc = " Logical tensor property"]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " Undefined tensor property"]
    pub const dnnl_graph_tensor_property_undef: Type = 0;
    #[doc = " Variable means the tensor may be changed during computation or between\n different iterations."]
    pub const dnnl_graph_tensor_property_variable: Type = 1;
    #[doc = " Constant means the tensor will keep unchanged during computation and\n between different iterations. It's useful for the library to apply\n optimizations for constant tensors or cache constant tensors inside the\n library. For example, constant weight tensors in inference scenarios."]
    pub const dnnl_graph_tensor_property_constant: Type = 2;
}
#[doc = " Logical tensor. It is based on an ID, a number of dimensions, dimensions\n themselves, element data type, tensor property and tensor memory layout."]
#[repr(C)]
#[derive(Copy, Clone)]
pub struct dnnl_graph_logical_tensor_t {
    #[doc = " Unique id of each logical tensor. The library uses logical tensor IDs to\n build up the connections between operations if the output of one\n operation has the same ID as the input of another operation."]
    pub id: usize,
    #[doc = " Number of dimensions. -1 means unknown (DNNL_GRAPH_UNKNOWN_NDIMS). 0 is\n used to define scalar tensor."]
    pub ndims: ::std::os::raw::c_int,
    #[doc = " Size of each dimension. #DNNL_GRAPH_UNKNOWN_DIM means the size of that\n dimension is unknown. 0 is used to define zero-dimension tensor. The\n library supports to deduce output shapes according to input shapes\n during compilation. Unlike memory descriptor in oneDNN primitive API,\n the order of dimensions is not defined in logical tensor. It is defined\n by the operations which respect the order through the attributes\n #dnnl_graph_op_attr_data_format or #dnnl_graph_op_attr_weights_format.\n For example, for a Convolution with `data_format=NXC`, it means the\n first element of dims of activation tensor is mini-batch size, the last\n effective element of dims is channel size, and other elements between\n them are spatial dimensions."]
    pub dims: dnnl_dims_t,
    #[doc = " Data type of the tensor elements."]
    pub data_type: dnnl_data_type_t::Type,
    #[doc = " Property type of the tensor."]
    pub property: dnnl_graph_tensor_property_t::Type,
    #[doc = " Layout type of the tensor."]
    pub layout_type: dnnl_graph_layout_type_t::Type,
    pub layout: dnnl_graph_logical_tensor_t__bindgen_ty_1,
}
#[repr(C)]
#[derive(Copy, Clone)]
pub union dnnl_graph_logical_tensor_t__bindgen_ty_1 {
    #[doc = " The field is valid when `layout_type` is\n #dnnl_graph_layout_type_strided. #DNNL_GRAPH_UNKNOWN_DIM means the\n stride of the dimension is unknown. The library currently doesn't\n support other negative stride values."]
    pub strides: dnnl_dims_t,
    #[doc = " The field is valid when `layout_type` is\n #dnnl_graph_layout_type_opaque. An opaque layout ID is usually\n generated by a partition which is compiled with layout type any."]
    pub layout_id: usize,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of dnnl_graph_logical_tensor_t__bindgen_ty_1"]
        [::std::mem::size_of::<dnnl_graph_logical_tensor_t__bindgen_ty_1>() - 96usize];
    ["Alignment of dnnl_graph_logical_tensor_t__bindgen_ty_1"]
        [::std::mem::align_of::<dnnl_graph_logical_tensor_t__bindgen_ty_1>() - 8usize];
    ["Offset of field: dnnl_graph_logical_tensor_t__bindgen_ty_1::strides"]
        [::std::mem::offset_of!(dnnl_graph_logical_tensor_t__bindgen_ty_1, strides) - 0usize];
    ["Offset of field: dnnl_graph_logical_tensor_t__bindgen_ty_1::layout_id"]
        [::std::mem::offset_of!(dnnl_graph_logical_tensor_t__bindgen_ty_1, layout_id) - 0usize];
};
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of dnnl_graph_logical_tensor_t"]
        [::std::mem::size_of::<dnnl_graph_logical_tensor_t>() - 224usize];
    ["Alignment of dnnl_graph_logical_tensor_t"]
        [::std::mem::align_of::<dnnl_graph_logical_tensor_t>() - 8usize];
    ["Offset of field: dnnl_graph_logical_tensor_t::id"]
        [::std::mem::offset_of!(dnnl_graph_logical_tensor_t, id) - 0usize];
    ["Offset of field: dnnl_graph_logical_tensor_t::ndims"]
        [::std::mem::offset_of!(dnnl_graph_logical_tensor_t, ndims) - 8usize];
    ["Offset of field: dnnl_graph_logical_tensor_t::dims"]
        [::std::mem::offset_of!(dnnl_graph_logical_tensor_t, dims) - 16usize];
    ["Offset of field: dnnl_graph_logical_tensor_t::data_type"]
        [::std::mem::offset_of!(dnnl_graph_logical_tensor_t, data_type) - 112usize];
    ["Offset of field: dnnl_graph_logical_tensor_t::property"]
        [::std::mem::offset_of!(dnnl_graph_logical_tensor_t, property) - 116usize];
    ["Offset of field: dnnl_graph_logical_tensor_t::layout_type"]
        [::std::mem::offset_of!(dnnl_graph_logical_tensor_t, layout_type) - 120usize];
    ["Offset of field: dnnl_graph_logical_tensor_t::layout"]
        [::std::mem::offset_of!(dnnl_graph_logical_tensor_t, layout) - 128usize];
};
pub mod dnnl_graph_partition_policy_t {
    #[doc = " Policy specifications for partitioning"]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " Fusion policy returns partitions with typical post-op fusions, eg.\n Convolution + ReLU or other element-wise operations or a chian of\n post-ops."]
    pub const dnnl_graph_partition_policy_fusion: Type = 1;
    #[doc = " Debug policy doesn't not apply any fusions. It returns partitions with\n single operation in each partition. The policy is useful when users\n notice any bug or correctness issue in fusion policy."]
    pub const dnnl_graph_partition_policy_debug: Type = 2;
}
#[doc = " An opaque structure to describe a partition."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_graph_partition {
    _unused: [u8; 0],
}
#[doc = " A partition handle."]
pub type dnnl_graph_partition_t = *mut dnnl_graph_partition;
#[doc = " A constant partition handle."]
pub type const_dnnl_graph_partition_t = *const dnnl_graph_partition;
#[doc = " An opaque structure to describe a graph."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_graph_graph {
    _unused: [u8; 0],
}
#[doc = " A graph handle."]
pub type dnnl_graph_graph_t = *mut dnnl_graph_graph;
#[doc = " A constant graph handle."]
pub type const_dnnl_graph_graph_t = *const dnnl_graph_graph;
pub mod dnnl_graph_op_kind_t {
    #[doc = " Kinds of operations"]
    pub type Type = ::std::os::raw::c_uint;
    pub const dnnl_graph_op_abs: Type = 0;
    pub const dnnl_graph_op_abs_backward: Type = 1;
    pub const dnnl_graph_op_add: Type = 2;
    pub const dnnl_graph_op_avg_pool: Type = 3;
    pub const dnnl_graph_op_avg_pool_backward: Type = 4;
    pub const dnnl_graph_op_batch_norm_backward: Type = 5;
    pub const dnnl_graph_op_batch_norm_forward_training: Type = 6;
    pub const dnnl_graph_op_batch_norm_inference: Type = 7;
    pub const dnnl_graph_op_bias_add: Type = 8;
    pub const dnnl_graph_op_bias_add_backward: Type = 9;
    pub const dnnl_graph_op_clamp: Type = 10;
    pub const dnnl_graph_op_clamp_backward: Type = 11;
    pub const dnnl_graph_op_concat: Type = 12;
    pub const dnnl_graph_op_convolution: Type = 13;
    pub const dnnl_graph_op_convolution_backward_data: Type = 14;
    pub const dnnl_graph_op_convolution_backward_weights: Type = 15;
    pub const dnnl_graph_op_conv_transpose: Type = 16;
    pub const dnnl_graph_op_conv_transpose_backward_data: Type = 17;
    pub const dnnl_graph_op_conv_transpose_backward_weights: Type = 18;
    pub const dnnl_graph_op_dequantize: Type = 19;
    pub const dnnl_graph_op_divide: Type = 20;
    pub const dnnl_graph_op_dynamic_dequantize: Type = 21;
    pub const dnnl_graph_op_dynamic_quantize: Type = 22;
    pub const dnnl_graph_op_elu: Type = 23;
    pub const dnnl_graph_op_elu_backward: Type = 24;
    pub const dnnl_graph_op_end: Type = 25;
    pub const dnnl_graph_op_exp: Type = 26;
    pub const dnnl_graph_op_gelu: Type = 27;
    pub const dnnl_graph_op_gelu_backward: Type = 28;
    pub const dnnl_graph_op_hard_swish: Type = 29;
    pub const dnnl_graph_op_hard_swish_backward: Type = 30;
    pub const dnnl_graph_op_interpolate: Type = 31;
    pub const dnnl_graph_op_interpolate_backward: Type = 32;
    pub const dnnl_graph_op_layer_norm: Type = 33;
    pub const dnnl_graph_op_layer_norm_backward: Type = 34;
    pub const dnnl_graph_op_leaky_relu: Type = 35;
    pub const dnnl_graph_op_log: Type = 36;
    pub const dnnl_graph_op_log_softmax: Type = 37;
    pub const dnnl_graph_op_log_softmax_backward: Type = 38;
    pub const dnnl_graph_op_matmul: Type = 39;
    pub const dnnl_graph_op_maximum: Type = 40;
    pub const dnnl_graph_op_max_pool: Type = 41;
    pub const dnnl_graph_op_max_pool_backward: Type = 42;
    pub const dnnl_graph_op_minimum: Type = 43;
    pub const dnnl_graph_op_mish: Type = 44;
    pub const dnnl_graph_op_mish_backward: Type = 45;
    pub const dnnl_graph_op_multiply: Type = 46;
    pub const dnnl_graph_op_prelu: Type = 47;
    pub const dnnl_graph_op_prelu_backward: Type = 48;
    pub const dnnl_graph_op_quantize: Type = 49;
    pub const dnnl_graph_op_reciprocal: Type = 50;
    pub const dnnl_graph_op_reduce_l1: Type = 51;
    pub const dnnl_graph_op_reduce_l2: Type = 52;
    pub const dnnl_graph_op_reduce_max: Type = 53;
    pub const dnnl_graph_op_reduce_mean: Type = 54;
    pub const dnnl_graph_op_reduce_min: Type = 55;
    pub const dnnl_graph_op_reduce_prod: Type = 56;
    pub const dnnl_graph_op_reduce_sum: Type = 57;
    pub const dnnl_graph_op_relu: Type = 58;
    pub const dnnl_graph_op_relu_backward: Type = 59;
    pub const dnnl_graph_op_reorder: Type = 60;
    pub const dnnl_graph_op_round: Type = 61;
    pub const dnnl_graph_op_sigmoid: Type = 62;
    pub const dnnl_graph_op_sigmoid_backward: Type = 63;
    pub const dnnl_graph_op_softmax: Type = 64;
    pub const dnnl_graph_op_softmax_backward: Type = 65;
    pub const dnnl_graph_op_softplus: Type = 66;
    pub const dnnl_graph_op_softplus_backward: Type = 67;
    pub const dnnl_graph_op_sqrt: Type = 68;
    pub const dnnl_graph_op_sqrt_backward: Type = 69;
    pub const dnnl_graph_op_square: Type = 70;
    pub const dnnl_graph_op_squared_difference: Type = 71;
    pub const dnnl_graph_op_static_reshape: Type = 72;
    pub const dnnl_graph_op_static_transpose: Type = 73;
    pub const dnnl_graph_op_subtract: Type = 74;
    pub const dnnl_graph_op_tanh: Type = 75;
    pub const dnnl_graph_op_tanh_backward: Type = 76;
    pub const dnnl_graph_op_type_cast: Type = 77;
    pub const dnnl_graph_op_wildcard: Type = 78;
    pub const dnnl_graph_op_hard_sigmoid: Type = 79;
    pub const dnnl_graph_op_hard_sigmoid_backward: Type = 80;
    pub const dnnl_graph_op_select: Type = 81;
    pub const dnnl_graph_op_pow: Type = 82;
    pub const dnnl_graph_op_group_norm: Type = 83;
    pub const dnnl_graph_op_gen_index: Type = 84;
    pub const dnnl_graph_op_greater_equal: Type = 85;
    pub const dnnl_graph_op_last_symbol: Type = 86;
}
pub mod dnnl_graph_op_attr_t {
    #[doc = " Attributes of operations"]
    pub type Type = ::std::os::raw::c_uint;
    #[doc = " Undefined op attribute."]
    pub const dnnl_graph_op_attr_undef: Type = 0;
    #[doc = " Specifies an alpha attribute to an op."]
    pub const dnnl_graph_op_attr_alpha: Type = 1;
    #[doc = " Specifies an beta attribute to an op."]
    pub const dnnl_graph_op_attr_beta: Type = 2;
    #[doc = " Specifies an epsilon attribute to an op."]
    pub const dnnl_graph_op_attr_epsilon: Type = 3;
    #[doc = " Specifies a max attribute to an op."]
    pub const dnnl_graph_op_attr_max: Type = 4;
    #[doc = "Specifies a min attribute to an op."]
    pub const dnnl_graph_op_attr_min: Type = 5;
    #[doc = " Specifies a momentum attribute to an op."]
    pub const dnnl_graph_op_attr_momentum: Type = 6;
    #[doc = " Specifies a scales attribute to an op."]
    pub const dnnl_graph_op_attr_scales: Type = 32;
    #[doc = " Specifies an axis attribute to an op."]
    pub const dnnl_graph_op_attr_axis: Type = 48;
    #[doc = " Specifies a begin_norm_axis attribute to an op."]
    pub const dnnl_graph_op_attr_begin_norm_axis: Type = 49;
    #[doc = " Specifies a groups attribute to an op."]
    pub const dnnl_graph_op_attr_groups: Type = 50;
    #[doc = " Specifies an axes attribute to an op."]
    pub const dnnl_graph_op_attr_axes: Type = 64;
    #[doc = " Specifies a dilations attribute to an op."]
    pub const dnnl_graph_op_attr_dilations: Type = 65;
    #[doc = " Specifies an dst_shape attribute to an op."]
    pub const dnnl_graph_op_attr_dst_shape: Type = 66;
    #[doc = " Specifies a kernel attribute to an op."]
    pub const dnnl_graph_op_attr_kernel: Type = 67;
    #[doc = " Specifies an order attribute to an op."]
    pub const dnnl_graph_op_attr_order: Type = 68;
    #[doc = " Specifies an output_padding attribute to an op."]
    pub const dnnl_graph_op_attr_output_padding: Type = 69;
    #[doc = " Specifies a pads_begin attribute to an op."]
    pub const dnnl_graph_op_attr_pads_begin: Type = 70;
    #[doc = " Specifies a pads_end attribute to an op."]
    pub const dnnl_graph_op_attr_pads_end: Type = 71;
    #[doc = " Specifies a shape attribute to an op."]
    pub const dnnl_graph_op_attr_shape: Type = 72;
    #[doc = " Specifies a sizes attribute to an op."]
    pub const dnnl_graph_op_attr_sizes: Type = 73;
    #[doc = " Specifies a input_shape attribute to an op."]
    pub const dnnl_graph_op_attr_src_shape: Type = 74;
    #[doc = " Specifies a strides attribute to an op."]
    pub const dnnl_graph_op_attr_strides: Type = 75;
    #[doc = " Specifies a weight_shape attribute to an op."]
    pub const dnnl_graph_op_attr_weights_shape: Type = 76;
    #[doc = " Specifies a zps attribute to an op."]
    pub const dnnl_graph_op_attr_zps: Type = 77;
    #[doc = " Specifies a group shape attribute to an op."]
    pub const dnnl_graph_op_attr_group_shape: Type = 78;
    #[doc = " Specifies an exclude_pad attribute to an op."]
    pub const dnnl_graph_op_attr_exclude_pad: Type = 96;
    #[doc = " Specifies a keep_dims attribute to an op."]
    pub const dnnl_graph_op_attr_keep_dims: Type = 97;
    #[doc = " Specifies a keep_stats attribute to an op."]
    pub const dnnl_graph_op_attr_keep_stats: Type = 98;
    #[doc = " Specifies a per_channel_broadcast attribute to an op."]
    pub const dnnl_graph_op_attr_per_channel_broadcast: Type = 99;
    #[doc = " Specifies a special_zero attribute to an op."]
    pub const dnnl_graph_op_attr_special_zero: Type = 100;
    #[doc = " Specifies a transpose_a attribute to an op."]
    pub const dnnl_graph_op_attr_transpose_a: Type = 101;
    #[doc = " Specifies a transpose_b attribute to an op."]
    pub const dnnl_graph_op_attr_transpose_b: Type = 102;
    #[doc = " Specifies an use_affine attribute to an op."]
    pub const dnnl_graph_op_attr_use_affine: Type = 103;
    #[doc = " Specifies an use_dst attribute to an op."]
    pub const dnnl_graph_op_attr_use_dst: Type = 104;
    #[doc = " Specifies an auto_broadcast attribute to an op. The value can be \"none\"\n or \"numpy\"."]
    pub const dnnl_graph_op_attr_auto_broadcast: Type = 128;
    #[doc = " Specifies an auto_pad attribute to an op. The value can be \"none\",\n \"same_upper\", \"same_lower\", or \"valid\"."]
    pub const dnnl_graph_op_attr_auto_pad: Type = 129;
    #[doc = " Specifies an coordinate_transformation_mode attribute to an op. The\n value can be \"half_pixel\" or \"align_corners\". The attribute is defined\n for Interpolate operations."]
    pub const dnnl_graph_op_attr_coordinate_transformation_mode: Type = 130;
    #[doc = " Specifies a data_format of an op. The value can be \"NCX\" or \"NXC\"."]
    pub const dnnl_graph_op_attr_data_format: Type = 131;
    #[doc = " Specifies a mode attribute of an op.\n Interpolate: \"nearest\", \"linear\", \"bilinear\", or \"trilinear\".\n SoftMax: \"none\", \"inf_as_zero\"."]
    pub const dnnl_graph_op_attr_mode: Type = 132;
    #[doc = " Specifies a qtype attribute to an op. The value can be \"per_channel\" or\n \"per_tensor\". The attribute is defined for quantization operations."]
    pub const dnnl_graph_op_attr_qtype: Type = 133;
    #[doc = " Specifies a rounding_type attribute to an op. The value can be \"ceil\" or\n \"floor\"."]
    pub const dnnl_graph_op_attr_rounding_type: Type = 134;
    #[doc = " Specifies a weights_format of an op. The value can be \"OIX\", \"XIO\",\n \"IOX\", or \"XOI\". Different operations may support different values."]
    pub const dnnl_graph_op_attr_weights_format: Type = 135;
    #[doc = " Specifies the end of all above exteral attributes for check."]
    pub const dnnl_graph_op_attr_end: Type = 255;
}
#[doc = " An opaque structure to describe an operation."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_graph_op {
    _unused: [u8; 0],
}
#[doc = " An operation handle."]
pub type dnnl_graph_op_t = *mut dnnl_graph_op;
#[doc = " A constant operation handle."]
pub type const_dnnl_graph_op_t = *const dnnl_graph_op;
#[doc = " Allocation call-back function interface for host. For SYCL allocator, see\n #dnnl_graph_sycl_allocate_f."]
pub type dnnl_graph_host_allocate_f = ::std::option::Option<
    unsafe extern "C" fn(size: usize, alignment: usize) -> *mut ::std::os::raw::c_void,
>;
#[doc = " Deallocation call-back function interface for host. For SYCL allocator, see\n #dnnl_graph_sycl_deallocate_f."]
pub type dnnl_graph_host_deallocate_f =
    ::std::option::Option<unsafe extern "C" fn(arg1: *mut ::std::os::raw::c_void)>;
#[doc = " An opaque structure to describe an allocator."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_graph_allocator {
    _unused: [u8; 0],
}
#[doc = " An allocator handle."]
pub type dnnl_graph_allocator_t = *mut dnnl_graph_allocator;
#[doc = " A constant allocator handle."]
pub type const_dnnl_graph_allocator_t = *const dnnl_graph_allocator;
#[doc = " In-place pair definition. It can queried from a compiled partition\n indicating that an input and an output of the partition can share the same\n memory buffer for computation. In-place computation helps to reduce the\n memory footprint and improves cache locality. But since the library may not\n have a global view of user's application, it's possible that the tensor with\n `input_id` is used at other places in user's computation graph. In this\n case, the user should take the in-place pair as a hint and pass a different\n memory buffer for output tensor to avoid overwriting the input memory buffer\n which will probably cause unexpected incorrect results."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_graph_inplace_pair_t {
    #[doc = " The id of input tensor"]
    pub input_id: usize,
    #[doc = " The id of output tensor"]
    pub output_id: usize,
}
#[allow(clippy::unnecessary_operation, clippy::identity_op)]
const _: () = {
    ["Size of dnnl_graph_inplace_pair_t"]
        [::std::mem::size_of::<dnnl_graph_inplace_pair_t>() - 16usize];
    ["Alignment of dnnl_graph_inplace_pair_t"]
        [::std::mem::align_of::<dnnl_graph_inplace_pair_t>() - 8usize];
    ["Offset of field: dnnl_graph_inplace_pair_t::input_id"]
        [::std::mem::offset_of!(dnnl_graph_inplace_pair_t, input_id) - 0usize];
    ["Offset of field: dnnl_graph_inplace_pair_t::output_id"]
        [::std::mem::offset_of!(dnnl_graph_inplace_pair_t, output_id) - 8usize];
};
#[doc = " An opaque structure to describe a compiled partition."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_graph_compiled_partition {
    _unused: [u8; 0],
}
#[doc = " A compiled partition handle."]
pub type dnnl_graph_compiled_partition_t = *mut dnnl_graph_compiled_partition;
#[doc = " A constant compiled partition handle."]
pub type const_dnnl_graph_compiled_partition_t = *const dnnl_graph_compiled_partition;
#[doc = " An opaque structure to describe a tensor."]
#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct dnnl_graph_tensor {
    _unused: [u8; 0],
}
#[doc = " A tensor handle."]
pub type dnnl_graph_tensor_t = *mut dnnl_graph_tensor;
#[doc = " A constant tensor handle."]
pub type const_dnnl_graph_tensor_t = *const dnnl_graph_tensor;
unsafe extern "C" {
    #[doc = " Creates a host allocator with the given allocation and deallocation\n call-back function pointers.\n\n @param allocator Output allocator.\n @param host_malloc A pointer to malloc function for host.\n @param host_free A pointer to free function for host.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_allocator_create(
        allocator: *mut dnnl_graph_allocator_t,
        host_malloc: dnnl_graph_host_allocate_f,
        host_free: dnnl_graph_host_deallocate_f,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Destroys an allocator.\n\n @param allocator The allocator to be destroyed.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_allocator_destroy(allocator: dnnl_graph_allocator_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " This API is a supplement for existing onednn engine API."]
    pub fn dnnl_graph_make_engine_with_allocator(
        engine: *mut dnnl_engine_t,
        kind: dnnl_engine_kind_t::Type,
        index: usize,
        alloc: const_dnnl_graph_allocator_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Initializes a logical tensor with id, data type, number of dimensions,\n layout type, and property. The logical tensor's dims are unknown with this\n interface.\n\n @param logical_tensor Output logical tensor.\n @param tid The unique id of the output logical tensor.\n @param dtype Elements data type.\n @param ndims Number of dimensions.\n @param ltype Layout type of the underlying tensor buffer.\n @param ptype Tensor property type.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_logical_tensor_init(
        logical_tensor: *mut dnnl_graph_logical_tensor_t,
        tid: usize,
        dtype: dnnl_data_type_t::Type,
        ndims: i32,
        ltype: dnnl_graph_layout_type_t::Type,
        ptype: dnnl_graph_tensor_property_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Initializes a logical tensor with basic information and dims. The logical\n tensor's dimensions and layout will be initialized according to the input\n arguments.\n\n @note\n     If dims contains all valid values and layout type is\n     #dnnl_graph_layout_type_strided. The strides field in\n     #dnnl_graph_logical_tensor_t will be calculated in a row major and\n     contiguous way. Otherwise, Accessing the strides field is an undefined\n     behavior.\n\n     Eg. dims (2, 3, 4, 5) will get strides (60, 20, 5, 1)\n\n @param logical_tensor Output logical tensor.\n @param tid The unique id of output logical tensor.\n @param dtype Elements data type.\n @param ndims Number of dimensions.\n @param dims Array of dimensions.\n @param ltype Layout type of the underlying tensor memory.\n @param ptype Tensor property type.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_logical_tensor_init_with_dims(
        logical_tensor: *mut dnnl_graph_logical_tensor_t,
        tid: usize,
        dtype: dnnl_data_type_t::Type,
        ndims: i32,
        dims: *const dnnl_dim_t,
        ltype: dnnl_graph_layout_type_t::Type,
        ptype: dnnl_graph_tensor_property_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Initializes a logical tensor with dimensions and strides provided by user.\n\n @note\n     Once strides are explicitly provided through the API, the `layout_type`\n     in #dnnl_graph_logical_tensor_t can only be\n     #dnnl_graph_layout_type_strided or #dnnl_graph_layout_type_any.\n\n @param logical_tensor Output logical tensor.\n @param tid The unique id of output logical tensor.\n @param dtype Elements data type.\n @param ndims Number of dimensions.\n @param dims Array of dimensions.\n @param strides Array of strides.\n @param ptype Tensor property type.\n @returns #dnnl_success on success or a status describing the error\n otherwise."]
    pub fn dnnl_graph_logical_tensor_init_with_strides(
        logical_tensor: *mut dnnl_graph_logical_tensor_t,
        tid: usize,
        dtype: dnnl_data_type_t::Type,
        ndims: i32,
        dims: *const dnnl_dim_t,
        strides: *const dnnl_dim_t,
        ptype: dnnl_graph_tensor_property_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the memory size described by the logical tensor. If it's a strided\n layout, the size will be calculated by `dims` and `strides`. If it's an\n opaque layout, the size will be decided by `layout_id`.\n\n @param logical_tensor Logical tensor.\n @param size Output memory size in bytes.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_logical_tensor_get_mem_size(
        logical_tensor: *const dnnl_graph_logical_tensor_t,
        size: *mut usize,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Compares if two logical tenors are equal. Users can decide accordingly\n if layout reordering is needed for two logical tensors. The method will\n return true for below two circumstances:\n\n 1. the two logical tensors are equal regarding each field in the struct,\n eg. id, ndims, dims, layout type, property, etc.\n 2. If all other fields are equal but the layout types in two logical\n tensors are different, the method will return true when the underlying\n memory layout is the same. For example, one logical tensor has strided\n layout type while the other one has opaque layout type, but underneath,\n both layouts are NHWC, the method will still return true for this case.\n\n @param lt1 The handle of first logical tensor.\n @param lt2 The handle of second logical tensor.\n @param is_equal 1 if these two logical tensors are equal, 0 otherwise.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_logical_tensor_is_equal(
        lt1: *const dnnl_graph_logical_tensor_t,
        lt2: *const dnnl_graph_logical_tensor_t,
        is_equal: *mut u8,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a tensor with logical tensor, engine, and data handle.\n\n @param tensor Output tensor.\n @param logical_tensor Description for this tensor.\n @param engine Engine to use.\n @param handle Handle of the memory buffer to use as an underlying storage.\n     - A pointer to the user-allocated buffer. In this case the library\n       doesn't own the buffer.\n     - The DNNL_MEMORY_ALLOCATE special value. Instructs the library to\n       allocate the buffer for the tensor. In this case the library\n       owns the buffer.\n     - DNNL_MEMORY_NONE to create tensor without an underlying buffer.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_tensor_create(
        tensor: *mut dnnl_graph_tensor_t,
        logical_tensor: *const dnnl_graph_logical_tensor_t,
        engine: dnnl_engine_t,
        handle: *mut ::std::os::raw::c_void,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Destroys a tensor.\n\n @param tensor The tensor to be destroyed.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_tensor_destroy(tensor: dnnl_graph_tensor_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Gets the data handle of a tensor.\n\n @param tensor The input tensor.\n @param handle Pointer to the data of input tensor.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_tensor_get_data_handle(
        tensor: const_dnnl_graph_tensor_t,
        handle: *mut *mut ::std::os::raw::c_void,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Set data handle for a tensor.\n\n @param tensor The input tensor.\n @param handle New data handle for tensor.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_tensor_set_data_handle(
        tensor: dnnl_graph_tensor_t,
        handle: *mut ::std::os::raw::c_void,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the engine of a tensor object.\n\n @param tensor The input tensor.\n @param engine Output engine on which the tensor is located.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_tensor_get_engine(
        tensor: const_dnnl_graph_tensor_t,
        engine: *mut dnnl_engine_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the logical tensor of a tensor object.\n\n @param tensor The input tensor.\n @param logical_tensor Output logical tensor of the tensor object.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_tensor_get_logical_tensor(
        tensor: const_dnnl_graph_tensor_t,
        logical_tensor: *mut dnnl_graph_logical_tensor_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Initializes an op with unique id, kind, and name.\n\n @param op Output op\n @param id The unique id of the output op.\n @param kind The op kind.\n @param verbose_name The string added as the op name.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_op_create(
        op: *mut dnnl_graph_op_t,
        id: usize,
        kind: dnnl_graph_op_kind_t::Type,
        verbose_name: *const ::std::os::raw::c_char,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Destroys an op.\n\n @param op The op to be destroyed.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_op_destroy(op: dnnl_graph_op_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Adds input logical tensor to the op.\n\n @param op Input op.\n @param input The input logical tensor to be added.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_op_add_input(
        op: dnnl_graph_op_t,
        input: *const dnnl_graph_logical_tensor_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Adds output logical tensor to the op.\n\n @param op Input op.\n @param output The output logical tensor to be added.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_op_add_output(
        op: dnnl_graph_op_t,
        output: *const dnnl_graph_logical_tensor_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets floating point attribute to an op.\n\n @param op Input op.\n @param name The attribute's name.\n @param value The attribute's value.\n @param value_len The number of value element.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_op_set_attr_f32(
        op: dnnl_graph_op_t,
        name: dnnl_graph_op_attr_t::Type,
        value: *const f32,
        value_len: usize,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets boolean attribute to an op.\n\n @param op Input op.\n @param name The attribute's name.\n @param value The attribute's value.\n @param value_len The number of value element.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_op_set_attr_bool(
        op: dnnl_graph_op_t,
        name: dnnl_graph_op_attr_t::Type,
        value: *const u8,
        value_len: usize,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets integer attribute to an op.\n\n @param op Input op.\n @param name The attribute's name.\n @param value The attribute's value.\n @param value_len The number of value element.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_op_set_attr_s64(
        op: dnnl_graph_op_t,
        name: dnnl_graph_op_attr_t::Type,
        value: *const i64,
        value_len: usize,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets string attribute to an op.\n\n @param op Input op.\n @param name The attribute's name.\n @param value The attribute's value.\n @param value_len The length of the string value.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_op_set_attr_str(
        op: dnnl_graph_op_t,
        name: dnnl_graph_op_attr_t::Type,
        value: *const ::std::os::raw::c_char,
        value_len: usize,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the unique id of an op.\n\n @param op Input op.\n @param id Output the unique id.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_op_get_id(op: const_dnnl_graph_op_t, id: *mut usize) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the kind of an op.\n\n @param op Input op.\n @param kind Output op kind.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_op_get_kind(
        op: const_dnnl_graph_op_t,
        kind: *mut dnnl_graph_op_kind_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a new partition with a given operator and engine kind. The API is\n used to create a partition from an operation directly without creating the\n graph and calling `get_partitions()`. The output partition contains only one\n operation specified by the parameter. The output partition instance should\n be destroyed via #dnnl_graph_partition_destroy after use.\n\n @param partition The handle of output partition.\n @param op The operation used to create partition.\n @param ekind The engine kind used to create partition.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_partition_create_with_op(
        partition: *mut dnnl_graph_partition_t,
        op: const_dnnl_graph_op_t,
        ekind: dnnl_engine_kind_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Destroys a partition.\n\n @param partition The partition to be destroyed.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_partition_destroy(partition: dnnl_graph_partition_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the number of operations in a partition.\n\n @param partition The target partition.\n @param num Output the number of operations.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_partition_get_op_num(
        partition: const_dnnl_graph_partition_t,
        num: *mut usize,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the list of op IDs of the partition.\n\n @param partition The target partition.\n @param num The number of ops.\n @param ids Output the op IDs.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_partition_get_ops(
        partition: dnnl_graph_partition_t,
        num: usize,
        ids: *mut usize,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the ID of a partition.\n\n @param partition The target partition.\n @param id Output the ID of the partition.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_partition_get_id(
        partition: const_dnnl_graph_partition_t,
        id: *mut usize,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Compiles a partition with given input and output logical tensors. The output\n logical tensors can contain unknown dimensions. For this case, the\n compilation will deduce the output shapes according to input shapes. The\n output logical tensors can also have layout type `any`. The compilation will\n choose the optimal layout for output tensors. The optimal layout will be\n represented as an opaque layout ID saved in the output logical tensor.\n\n @param partition The target partition.\n @param compiled_partition Output compiled partition.\n @param in_num The number of input logical tensors.\n @param inputs A list of input logical tensors.\n @param out_num The number of output logical tensors.\n @param outputs A list of output logical tensors.\n @param engine The target engine of the compilation.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_partition_compile(
        partition: dnnl_graph_partition_t,
        compiled_partition: dnnl_graph_compiled_partition_t,
        in_num: usize,
        inputs: *mut *const dnnl_graph_logical_tensor_t,
        out_num: usize,
        outputs: *mut *const dnnl_graph_logical_tensor_t,
        engine: dnnl_engine_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the number of input logical tensors of a partition.\n\n @param partition The target partition.\n @param num Output the number of input logical tensors.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_partition_get_input_ports_num(
        partition: const_dnnl_graph_partition_t,
        num: *mut usize,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns a list of input logical tensors from a partition.\n\n @param partition The target partition.\n @param num The number of input logical tensors.\n @param inputs The list of input logical tensors.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_partition_get_input_ports(
        partition: const_dnnl_graph_partition_t,
        num: usize,
        inputs: *mut dnnl_graph_logical_tensor_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the number of output logical tensors of a partition.\n\n @param partition The target partition.\n @param num Output the number of output logical tensors.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_partition_get_output_ports_num(
        partition: const_dnnl_graph_partition_t,
        num: *mut usize,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns a list of output logical tensors from a partition.\n\n @param partition The target partition.\n @param num The number of output logical tensors.\n @param outputs The list of output logical tensors.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_partition_get_output_ports(
        partition: const_dnnl_graph_partition_t,
        num: usize,
        outputs: *mut dnnl_graph_logical_tensor_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the supporting status of a partition. Some operations may not be\n supported by the library under certain circumstances. During partitioning\n stage, unsupported partitions will be returned to users with each containing\n an unsupported operation. Users should check the supporting status of a\n partition before transforming the computation graph or compiling the\n partition.\n\n @param partition The target partition.\n @param is_supported Output flag to indicate the supporting status. 0 means\n     unsupported while 1 means supported.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_partition_is_supported(
        partition: const_dnnl_graph_partition_t,
        is_supported: *mut u8,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the engine kind of a partition.\n\n @param partition The target partition.\n @param kind The output engine kind.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_partition_get_engine_kind(
        partition: const_dnnl_graph_partition_t,
        kind: *mut dnnl_engine_kind_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a new compiled partition handle.\n\n @param compiled_partition The handle of output compiled partition.\n @param partition The handle of input partition.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_compiled_partition_create(
        compiled_partition: *mut dnnl_graph_compiled_partition_t,
        partition: dnnl_graph_partition_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Executes a compiled partition.\n\n @param compiled_partition The handle of target compiled partition.\n @param stream The stream used for execution.\n @param num_inputs The number of input tensors.\n @param inputs A list of input tensors.\n @param num_outputs The number of output tensors.\n @param outputs A non-empty list of output tensors.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_compiled_partition_execute(
        compiled_partition: const_dnnl_graph_compiled_partition_t,
        stream: dnnl_stream_t,
        num_inputs: usize,
        inputs: *mut const_dnnl_graph_tensor_t,
        num_outputs: usize,
        outputs: *mut const_dnnl_graph_tensor_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Destroys a compiled partition.\n\n @param compiled_partition The compiled partition to be destroyed.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_compiled_partition_destroy(
        compiled_partition: dnnl_graph_compiled_partition_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Queries an input or output logical tensor according to tensor ID. If the\n tensor ID doesn't belong to any input or output of the compiled partition,\n an error status #dnnl_invalid_arguments will be returned by the API.\n\n @param compiled_partition The handle of target compiled_partition.\n @param tid The unique id of required tensor.\n @param lt The output logical tensor.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_compiled_partition_query_logical_tensor(
        compiled_partition: const_dnnl_graph_compiled_partition_t,
        tid: usize,
        lt: *mut dnnl_graph_logical_tensor_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the hint of in-place pairs from a compiled partition. It indicates\n that an input and an output of the partition can share the same memory\n buffer for computation. In-place computation helps to reduce the memory\n footprint and improves cache locality. But since the library may not have a\n global view of user's application, it's possible that the tensor with\n `input_id` is used at other places in user's computation graph. In this\n case, the user should take the in-place pair as a hint and pass a different\n memory buffer for output tensor to avoid overwriting the input memory buffer\n which will probably cause unexpected incorrect results.\n\n @param compiled_partition The handle of target compiled_partition.\n @param num_inplace_pairs The number of in-place pairs.\n @param inplace_pairs The handle of in-place pairs.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_compiled_partition_get_inplace_ports(
        compiled_partition: const_dnnl_graph_compiled_partition_t,
        num_inplace_pairs: *mut usize,
        inplace_pairs: *mut *const dnnl_graph_inplace_pair_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a new empty graph. A graph is associated to a specific engine kind.\n The partitions returned from the graph will inherit the engine kind of the\n graph.\n\n @param graph The handle of output graph.\n @param engine_kind The target engine kind.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_graph_create(
        graph: *mut dnnl_graph_graph_t,
        engine_kind: dnnl_engine_kind_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Creates a new empty graph with an engine kind and a floating-point math\n mode. All partitions returned from the graph will inherit the engine kind\n and floating-point math mode.\n\n @param graph The handle of output graph.\n @param engine_kind The kind for engine.\n @param mode The floating-point math mode.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_graph_create_with_fpmath_mode(
        graph: *mut dnnl_graph_graph_t,
        engine_kind: dnnl_engine_kind_t::Type,
        mode: dnnl_fpmath_mode_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Destroys a graph.\n\n @param graph The graph to be destroyed.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_graph_destroy(graph: dnnl_graph_graph_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Set the floating point math mode for a graph.\n\n @param graph The target graph.\n @param mode The floating-point math mode.\n @param apply_to_int The flag that controls whether to use floating-point\n     arithmetic for integral operations.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_graph_set_fpmath_mode(
        graph: dnnl_graph_graph_t,
        mode: dnnl_fpmath_mode_t::Type,
        apply_to_int: ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Get the floating point math mode for a graph.\n\n @param graph The target graph.\n @param mode The floating-point math mode.\n @param apply_to_int The flag that controls whether to use floating-point\n     arithmetic for integral operations.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_graph_get_fpmath_mode(
        graph: dnnl_graph_graph_t,
        mode: *mut dnnl_fpmath_mode_t::Type,
        apply_to_int: *mut ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Adds an operation into a graph. The API will return failure if the operator\n has already been added to the graph or the operation cannot pass the schema\n check in the library (eg. input and output numbers and data types, the\n attributes of the operation, etc.).\n\n @param graph The target graph.\n @param op The operation to be added.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_add_op(graph: dnnl_graph_graph_t, op: dnnl_graph_op_t)
        -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Finalizes a graph. It means users have finished adding operations into the\n graph and the graph is ready for partitioning. Adding a new operation into a\n finalized graph will return failures. Similarly, partitioning on a\n un-finalized graph will also return failures.\n\n @param graph The target graph to be finalized.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_graph_finalize(graph: dnnl_graph_graph_t) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Checks if a graph is finalized.\n\n @param graph The target graph to be finalized.\n @param finalized Output the finalization status. 0 means then graph is not\n     finalized. Other values means the graph is finalized.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_graph_is_finalized(
        graph: dnnl_graph_graph_t,
        finalized: *mut u8,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Filters a graph. Partitions will be claimed internally according to the\n capability of the library, the engine kind, and the policy.\n\n @param graph The target graph.\n @param policy The partition policy.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_graph_filter(
        graph: dnnl_graph_graph_t,
        policy: dnnl_graph_partition_policy_t::Type,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the number of partitions of a graph. The API should be called after\n a partition is already filtered. Otherwise, the output number is zero.\n\n @param graph The graph.\n @param num Output the number of partitions.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_graph_get_partition_num(
        graph: const_dnnl_graph_graph_t,
        num: *mut usize,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the partitions from a filtered graph. Output partition instances\n will be written into the parameter `partitions`. Users need to make sure\n `partitions` is valid and has enough space to accept the partition\n instances. Each output partition instance should be destroyed via\n #dnnl_graph_partition_destroy explicitly after use.\n\n @param graph The target graph.\n @param num The number of partitions.\n @param partitions Output the partitions.\n @returns #dnnl_success on success or a status describing the error\n     otherwise."]
    pub fn dnnl_graph_graph_get_partitions(
        graph: dnnl_graph_graph_t,
        num: usize,
        partitions: *mut dnnl_graph_partition_t,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Returns the number of compiled partitions that can be held in the compiled\n partition cache at the same time.\n\n @param capacity Compiled partition cache capacity to query. Concurrently\n accessing @p capacity is safe.\n @returns #dnnl_invalid_arguments if the @p capacity value\n     is invalid, and #dnnl_success on success."]
    pub fn dnnl_graph_get_compiled_partition_cache_capacity(
        capacity: *mut ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Sets a number of compiled partitions that can be held in the compiled\n partition cache at the same time. The default capacity of compiled partition\n cache is 1024.\n\n @param capacity Compiled partition cache capacity to set. The default cache\n capacity is 1024. If a new @p capacity is less than a number of compiled\n partition that the compiled partition cache already has, then the excess\n entries will be evicted. Setting the @p capacity to 0 clears the compiled\n partition cache and disables it. Concurrently modifying @p capacity is safe.\n @returns #dnnl_invalid_arguments if the @p capacity value\n is invalid, and #dnnl_success on success."]
    pub fn dnnl_graph_set_compiled_partition_cache_capacity(
        capacity: ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Control the enabling or disabling of constant tensor cache. This API must\n be called once before compilation stage. By default, constant tensor cache is\n disabled in the library.\n\n @param flag Set to positive value to enable the cache and set to 0 to\n disable the cache. Negative values are invalid.\n @returns #dnnl_invalid_arguments if the @p flag value is\n invalid, and #dnnl_success on success.\n @note This API is deprecated and will be removed in future release, please\n use the dnnl_graph_set_constant_tensor_cache_capacity API to disable\n constant tensor cache by setting it's capacity to zero."]
    pub fn dnnl_graph_set_constant_tensor_cache(flag: ::std::os::raw::c_int)
        -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Return the enabling or disabling status of constant tensor cache.\n\n @param flag The constant tensor cache enabling status to query.\n @returns #dnnl_invalid_arguments if the @p flag value is\n nullptr, and #dnnl_success on success.\n @note This API is deprecated and will be removed in future release, please\n use the dnnl_graph_get_constant_tensor_cache_capacity API to check the\n enabling status by checking it's capacity."]
    pub fn dnnl_graph_get_constant_tensor_cache(
        flag: *mut ::std::os::raw::c_int,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Control the capacity for the constant tensor cache that used for specific\n engine kind. This API is thread safe and can be called multiple times at\n runtime. The capacity is set to zero by default which means the cache is\n disabled. When calling this API, the corresponding cache will be flushed.\n Setting capacity to 0 means to clear all cached tensors and disable cache.\n Once the capacity limit is reached, no new tensors will be cached. If there\n are multiple devices for an engine kind, the capacity set here is for each\n device.\n\n @param eng_kind The engine kind that the constant tensor cache used for.\n @param size The constant tensor cache capacity size to set.\n @returns #dnnl_invalid_arguments if the @p eng_kind value is invalid, and\n #dnnl_success on success."]
    pub fn dnnl_graph_set_constant_tensor_cache_capacity(
        eng_kind: dnnl_engine_kind_t::Type,
        size: usize,
    ) -> dnnl_status_t::Type;
}
unsafe extern "C" {
    #[doc = " Return the current capacity of constant tensor cache.\n\n @param eng_kind The engine kind that the constant tensor cache used for.\n @param size The constant tensor cache capacity size to query.\n @returns #dnnl_invalid_arguments if the @p eng_kind value is\n nullptr or the @p size is nullptr, and #dnnl_success on success."]
    pub fn dnnl_graph_get_constant_tensor_cache_capacity(
        eng_kind: dnnl_engine_kind_t::Type,
        size: *mut usize,
    ) -> dnnl_status_t::Type;
}
